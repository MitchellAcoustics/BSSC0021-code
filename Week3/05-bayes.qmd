---
r-fit-text: true
---

```{r}
#| include: false
library(dplyr)
library(reshape2)
library(tidyr)
library(ggplot2)
library(knitr)
library(readr)
library(cowplot)
library(janitor)
```

# Bayes' Rule and Learning from Data {background-color="#1E3D59"}

## The Basic Formula

::: {.columns}
::: {.column width="50%"}
When we know $P(A|B)$ but want $P(B|A)$:

$P(B|A) = \frac{P(A|B)*P(B)}{P(A)}$

**Alternative Form:**

$P(B|A) = \frac{P(A|B)*P(B)}{P(A|B)*P(B) + P(A|\neg B)*P(\neg B)}$
::::

::: {.column width="50%"}
::: {.fragment}
**Components:**

 - Prior: $P(B)$
 - Likelihood: $P(A|B)$
 - Marginal likelihood: $P(A)$
 - Posterior: $P(B|A)$
::::
::::
::::

::: {.notes}
In many cases, we know P(A|B) but we really want to know P(B|A). This commonly occurs in medical screening, where we know P(positive test result| disease) but what we want to know is P(disease|positive test result).

If we have only two outcomes, we can express Bayes' rule in a somewhat clearer way, using the sum rule to redefine P(A).
::::

## Putting Bayes into Practice
### Construction company drug testing

A major construction company conducts mandatory random drug and alcohol screening using rapid saliva tests. Consider the following scenario:

::: {.incremental}
 - In the UK construction industry during 2023, the prevalence of substance use affecting workplace safety was estimated at **2.5%** of the workforce
 - The rapid saliva test used has a sensitivity (true positive rate) of **85%** when conducted according to protocol
 - The specificity (true negative rate) of these tests is **99.2%**

::::

::: {.notes}
Let's consider a specific example. Suppose that a worker is selected for a random drug screening. The test result is positive. What is the probability that this worker is actually positive for substances?
::::

## Putting Bayes into Practice
### Construction company drug testing
Let's consider a specific example. Suppose that a worker is selected for a random drug screening. The test result is positive. What is the probability that this worker is actually positive for substances?

::: {.fragment}
**Context:**
The company's current policy is immediate suspension without pay following a positive test result, pending a more accurate laboratory confirmation test that takes 48 hours.

 - Mandatory screening
 - Rapid saliva test
 - Safety-critical roles
 - Immediate consequences
::::

## Putting Bayes into Practice
### Construction company drug testing

**Construction Site Testing:**

 - Sensitivity: P(positive|substance) = 0.85
 - Specificity: P(negative|no substance) = 0.992
 - Base rate: P(substance) = 0.025

::: {.fragment}

**Key Values:**

 - P(S) = 0.025 (prevalence)
 - P(P|S) = 0.85 (sensitivity)
 - P(P|not S) = 0.008 (1 - specificity)

::::

::: {.notes}
A major construction company conducts mandatory random drug and alcohol screening using rapid saliva tests. In the UK construction industry during 2023, the prevalence of substance use affecting workplace safety was estimated at 2.5% of the workforce. The rapid saliva test used has a sensitivity of 85% when conducted according to protocol, and a specificity of 99.2%.
::::

## Let's Work Through It {background-color="#40798C"}

Using Bayes' Theorem, calculate the probability that this worker is actually positive for substances given their positive test result.

 - P(S) = 0.025 (prevalence)
 - P(P|S) = 0.85 (sensitivity)
 - P(P|not S) = 0.008 (1 - specificity)

::: {.notes}
A construction worker is randomly selected for testing at the start of their shift. Their saliva test comes back positive. Using Bayes' Theorem, calculate the probability that this worker is actually positive for substances given their positive test result.
::::

```{r}
#| echo: false
#| include: false

# Define the probabilities
P_S <- 0.025 # Base rate (prevalence)
P_notS <- 1 - P_S # Probability of no substance
P_P_S <- 0.85 # Sensitivity
P_N_notS <- 0.992 # Specificity
P_P_notS <- 1 - P_N_notS # False positive rate

# Calculate P(P) - total probability of positive test
P_P <- (P_P_S * P_S) + (P_P_notS * P_notS)

# Calculate P(S|P) using Bayes' Theorem
P_S_P <- (P_P_S * P_S) / P_P

# Calculate odds and odds ratio
prior_odds <- P_S / P_notS
posterior_odds <- P_S_P / (1 - P_S_P)
odds_ratio <- posterior_odds / prior_odds

# Format numbers for display
P_S_P_pct <- round(P_S_P * 100, 1)
P_P_components <- c(
  pp1 = round(P_P_S * P_S, 5),
  pp2 = round(P_P_notS * P_notS, 5)
)
P_P_total <- round(P_P, 5)
odds_ratio_rounded <- round(odds_ratio, 2)
```

## Solution

::: {.columns}
::: {.column width="60%"}
**Calculate P(substance|positive):**

::: {.fragment}
\begin{align*}
P(P) &= P(P|S) \times P(S) + P(P|not S) \times P(not S) \\
&= (0.85 \times 0.025) + (0.008 \times 0.975) \\
&= `r P_P_components['pp1']` + `r P_P_components['pp2']` \\
&= `r P_P_total`
\end{align*}

::::

::: {.fragment}

\begin{align*}
P(S|P) &= \frac{P(P|S) \times P(S)}{P(P)} \\
&= \frac{0.85 \times 0.025}{`r P_P_total`} \\
&= `r P_S_P` \text{ or } `r P_S_P_pct`\%
\end{align*}

::::
::::

::: {.column width="40%"}
::: {.fragment}
**Interpretation:**

 - ~`r P_S_P_pct`% chance true positive
 - ~`r round((1-P_S_P)*100, 1)`% chance false positive
 - Much higher than `r P_S*100`% base rate
 - Still significant uncertainty
::::
::::
::::

::: {.notes}
Using Bayes' Theorem, we find that given a positive test result, there is a `r P_S_P_pct`% probability that the worker actually has substances present. This is much higher than the base rate of `r P_S*100`%, but still leaves significant uncertainty with a `r round((1-P_S_P)*100, 1)`% false positive rate.
::::

## Discussion: The Real-world Implications {background-color="#40798C"}

The company's current policy is immediate suspension without pay following a positive test result. 

What do these results mean for this business policy? Is it fair to immediately suspend workers without pay for a positive test result?

::: {.notes}
The company's current policy is immediate suspension without pay following a positive test result, pending a more accurate laboratory confirmation test that takes 48 hours.


Given that approximately `r round((1-P_S_P)*100, 1)`% of positive test results may be false positives, an immediate suspension without pay could unfairly penalize innocent workers; however, the high stakes of construction safety and the `r P_S_P_pct`% probability of a true positive suggest that temporary removal from safety-critical roles is prudent while awaiting confirmation.
::::

## Learning from Data

::: {.columns}
::: {.column width="50%"}
**Bayes' Rule as Learning:**

$P(B|A) = \frac{P(A|B)}{P(A)}*P(B)$

**Components:**

 - Prior belief: $P(B)$
 - Evidence strength: $\frac{P(A|B)}{P(A)}$
 - Updated belief: $P(B|A)$
::::

::: {.column width="50%"}
**Key Insights:**

 - Updates prior knowledge
 - Evidence can strengthen/weaken
 - Systematic way to learn
 - Combines knowledge & data
::::
::::

::: {.notes}
Another way to think of Bayes' rule is as a way to update our beliefs on the basis of data. The different parts of Bayes' rule have specific names, that relate to their role in using Bayes' rule to update our beliefs.

The part on the left tells us how much more or less likely the data A are given B, relative to the overall likelihood of the data, while the part on the right side tells us how likely we thought B was before we knew anything about the data.
::::

## Odds and Odds Ratios

::: {.columns}
::: {.column width="50%"}
**Converting to Odds:**

$\text{odds of A} = \frac{P(A)}{P(\neg A)}$

**Example:**

Drug test odds:

 - Prior: $\frac{`r P_S`}{`r P_notS`} = `r round(prior_odds, 3)`$
 - Posterior: $\frac{`r P_S_P`}{`r 1-P_S_P`} = `r round(posterior_odds, 3)`$
::::

::: {.column width="50%"}
**Odds Ratio:**

$\frac{\text{posterior odds}}{\text{prior odds}} = \frac{`r round(posterior_odds, 3)`}{`r round(prior_odds, 3)`} = `r odds_ratio_rounded`$

**Interpretation:**

 - Odds increased 105Ã—
 - Much stronger evidence
 - Shows test's power
 - Despite false positives
::::
::::

::: {.notes}
We can convert probabilities into odds which express the relative likelihood of something happening or not. An odds ratio is an example of what we will later call an effect size, which is a way of quantifying how relatively large any particular statistical effect is.

First, remember the rule for computing a conditional probability. We can rearrange this to get the formula to compute the joint probability using the conditional. Using this we can compute the inverse probability.

::::
