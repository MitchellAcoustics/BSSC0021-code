---
r-fit-text: true
---

# Probability Rules and Classical Probability {background-color="#1E3D59"}

## Basic Rules {.incremental}

1. Rule of Subtraction:

   $P(\neg A) = 1 - P(A)$
   
   Example: P(not rolling a 1) = $1 - \frac{1}{6} = \frac{5}{6}$

2. Intersection Rule (independent events):

   $P(A \cap B) = P(A) * P(B)$
   
   Example: P(six on both rolls) = $\frac{1}{6} * \frac{1}{6} = \frac{1}{36}$

3. Addition Rule:

   $P(A \cup B) = P(A) + P(B) - P(A \cap B)$

::: {.notes}
To understand de Méré's error, we need to introduce some of the rules of probability theory:

1. The rule of subtraction says that the probability of some event A not happening is one minus the probability of the event happening
2. For independent events, we compute the probability of both occurring by multiplying their individual probabilities
3. The addition rule tells us that to obtain the probability of either of two events occurring, we add together the individual probabilities, but then subtract the likelihood of both occurring together
::::

## Classical Probability

::: {.columns}
::: {.column width="50%"}
**Key Principles:**

 - Equal likelihood assumption
 - Based on counting outcomes
 - No experiments needed
 - Common in games of chance

**Basic Formula:**

$P(outcome_i) = \frac{1}{\text{number of possible outcomes}}$
::::

::: {.column width="50%"}
**Examples:**

 - Fair coin: P(heads) = 1/2
 - Fair die: P(6) = 1/6
 - Two dice: P(double-six) = 1/36

```{r}
#| include: false
library(dplyr)
library(reshape2)
library(tidyr)
library(ggplot2)
library(knitr)
library(readr)
library(cowplot)
library(janitor)
```

```{r}
#| echo: false
# Visualization of dice outcomes
# (We'll keep the code but the visualization will be added later)
```

::::
::::

::: {.notes}
Classical probability arose from the study of games of chance such as dice and cards. In this approach, we compute the probability directly based on our knowledge of the situation.

We start with the assumption that all of the elementary events in the sample space are equally likely; that is, when you roll a die, each of the possible outcomes ({1,2,3,4,5,6}) is equally likely to occur.
::::

## de Méré's Problem

::: {.columns}
::: {.column width="60%"}
French gambler Chevalier de Méré played two games:

1. Bet on ≥1 six in 4 die rolls
2. Bet on ≥1 double-six in 24 rolls of two dice

He thought both had probability $\frac{2}{3}$ but...

 - Won money on first bet
 - Lost money on second bet
::::

::: {.column width="40%"}
His reasoning:

For first bet:

$4 * \frac{1}{6} = \frac{2}{3}$

For second bet:

$24 * \frac{1}{36} = \frac{2}{3}$

::::
::::

::: {.notes}
A famous example arose from a problem encountered by a French gambler who went by the name of Chevalier de Méré. de Méré played two different dice games: In the first he bet on the chance of at least one six on four rolls of a six-sided die, while in the second he bet on the chance of at least one double-six on 24 rolls of two dice. He expected to win money on both of these gambles, but he found that while on average he won money on the first gamble, he actually lost money on average when he played the second gamble many times.
::::

## Visualizing Multiple Events

::: {.columns}
::: {.column width="50%"}

**Matrix of Outcomes:**

```{r}
#| echo: false
imgmtx <- matrix(0, nrow = 6, ncol = 6)
imgmtx[, 1] <- 1
imgmtx[6, ] <- 1

plot <-
  imgmtx %>%
    melt() %>%
    ggplot(aes(Var1, Var2, fill = value)) +
    scale_fill_gradientn(colours = c("#0000FFFF", "#FFFFFFFF", "#FF0000FF")) +
    geom_raster(interpolate = FALSE) +
    theme_minimal() +
    theme(
      axis.line = element_blank(),
      axis.text.x = element_blank(),
      axis.text.y = element_blank(),
      axis.ticks = element_blank(),
      legend.position = "none"
    ) +
    labs(
      x = "Throw 1",
      y = "Throw 2"
    )

for (i in seq(0.5, 6.5)) {
  plot <- plot + geom_hline(yintercept = i, color = "white")
  plot <- plot + geom_vline(xintercept = i, color = "white")
  for (j in seq(0.5, 6.5)) {
    plot <- plot +
      annotate(
        "text",
        x = i + 0.5,
        y = 6.5 - j,
        label = sprintf("%d,%d", i + 0.5, j + 0.5),
        color = "white"
      )
  }
}
plot
```

::::

::: {.column width="50%"}
**Key Points:**

 - Red cells: six on either throw
 - Total red cells: 11
 - Explains $\frac{11}{36}$ probability
 - Shows de Méré's error

::::
::::

::: {.notes}
This matrix represents all possible combinations of results across two throws, and highlights the cells that involve a six on either the first or second throw. If you count up the cells in red you will see that there are 11 such cells. This shows why the addition rule gives a different answer from de Méré's; if we were to simply add together the probabilities for the two throws as he did, then we would count (6,6) towards both, when it should really only be counted once.
::::

## Pascal's Solution

::: {.columns}
::: {.column width="50%"}
**First bet:**

$P(\text{no sixes}) = \bigg(\frac{5}{6}\bigg)^4=0.482$

$P(\text{≥1 six}) = 1 - 0.482 = 0.517$

\
**Second bet:**

$P(\text{no double six}) = \bigg(\frac{35}{36}\bigg)^{24}=0.509$

$P(\text{≥1 double six}) = 1 - 0.509 = 0.491$
::::

::: {.column width="50%"}
**Key Insights:**

 - Easier to compute complement
 - First bet: P > 0.5
 - Second bet: P < 0.5
 - Explains gambling results

::::
::::

::: {.notes}
Blaise Pascal used the rules of probability to solve de Méré's problem. First, he realized that computing the probability of at least one event out of a combination was tricky, whereas computing the probability that something does not occur across several events is relatively easy -- it's just the product of the probabilities of the individual events.

The first bet has probability > 0.5, explaining why de Méré made money on this bet on average.
The second bet has probability < 0.5, explaining why de Méré lost money on average on this bet.
::::
