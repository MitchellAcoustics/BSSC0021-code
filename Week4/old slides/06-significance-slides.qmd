---
title: "Hypothesis Testing"
subtitle: "Part 6: Modern Challenges in Statistical Significance"
---

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(ggplot2)
library(cowplot)
library(knitr)
library(NHANES)

# drop duplicated IDs within the NHANES dataset
NHANES <- 
  NHANES %>% 
  dplyr::distinct(ID,.keep_all = TRUE)

NHANES_adult <- 
  NHANES %>%
  drop_na(PhysActive,BMI) %>%
  subset(Age >= 18)
```

## The Reproducibility Crisis {.smaller}

::: {.panel-tabset}

### The Problem

::: {.columns}
::: {.column width="50%"}
**Key Issues:**

- Many studies don't replicate
- Publication bias
- P-hacking common
- Underpowered studies
::::

::: {.column width="50%"}
**Contributing Factors:**

- Focus on p < 0.05
- Publication pressure
- Limited resources
- Complex phenomena
::::
::::

### Evidence

```{r repro-crisis}
#| fig-width: 10
#| fig-height: 6
#| echo: false

# Create visualization of replication attempts
fields <- c("Psychology", "Medicine", "Economics", "Social Science")
replication_rates <- c(0.39, 0.43, 0.61, 0.42)
sample_sizes <- c(100, 150, 80, 120)

repro_data <- data.frame(
  field = fields,
  rate = replication_rates,
  size = sample_sizes
)

ggplot(repro_data, aes(x = field, y = rate)) +
  geom_bar(stat = "identity", fill = "steelblue", alpha = 0.7) +
  geom_text(aes(label = sprintf("%.0f%%", rate*100)), vjust = -0.5) +
  labs(title = "Replication Success Rates Across Fields",
       subtitle = "Based on major replication projects",
       x = "Field",
       y = "Successful Replication Rate") +
  theme_minimal() +
  ylim(0, 1)
```

::::

::: {.notes}
Key points about reproducibility:

1. Major concern across sciences
2. Multiple contributing factors
3. No simple solutions
4. Requires systemic changes
::::

## Big Data Challenges {.smaller}

::: {.panel-tabset}

### Scale of Testing

::: {.columns}
::: {.column width="50%"}
**Modern Research Scale:**

- Genomics: millions of variants
- Neuroimaging: thousands of voxels
- Social media: billions of interactions
- Sensors: continuous data streams
::::

::: {.column width="50%"}
**Consequences:**

- False positive inflation
- Computational challenges
- Multiple testing burden
- Interpretation difficulties
::::
::::

### False Discovery Rate

```{r fdr-viz}
#| fig-width: 10
#| fig-height: 6
#| echo: false

# Simulate multiple testing scenario
set.seed(123)
n_tests <- c(1, 10, 100, 1000, 10000)
alpha <- 0.05

# Calculate expected false positives
false_positives <- data.frame(
  tests = n_tests,
  expected = n_tests * alpha
)

ggplot(false_positives, aes(x = tests, y = expected)) +
  geom_point(size = 3) +
  geom_line() +
  scale_x_log10(breaks = n_tests,
                labels = scales::comma) +
  scale_y_log10() +
  labs(title = "Expected False Positives vs Number of Tests",
       subtitle = "Using traditional p < 0.05",
       x = "Number of Tests (log scale)",
       y = "Expected False Positives (log scale)") +
  theme_minimal()
```

### Solutions

::: {.columns}
::: {.column width="50%"}
**Statistical Approaches:**

1. FDR Control
   - Less stringent
   - More power
   - Better for discovery

2. Hierarchical Methods
   - Group tests
   - Share information
   - Increase power
::::

::: {.column width="50%"}
**Practical Approaches:**

1. Pre-registration
   - Specify tests
   - Reduce flexibility
   - Increase transparency

2. Replication
   - Validate findings
   - Different contexts
   - Independent teams
::::
::::
::::

::: {.notes}
Key points about big data:

1. Scale creates new challenges
2. Traditional methods insufficient
3. Need new approaches
4. Balance discovery and rigor
::::

## The Power Problem {.smaller}

::: {.panel-tabset}

### Understanding Power

```{r power-viz}
#| fig-width: 10
#| fig-height: 6
#| echo: false

# Create visualization of power
x <- seq(-4, 6, length.out = 200)
null_dist <- dnorm(x, mean = 0, sd = 1)
alt_dist <- dnorm(x, mean = 2, sd = 1)

power_df <- data.frame(
  x = rep(x, 2),
  y = c(null_dist, alt_dist),
  dist = rep(c("Null", "Alternative"), each = length(x))
)

ggplot(power_df, aes(x = x, y = y, color = dist)) +
  geom_line(size = 1) +
  geom_vline(xintercept = qnorm(0.95), linetype = "dashed") +
  geom_area(data = subset(power_df, 
                         dist == "Alternative" & x > qnorm(0.95)),
            aes(x = x, y = y), fill = "green", alpha = 0.3) +
  labs(title = "Statistical Power Visualization",
       subtitle = "Green area shows power (probability of detecting true effect)",
       x = "Test Statistic",
       y = "Probability Density") +
  theme_minimal()
```

### Real World Impact

::: {.columns}
::: {.column width="50%"}
**Consequences:**

- Missed discoveries
- Wasted resources
- Biased literature
- Irreproducible results
::::

::: {.column width="50%"}
**Common Issues:**

- Small samples
- Small effects
- Noisy measures
- Complex designs
::::
::::

### Solutions

```{r power-solutions}
#| fig-width: 10
#| fig-height: 6
#| echo: false

# Create visualization of sample size vs power
n_seq <- seq(10, 200, by = 10)
effect_sizes <- c(0.2, 0.5, 0.8)
power_curves <- expand.grid(n = n_seq, d = effect_sizes)
power_curves$power <- mapply(function(n, d) {
  power.t.test(n = n, delta = d, sd = 1, 
               sig.level = 0.05, type = "two.sample")$power
}, power_curves$n, power_curves$d)

ggplot(power_curves, aes(x = n, y = power, color = factor(d))) +
  geom_line(size = 1) +
  geom_hline(yintercept = 0.8, linetype = "dashed") +
  labs(title = "Sample Size Needed for Different Effect Sizes",
       subtitle = "Dashed line shows conventional 80% power",
       x = "Sample Size per Group",
       y = "Statistical Power",
       color = "Effect Size") +
  theme_minimal()
```

::::

::: {.notes}
Key points about power:
1. Often overlooked
2. Critical for reproducibility
3. Requires planning
4. Trade-offs with resources
::::

## Future Directions {.smaller}

::: {.panel-tabset}

### Moving Beyond p-values

::: {.columns}
::: {.column width="50%"}
**Alternative Approaches:**

1. Effect Sizes
   - Standardized measures
   - Practical significance
   - Meta-analysis friendly

2. Confidence Intervals
   - Range of plausible values
   - Uncertainty visualization
   - Better interpretation
::::

::: {.column width="50%"}
**Modern Methods:**

1. Bayesian Analysis
   - Prior knowledge
   - Direct probabilities
   - Uncertainty quantification

2. Machine Learning
   - Cross-validation
   - Out-of-sample prediction
   - Model comparison
::::
::::

### Open Science Practices

::: {.columns}
::: {.column width="50%"}
**Transparency:**

- Pre-registration
- Open data
- Open code
- Detailed methods
::::

::: {.column width="50%"}
**Collaboration:**

- Multi-lab studies
- Replication projects
- Team science
- Peer review reform
::::
::::

### Practical Steps

```{dot}
digraph G {
  rankdir=LR;
  node [shape=box];
  
  plan [label="Planning\nPhase"];
  collect [label="Data\nCollection"];
  analyze [label="Analysis\nPhase"];
  report [label="Reporting\nPhase"];
  
  plan -> collect [label="Power\nAnalysis"];
  collect -> analyze [label="Quality\nControl"];
  analyze -> report [label="Multiple\nApproaches"];
  
  {rank=same; plan collect analyze report}
}
```

::::

::: {.notes}
Key points about future:
1. Multiple approaches needed
2. Transparency essential
3. Better training required
4. Systemic changes necessary
::::

## Recommended Reading {.smaller}

::: {.columns}
::: {.column width="50%"}
**Classic Papers:**

1. "The Earth is Round (p < .05)" Cohen (1994)
2. "Mindless Statistics" Gigerenzer (2004)
::::

::: {.column width="50%"}
**Modern Developments:**

1. ASA Statement on p-values (2016)
   - Official guidance
   - Common misunderstandings
   - Best practices

2. "Moving to a World Beyond p < 0.05"
   - Multiple papers
   - Practical solutions
   - Future directions
::::
::::

::: {.notes}
These readings provide:
1. Historical perspective
2. Current best practices
3. Future directions
4. Practical guidance
::::
