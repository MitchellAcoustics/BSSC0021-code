# - t-values and p-values for significance tests
# - R-squared and adjusted R-squared values
# - F-statistic and its p-value
# - Residual standard error
resid(model)
plot(model)
ggplot(model.diag.metrics, aes(studyTime, grades)) +
geom_point() +
stat_smooth(method = lm, se = FALSE) +
geom_segment(aes(xend = studyTime, yend = .fitted), color = "red", size = 0.3)
model.diag.metrics <- augment(model)
library(broom)
model.diag.metrics <- augment(model)
ggplot(model.diag.metrics, aes(studyTime, grades)) +
geom_point() +
stat_smooth(method = lm, se = FALSE) +
geom_segment(aes(xend = studyTime, yend = .fitted), color = "red", size = 0.3)
# Demonstrating regression to the mean
set.seed(42)
# Generate two correlated variables
n <- 1000
x <- rnorm(n)
y <- 0.7 * x + rnorm(n, 0, sqrt(1 - 0.7^2))
cor(x, y) # Should be around 0.7
# Identify extreme values in x
extreme_x <- abs(x) > 2
# Compare means of corresponding y values
mean(y[extreme_x]) # Closer to 0 than expected
mean(x[extreme_x]) # Should be around 2.2-2.3
# Visualization
plot(x, y,
col = ifelse(extreme_x, "red", "black"),
main = "Regression to the Mean"
)
abline(h = 0, v = 0, lty = 2)
# Reuse our simulated data
head(df)
##   studyTime    grades
## 1 0.2875775 71.67156
## 2 0.7883051 74.91224
## 3 0.4089769 72.59636
## 4 0.8830174 74.27857
## 5 0.9404673 75.06098
## 6 0.0455565 69.01599
# Fit the linear model
model <- lm(grades ~ studyTime, data = df)
# View model summary
summary(model)
# Visualize the regression line
ggplot(df, aes(x = studyTime, y = grades)) +
geom_point() +
geom_smooth(method = "lm", se = TRUE) +
labs(
title = "Linear Regression: Study Time vs. Grades",
x = "Study Time (hours)",
y = "Grades (%)"
) +
theme_minimal()
# Make predictions
new_data <- data.frame(studyTime = c(1, 3, 5))
predictions <- predict(model, new_data)
predictions
# Confidence intervals for predictions
predict(model, new_data, interval = "confidence")
# Prediction intervals
predict(model, new_data, interval = "prediction")
confint(model, level = 0.95)
##                   2.5 %    97.5 %
## (Intercept) 68.9376954 71.489689
## studyTime    4.5190811  5.465801
# Calculate standard error manually
residuals <- residuals(model)
RSS <- sum(residuals^2) # Residual Sum of Squares
n <- length(df$studyTime)
x_dev_squared <- sum((df$studyTime - mean(df$studyTime))^2)
# SE formula
se_beta1 <- sqrt(RSS / (n - 2) / x_dev_squared)
print(paste(
"SE of slope (manual):",
round(se_beta1, 4)
))
# Compare with lm() output
summary_model <- summary(model)
se_from_lm <- summary_model$coefficients[2, 2]
print(paste(
"SE of slope (lm):",
round(se_from_lm, 4)
))
# Calculate confidence intervals for coefficients
conf_intervals <- confint(model, level = 0.95)
print(conf_intervals)
# For our studyTime coefficient:
# 2.5%: 4.52
# 97.5%: 5.47
# Visualizing the uncertainty in the slope
ggplot(df, aes(x = studyTime, y = grades)) +
geom_point() +
geom_smooth(method = "lm", se = TRUE) +
geom_abline(
slope = conf_intervals[2, 1], # Lower bound
intercept = confint(model)[1, 1],
linetype = "dashed", color = "blue"
) +
geom_abline(
slope = conf_intervals[2, 2], # Upper bound
intercept = confint(model)[1, 2],
linetype = "dashed", color = "blue"
) +
labs(title = "Uncertainty in Regression Line") +
theme_minimal()
# Generate all four diagnostic plots
par(mfrow = c(2, 2))
plot(model)
# Alternative: individual plots
plot(model, which = 1) # Residuals vs Fitted
plot(model, which = 2) # Normal Q-Q
plot(model, which = 3) # Scale-Location
plot(model, which = 4) # Residuals vs Leverage
# Check specific diagnostics
# Normality test for residuals
shapiro.test(residuals(model))
# Breusch-Pagan test for homoscedasticity
library(lmtest)
bptest(model)
# Durbin-Watson test for autocorrelation
dwtest(model)
# Testing for linearity
# Add a quadratic term and test significance
quad_model <- lm(grades ~ studyTime + I(studyTime^2),
data = df
)
summary(quad_model)
# Testing for homoscedasticity
library(lmtest)
bptest(model)
# Testing for normality of residuals
shapiro.test(residuals(model))
# Identifying influential observations
plot(model, which = 4)
influence.measures(model)
# Plot residuals against predictors
plot(df$studyTime, residuals(model),
xlab = "Study Time", ylab = "Residuals",
main = "Residuals vs. Study Time"
)
abline(h = 0, lty = 2)
# Standardize variables
df$z_studyTime <- scale(df$studyTime)
df$z_grades <- scale(df$grades)
# Fit model with standardized variables
std_model <- lm(z_grades ~ z_studyTime, data = df)
summary(std_model)
# Get mean values of x and y
mean_x <- mean(df$studyTime)
mean_y <- mean(df$grades)
# Get coefficient estimates
coef_est <- coef(model)
# Plot with improved confidence bounds for slope
ggplot(df, aes(x = studyTime, y = grades)) +
geom_point() +
geom_smooth(method = "lm", se = TRUE) +
geom_abline(
slope = conf_intervals[2, 1], # Lower bound of slope
intercept = mean_y - conf_intervals[2, 1] * mean_x, # Adjusted intercept
linetype = "dashed", color = "blue"
) +
geom_abline(
slope = conf_intervals[2, 2], # Upper bound of slope
intercept = mean_y - conf_intervals[2, 2] * mean_x, # Adjusted intercept
linetype = "dashed", color = "blue"
) +
labs(title = "Uncertainty in Regression Line") +
theme_minimal()
#| echo: false
#| message: false
#| warning: false
library(tidyverse)
library(haven)
library(knitr)
library(broom)
library(ggplot2)
library(gtsummary)
library(cowplot)
library(gridExtra)
library(hrbrthemes)
library(effectsize)
library(emmeans)
# Load the fuel consumption dataset
load("data/dataset-canada-fuel-2015-subset1.Rdata")
# Set common options
knitr::opts_chunk$set(dev = "ragg_png")
pdf.options(encoding = "CP1250")
View(data)
View(data)
#| echo: false
#| message: false
#| warning: false
library(tidyverse)
library(haven)
library(knitr)
library(broom)
library(ggplot2)
library(gtsummary)
library(cowplot)
library(gridExtra)
library(hrbrthemes)
library(effectsize)
library(emmeans)
# Load the fuel consumption dataset
load("data/dataset-canada-fuel-2015-subset1.Rdata")
fuel_data <- data
# Set common options
knitr::opts_chunk$set(dev = "ragg_png")
pdf.options(encoding = "CP1250")
# View the structure of the fuel consumption dataset
fuel_data |>
select(make, model, class, enginesize, cylinder468, fueluseboth) |>
head(5) |>
kable()
# View the structure of the fuel consumption dataset
fuel_data |>
select(make, model, class, enginesize, cylinders468, fueluseboth) |>
head(5) |>
kable()
# Run traditional ANOVA
anova_result <- aov(fueluseboth ~ class, data = fuel_data)
summary(anova_result)
# Run equivalent linear model
lm_result <- lm(fueluseboth ~ class, data = fuel_data)
anova(lm_result)
# View coefficients from the linear model
tidy(lm_result) |>
kable(digits = 3)
# Create a visualization of group means
ggplot(fuel_data, aes(x = class, y = fueluseboth)) +
geom_boxplot(fill = "lightblue") +
geom_point(position = position_jitter(width = 0.2), alpha = 0.3) +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
labs(x = "Vehicle Class", y = "Fuel Consumption (L/100km)",
title = "Fuel Consumption by Vehicle Class")
# Create a simplified cylinder factor
fuel_data <- fuel_data |>
mutate(cyl_factor = factor(case_when(
cylinders468 <= 4 ~ "4 or fewer",
cylinders468 == 6 ~ "6",
cylinders468 >= 8 ~ "8 or more"
)))
# Run two-way ANOVA
two_way_model <- lm(fueluseboth ~ class + cyl_factor, data = fuel_data)
anova(two_way_model)
# Run two-way ANOVA with interaction
interaction_model <- lm(fueluseboth ~ class * cyl_factor, data = fuel_data)
anova(interaction_model)
# Create an interaction plot
ggplot(fuel_data, aes(x = class, y = fueluseboth, fill = cyl_factor)) +
stat_summary(fun = mean, geom = "bar", position = "dodge") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
labs(x = "Vehicle Class", y = "Average Fuel Consumption (L/100km)",
fill = "Cylinders",
title = "Interaction between Vehicle Class and Engine Cylinders")
# Run ANCOVA
ancova_model <- lm(fueluseboth ~ class + enginesize, data = fuel_data)
summary(ancova_model)
# Calculate effect sizes
eta_squared(anova_result)
# Calculate estimated marginal means
emm <- emmeans(lm_result, ~ class)
# Pairwise comparisons with Tukey adjustment
pairs(emm) |>
as_tibble() |>
filter(p.value < 0.05) |>
arrange(p.value) |>
head(5) |>
kable(digits = 3)
# Load HR Analytics dataset if not already loaded
if (!exists("hr_data")) {
hr_data <- read_sav("data/dataset-abc-insurance-hr-data.sav")
}
# Run ANOVA for job satisfaction by department
hr_anova <- lm(jobsat ~ dept, data = hr_data)
#| echo: false
#| message: false
#| warning: false
library(tidyverse)
library(haven)
library(knitr)
library(broom)
library(ggplot2)
library(gtsummary)
library(cowplot)
library(gridExtra)
library(hrbrthemes)
library(effectsize)
library(emmeans)
# Load the fuel consumption dataset
load("data/dataset-canada-fuel-2015-subset1.Rdata")
fuel_data <- data
# Set common options
knitr::opts_chunk$set(dev = "ragg_png")
pdf.options(encoding = "CP1250")
# View the structure of the fuel consumption dataset
fuel_data |>
select(make, model, class, enginesize, cylinders468, fueluseboth) |>
head(5) |>
kable()
# Run traditional ANOVA
anova_result <- aov(fueluseboth ~ class, data = fuel_data)
summary(anova_result)
# Run equivalent linear model
lm_result <- lm(fueluseboth ~ class, data = fuel_data)
anova(lm_result)
# View coefficients from the linear model
tidy(lm_result) |>
kable(digits = 3)
# Create a visualization of group means
ggplot(fuel_data, aes(x = class, y = fueluseboth)) +
geom_boxplot(fill = "lightblue") +
geom_point(position = position_jitter(width = 0.2), alpha = 0.3) +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
labs(x = "Vehicle Class", y = "Fuel Consumption (L/100km)",
title = "Fuel Consumption by Vehicle Class")
# Create a simplified cylinder factor
fuel_data <- fuel_data |>
mutate(cyl_factor = factor(case_when(
cylinders468 <= 4 ~ "4 or fewer",
cylinders468 == 6 ~ "6",
cylinders468 >= 8 ~ "8 or more"
)))
# Run two-way ANOVA
two_way_model <- lm(fueluseboth ~ class + cyl_factor, data = fuel_data)
anova(two_way_model)
# Run two-way ANOVA with interaction
interaction_model <- lm(fueluseboth ~ class * cyl_factor, data = fuel_data)
anova(interaction_model)
# Create an interaction plot
ggplot(fuel_data, aes(x = class, y = fueluseboth, fill = cyl_factor)) +
stat_summary(fun = mean, geom = "bar", position = "dodge") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
labs(x = "Vehicle Class", y = "Average Fuel Consumption (L/100km)",
fill = "Cylinders",
title = "Interaction between Vehicle Class and Engine Cylinders")
# Run ANCOVA
ancova_model <- lm(fueluseboth ~ class + enginesize, data = fuel_data)
summary(ancova_model)
# Calculate effect sizes
eta_squared(anova_result)
# Calculate estimated marginal means
emm <- emmeans(lm_result, ~ class)
# Pairwise comparisons with Tukey adjustment
pairs(emm) |>
as_tibble() |>
filter(p.value < 0.05) |>
arrange(p.value) |>
head(5) |>
kable(digits = 3)
# Load HR Analytics dataset if not already loaded
if (!exists("hr_data")) {
hr_data <- read_sav("data/dataset-abc-insurance-hr-data.sav") |> janitor::clean_names()
}
# Run ANOVA for job satisfaction by department
hr_anova <- lm(jobsat ~ dept, data = hr_data)
View(hr_data)
#| echo: false
#| message: false
#| warning: false
library(tidyverse)
library(haven)
library(knitr)
library(broom)
library(ggplot2)
library(gtsummary)
library(cowplot)
library(gridExtra)
library(hrbrthemes)
# Set common options
knitr::opts_chunk$set(dev = "ragg_png")
pdf.options(encoding = "CP1250")
# Create example data
set.seed(123)
y <- rnorm(20, mean = 5, sd = 2)
# Traditional t-test
t_test_result <- t.test(y, mu = 0)
# Same test as linear model
lm_result <- lm(y ~ 1)
# Compare results
t_test_result$estimate  # Mean
coef(lm_result)[1]      # Intercept (β₀)
# Same t-statistic
t_test_result$statistic
summary(lm_result)$coefficients[1, 3]
# Example data for two groups
set.seed(123)
group <- factor(rep(c("A", "B"), each = 10))
y_grouped <- c(rnorm(10, mean = 5, sd = 2),
rnorm(10, mean = 7, sd = 2))
data <- data.frame(y = y_grouped, group = group)
# Traditional t-test
t_test_grouped <- t.test(y ~ group, data = data,
var.equal = TRUE)
# Same test as linear model
lm_grouped <- lm(y ~ group, data = data)
summary(lm_grouped)$coefficients
# Example data with continuous predictors
set.seed(456)
x1 <- rnorm(20, mean = 50, sd = 10)
x2 <- rnorm(20, mean = 100, sd = 15)
y_multi <- 10 + 0.5*x1 + 0.3*x2 + rnorm(20, 0, 5)
multi_data <- data.frame(y = y_multi, x1 = x1, x2 = x2)
# Multiple regression model
multi_model <- lm(y ~ x1 + x2, data = multi_data)
summary(multi_model)$coefficients
# Load HR Analytics dataset
hr_data <- read_sav("data/dataset-abc-insurance-hr-data.sav") |> janitor::clean_names()
# View the structure of the dataset
hr_data |>
head(5) |>
kable()
# Load HR Analytics dataset if not already loaded
if (!exists("hr_data")) {
hr_data <- read_sav("data/dataset-abc-insurance-hr-data.sav") |> janitor::clean_names()
}
# Run ANOVA for job satisfaction by department
hr_anova <- lm(job_satisfaction ~ job_role, data = hr_data)
summary(hr_anova)
# Create a visualization of satisfaction by department
ggplot(hr_data, aes(x = reorder(job_roles, job_satisfaction, FUN = mean),
y = job_satisfaction)) +
geom_boxplot(fill = "lightgreen") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
labs(x = "Role", y = "Job Satisfaction (1-5 scale)",
title = "Job Satisfaction by Role")
# Create a visualization of satisfaction by department
ggplot(hr_data, aes(x = reorder(job_role, job_satisfaction, FUN = mean),
y = job_satisfaction)) +
geom_boxplot(fill = "lightgreen") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
labs(x = "Role", y = "Job Satisfaction (1-5 scale)",
title = "Job Satisfaction by Role")
# Build a complex model
complex_model <- lm(job_satisfaction ~ job_role + gender + evaluation +
job_role:evaluation, data = hr_data)
# View model summary
anova(complex_model) |>
as_tibble() |>
kable(digits = 3)
#| echo: false
#| message: false
#| warning: false
library(tidyverse)
library(haven)
library(knitr)
library(broom)
library(ggplot2)
library(gtsummary)
library(cowplot)
library(gridExtra)
library(hrbrthemes)
# Set common options
knitr::opts_chunk$set(dev = "ragg_png")
pdf.options(encoding = "CP1250")
# Create example data
set.seed(123)
y <- rnorm(20, mean = 5, sd = 2)
#| echo: true
# Traditional t-test
t_test_result <- t.test(y, mu = 0)
# Same test as linear model
lm_result <- lm(y ~ 1)
# Compare results
# t_test_result$estimate # Mean
# coef(lm_result)[1] # Intercept (β₀)
#
# # Same t-statistic
# t_test_result$statistic
summary(lm_result)$coefficients[1, 3]
# Compare results
# t_test_result$estimate # Mean
coef(lm_result)[1] # Intercept (β₀)
#
# # Same t-statistic
# t_test_result$statistic
# summary(lm_result)$coefficients[1, 3]
# Compare results
# t_test_result$estimate # Mean
# coef(lm_result)[1] # Intercept (β₀)
#
# # Same t-statistic
# t_test_result$statistic
# summary(lm_result)$coefficients[1, 3]
lm_result
# Compare results
# t_test_result$estimate # Mean
# coef(lm_result)[1] # Intercept (β₀)
#
# # Same t-statistic
# t_test_result$statistic
# summary(lm_result)$coefficients[1, 3]
summary(lm_result)
# Compare results
# t_test_result$estimate # Mean
# coef(lm_result)[1] # Intercept (β₀)
#
# # Same t-statistic
# t_test_result$statistic
# summary(lm_result)$coefficients[1, 3]
summary(lm_result)$coefficients
