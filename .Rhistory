# Calculate the mean and test value
mean_score <- mean(test_scores)
test_value <- 65
# Plot
ggplot(test_data, aes(x = index, y = score)) +
# Add jittered points
geom_jitter(width = 0.2, alpha = 0.6, color = "steelblue", size = 3) +
# Add actual mean line
geom_hline(yintercept = mean_score, color = "darkred", size = 1.5) +
# Add test value line
geom_hline(yintercept = test_value, color = "darkgreen", linetype = "dashed", size = 1.5) +
# Add annotations
annotate("text",
x = 1.1, y = mean_score + 3,
label = paste("Sample Mean =", round(mean_score, 1), "(β0)"),
color = "darkred", size = 5
) +
annotate("text",
x = 1.1, y = test_value - 3,
label = paste("Test Value =", test_value),
color = "darkgreen", size = 5
) +
# Format
theme_minimal() +
theme(
axis.text.x = element_blank(),
axis.title.x = element_blank()
) +
labs(
title = "One-Sample t-test as Linear Model",
subtitle = TeX("$y = 70.7 + \\epsilon = \\beta_0 + \\epsilon$"),
y = "Test Score"
)
# Create data for independent t-test example
set.seed(123)
group_data <- data.frame(
group = factor(rep(c("Group A", "Group B"), each = 15)),
score = c(rnorm(15, mean = 65, sd = 8), rnorm(15, mean = 75, sd = 8))
)
# Calculate group means
mean_A <- mean(group_data$score[group_data$group == "Group A"])
mean_B <- mean(group_data$score[group_data$group == "Group B"])
diff <- mean_B - mean_A
# Plot
ggplot(group_data, aes(x = group, y = score, color = group)) +
# Add jittered points
geom_jitter(width = 0.2, alpha = 0.7, size = 3) +
# Add group means
stat_summary(fun = mean, geom = "point", size = 5, shape = 18) +
stat_summary(
fun = mean, geom = "errorbar",
aes(ymax = after_stat(y), ymin = after_stat(y)), width = 0.3, linewidth = 1.5
) +
# Add annotations
annotate("text",
x = 1, y = mean_A - 5,
label = expression(beta[0] ~ "(Group A mean)"), color = "#F8766D", size = 5
) +
annotate("segment",
x = 1.1, xend = 1.9,
y = mean_A + 5,
yend = mean_A + 5,
arrow = arrow(length = unit(0.3, "cm")), color = "#00BFC4"
) +
annotate("text",
x = 1.5, y = mean_A + 8,
label = expression(beta[1] ~ "(difference)"), color = "#00BFC4", size = 5
) +
# Format
theme_minimal() +
scale_color_brewer(palette = "Set1") +
theme(legend.position = "none") +
labs(
title = "Independent t-test as Linear Model",
subtitle = TeX("$y = 6.8 * x + \\epsilon = \\beta_1 * x + \\epsilon$"),
x = "Group",
y = "Score"
)
# Create data for dummy coding visualization
dummy_data <- data.frame(
Category = factor(rep(c("A", "B", "C"), each = 10)),
Value = c(rnorm(10, 10, 2), rnorm(10, 15, 2), rnorm(10, 12, 2))
)
# Create dummy variables
dummy_data$B_dummy <- ifelse(dummy_data$Category == "B", 1, 0)
dummy_data$C_dummy <- ifelse(dummy_data$Category == "C", 1, 0)
# Calculate means
means <- tapply(dummy_data$Value, dummy_data$Category, mean)
# Create a visualization of dummy coding
ggplot(dummy_data, aes(x = Category, y = Value, color = Category)) +
# Add jittered points
geom_jitter(width = 0.2, alpha = 0.7, size = 3) +
# Add means
stat_summary(fun = mean, geom = "point", size = 5, shape = 18) +
stat_summary(
fun = mean, geom = "errorbar",
aes(ymax = after_stat(y), ymin = after_stat(y)), width = 0.3, linewidth = 1.5
) +
# Add annotations
annotate("text",
x = 1, y = means["A"] - 2,
label = expression(beta[0] ~ "(reference group mean)"), color = "#F8766D", size = 4.5
) +
annotate("text",
x = 2, y = means["B"] + 2,
label = expression(beta[1] ~ "(difference from reference)"), color = "#00BA38", size = 4.5
) +
annotate("text",
x = 3, y = means["C"] + 2,
label = expression(beta[2] ~ "(difference from reference)"), color = "#619CFF", size = 4.5
) +
# Format
theme_minimal() +
theme(legend.position = "none") +
labs(
title = "Dummy Coding of Categorical Variables",
subtitle = "Creating numeric indicators for linear models",
x = "Category",
y = "Value"
)
# Create data for ANOVA example
set.seed(42)
anova_data <- data.frame(
group = factor(rep(c("Method A", "Method B", "Method C", "Method D"), each = 10)),
score = c(
rnorm(10, mean = 65, sd = 8),
rnorm(10, mean = 70, sd = 8),
rnorm(10, mean = 75, sd = 8),
rnorm(10, mean = 72, sd = 8)
)
)
# Calculate means for annotations
means <- tapply(anova_data$score, anova_data$group, mean)
# Plot
ggplot(anova_data, aes(x = group, y = score, fill = group)) +
# Add boxplots
geom_boxplot(alpha = 0.7) +
# Add jittered points
geom_jitter(width = 0.2, alpha = 0.6, color = "darkblue") +
# Add annotations
annotate("text",
x = 1, y = max(anova_data$score) + 5,
label = expression(beta[0] ~ "(reference group mean)"), color = "black", size = 4
) +
annotate("text",
x = 2, y = max(anova_data$score) + 5,
label = expression(beta[1] ~ "(difference)"), color = "black", size = 4
) +
annotate("text",
x = 3, y = max(anova_data$score) + 5,
label = expression(beta[2] ~ "(difference)"), color = "black", size = 4
) +
annotate("text",
x = 4, y = max(anova_data$score) + 5,
label = expression(beta[3] ~ "(difference)"), color = "black", size = 4
) +
# Add arrows pointing to means
annotate("segment",
x = 1, xend = 1,
y = max(anova_data$score) + 4, yend = means["Method A"] + 5,
arrow = arrow(length = unit(0.2, "cm"))
) +
annotate("segment",
x = 2, xend = 2,
y = max(anova_data$score) + 4, yend = means["Method B"] + 5,
arrow = arrow(length = unit(0.2, "cm"))
) +
annotate("segment",
x = 3, xend = 3,
y = max(anova_data$score) + 4, yend = means["Method C"] + 5,
arrow = arrow(length = unit(0.2, "cm"))
) +
annotate("segment",
x = 4, xend = 4,
y = max(anova_data$score) + 4, yend = means["Method D"] + 5,
arrow = arrow(length = unit(0.2, "cm"))
) +
# Format
theme_minimal() +
theme(legend.position = "none") +
scale_fill_brewer(palette = "Pastel1") +
labs(
title = "ANOVA as Linear Model",
subtitle = "Comparing means across multiple groups",
x = "Teaching Method",
y = "Test Score"
) +
coord_cartesian(ylim = c(min(anova_data$score) - 5, max(anova_data$score) + 10))
# Create data for regression example
set.seed(42)
study_hours <- runif(50, 1, 10)
previous_grades <- rnorm(50, mean = 70, sd = 10)
test_score <- 40 + 3 * study_hours + 0.3 * previous_grades + rnorm(50, 0, 5)
regression_data <- data.frame(
study_hours = study_hours,
previous_grades = previous_grades,
test_score = test_score
)
# Create 3D scatter plot with plotly
library(plotly)
plot_ly(regression_data,
x = ~study_hours, y = ~previous_grades, z = ~test_score,
marker = list(size = 5, color = "blue", opacity = 0.6)
) %>%
add_markers() %>%
layout(
title = "Multiple Regression Model",
scene = list(
xaxis = list(title = "Study Hours"),
yaxis = list(title = "Previous Grades"),
zaxis = list(title = "Test Score")
)
)
tests_table <- tibble(
Test = c("One-sample t-test", "Independent t-test", "One-way ANOVA", "Multiple regression"),
`Linear Model` = c("y ~ 1", "y ~ group", "y ~ group", "y ~ x1 + x2 + ..."),
`What's being tested` = c("Is the intercept equal to a specific value?", "Is there a difference between groups?", "Are there differences between any groups?", "Do the predictors affect the outcome?")
)
knitr::kable(tests_table)
#| echo: false
#| message: false
# Load the HR dataset
hr_data <- read_sav("data/dataset-abc-insurance-hr-data.sav") %>%
janitor::clean_names() %>%
mutate(
gender = factor(gender, levels = 1:2, labels = c("Female", "Male")),
job_role = factor(job_role)
)
#| echo: true
# Traditional one-sample t-test
t.test(hr_data$tenure, mu = 5.0)
# Same test as linear model
summary(lm(tenure - 5.0 ~ 1, data = hr_data))
#| echo: true
# Traditional independent t-test
t.test(intentionto_quit ~ gender, data = hr_data, var.equal = TRUE)
# Same test as linear model
summary(lm(intentionto_quit ~ gender, data = hr_data))
#| echo: true
# Traditional ANOVA
summary(aov(intentionto_quit ~ job_role, data = hr_data))
# Same test as linear model
anova(lm(intentionto_quit ~ job_role, data = hr_data))
#| echo: true
# Multiple regression model
salary_model <- lm(salarygrade ~ gender + tenure + evaluation,
data = hr_data
)
summary(salary_model)
#| echo: true
# Multiple regression model
salary_model <- lm(intentionto_quit ~ gender + tenure + evaluation,
data = hr_data
)
summary(salary_model)
#| echo: false
# Create visualizations of the regression relationships
p1 <- ggplot(hr_data, aes(x = tenure, y = intentionto_quit, color = gender)) +
geom_point(alpha = 0.3) +
geom_smooth(method = "lm", se = FALSE) +
theme_minimal() +
labs(
title = "Experience and Intention by Gender",
x = "Years of Experience",
y = "Intention to Quit"
) +
scale_color_manual(values = c("Female" = "#FF9999", "Male" = "#6699CC"))
p2 <- ggplot(hr_data, aes(x = evaluation, y = intentionto_quit, color = gender)) +
geom_point(alpha = 0.3) +
geom_smooth(method = "lm", se = FALSE) +
theme_minimal() +
labs(
title = "Performance and Intention by Gender",
x = "Performance Rating",
y = "Intention to Quit"
) +
scale_color_manual(values = c("Female" = "#FF9999", "Male" = "#6699CC"))
p1 + p2
#| echo: true
# Multiple regression model
salary_model <- lm(intentionto_quit ~ gender + tenure + evaluation + salary_grade,
data = hr_data
)
#| echo: true
# Multiple regression model
salary_model <- lm(intentionto_quit ~ gender + tenure + evaluation + salarygrade,
data = hr_data
)
summary(salary_model)
#| echo: true
# Multiple regression model
quit_model <- lm(intentionto_quit ~ gender + tenure + evaluation,
data = hr_data
)
summary(quit_model)
#| echo: true
# Multiple regression model
quit_model <- lm(intentionto_quit ~ gender + tenure + evaluation + salarygrade,
data = hr_data
)
summary(quit_model)
#| echo: false
# Create visualizations of the regression relationships
p1 <- ggplot(hr_data, aes(x = tenure, y = intentionto_quit, color = gender)) +
geom_point(alpha = 0.3) +
geom_smooth(method = "lm", se = FALSE) +
theme_minimal() +
labs(
title = "Experience and Intention by Gender",
x = "Years of Experience",
y = "Intention to Quit"
) +
scale_color_manual(values = c("Female" = "#FF9999", "Male" = "#6699CC"))
p2 <- ggplot(hr_data, aes(x = evaluation, y = intentionto_quit, color = gender)) +
geom_point(alpha = 0.3) +
geom_smooth(method = "lm", se = FALSE) +
theme_minimal() +
labs(
title = "Performance and Intention by Gender",
x = "Performance Rating",
y = "Intention to Quit"
) +
scale_color_manual(values = c("Female" = "#FF9999", "Male" = "#6699CC"))
p1 + p2
# Create data for ANCOVA visualization
set.seed(123)
ancova_data <- data.frame(
group = rep(c("Group A", "Group B", "Group C"), each = 30),
x = runif(90, 0, 10),
y = numeric(90)
)
# Generate y values with different intercepts but same slope
ancova_data$y[ancova_data$group == "Group A"] <-
5 + 2 * ancova_data$x[ancova_data$group == "Group A"] + rnorm(30, 0, 2)
ancova_data$y[ancova_data$group == "Group B"] <-
10 + 2 * ancova_data$x[ancova_data$group == "Group B"] + rnorm(30, 0, 2)
ancova_data$y[ancova_data$group == "Group C"] <-
7 + 2 * ancova_data$x[ancova_data$group == "Group C"] + rnorm(30, 0, 2)
# Plot
ggplot(ancova_data, aes(x = x, y = y, color = group)) +
geom_point(alpha = 0.6) +
geom_smooth(method = "lm", se = FALSE, linewidth = 1.5) +
theme_minimal() +
labs(
title = "ANCOVA: Combining Categorical and Continuous",
subtitle = "Different intercepts (group effects) with same slope (x effect)",
x = "Continuous Predictor",
y = "Outcome"
) +
scale_color_brewer(palette = "Set1")
#| echo: true
# Traditional independent t-test
t.test(intentionto_quit ~ gender, data = hr_data, var.equal = TRUE)
# Same test as linear model
summary(lm(intentionto_quit ~ gender, data = hr_data))
#| echo: true
# Traditional independent t-test
t.test(intentionto_quit ~ gender, data = hr_data, var.equal = TRUE)
# Same test as linear model
summary(lm(intentionto_quit ~ 0 + gender, data = hr_data))
#| echo: true
# Traditional independent t-test
t.test(intentionto_quit ~ gender, data = hr_data, var.equal = TRUE)
# Same test as linear model
summary(lm(intentionto_quit ~ gender, data = hr_data))
#| echo: false
#| message: false
#| warning: false
library(tidyverse)
library(haven)
library(knitr)
library(broom)
library(ggplot2)
library(gtsummary)
library(cowplot)
library(gridExtra)
library(hrbrthemes)
library(patchwork) # For combining plots
library(latex2exp)
library(webshot2)
# Set common options
knitr::opts_chunk$set(dev = "ragg_png")
pdf.options(encoding = "CP1250")
# Create example data
set.seed(123)
x <- seq(1, 10, length.out = 20)
y <- 2 + 0.5 * x + rnorm(20, 0, 1)
df <- data.frame(x = x, y = y)
# Fit a model to get the intercept and slope
model <- lm(y ~ x, data = df)
intercept <- coef(model)[1]
slope <- coef(model)[2]
# Plot
ggplot(df, aes(x, y)) +
# Add data points
geom_point(size = 3, color = "steelblue") +
# Add the regression line
geom_abline(intercept = intercept, slope = slope, color = "darkred", size = 1.5) +
# Add error bars for a few points
geom_segment(
data = df[c(5, 10, 15), ],
aes(x = x, y = y, xend = x, yend = predict(model)[c(5, 10, 15)]),
color = "gray50", linetype = "dashed"
) +
# Add annotations
annotate("text",
x = 2, y = 2, label = expression(beta[0] ~ "(intercept)"),
color = "darkred", size = 5, hjust = 0
) +
annotate("text",
x = 8, y = 6.5, label = expression(beta[1] ~ "(slope)"),
color = "darkred", size = 5
) +
annotate("text",
x = 9.5, y = 3.5, label = expression(epsilon ~ "(error)"),
color = "gray50", size = 5
) +
# Add an arrow for the slope
annotate("segment",
x = 7, xend = 9, y = 6, yend = 7,
arrow = arrow(length = unit(0.3, "cm")), color = "darkred"
) +
# Format the plot
theme_minimal() +
labs(
title = "Components of the General Linear Model",
x = "Predictor (x)",
y = "Outcome (y)"
)
# Create data for simple regression
set.seed(123)
experience <- runif(40, 1, 20)
salary <- 30000 + 2500 * experience + rnorm(40, 0, 10000)
simple_data <- data.frame(experience = experience, salary = salary)
# Fit model
simple_model <- lm(salary ~ experience, data = simple_data)
# Create plot
ggplot(simple_data, aes(x = experience, y = salary)) +
geom_point(color = "steelblue", alpha = 0.7) +
geom_smooth(method = "lm", color = "darkred") +
theme_minimal() +
labs(
title = "Simple Linear Regression",
x = "Years of Experience",
y = "Salary ($)",
subtitle = paste("Slope (β₁):", round(coef(simple_model)[2]))
) +
annotate("text",
x = 5, y = 30000,
label = paste("β₀ =", round(coef(simple_model)[1])),
color = "darkred", size = 4
)
# Create data for multiple regression
set.seed(456)
performance <- runif(40, 2, 5)
salary_multi <- 20000 + 2000 * experience + 8000 * performance + rnorm(40, 0, 8000)
multi_data <- data.frame(
experience = experience,
performance = performance,
salary = salary_multi
)
# Fit model
multi_model <- lm(salary ~ experience + performance, data = multi_data)
# Create 3D scatterplot
library(plotly)
plot_ly(multi_data,
x = ~experience,
y = ~performance,
z = ~salary,
marker = list(size = 5, color = "steelblue", opacity = 0.8)
) |>
add_markers() |>
add_surface(
x = seq(min(multi_data$experience), max(multi_data$experience), length.out = 10),
y = seq(min(multi_data$performance), max(multi_data$performance), length.out = 10),
z = outer(
seq(min(multi_data$experience), max(multi_data$experience), length.out = 10),
seq(min(multi_data$performance), max(multi_data$performance), length.out = 10),
function(exp, perf) coef(multi_model)[1] + coef(multi_model)[2] * exp + coef(multi_model)[3] * perf
),
opacity = 0.7,
colorscale = "Reds"
) |>
layout(
title = "Multiple Regression",
scene = list(
xaxis = list(title = "Experience"),
yaxis = list(title = "Performance"),
zaxis = list(title = "Salary")
)
)
# Example with multiple predictors using HR data
hr_data <- read_sav("data/dataset-abc-insurance-hr-data.sav") |>
janitor::clean_names() |>
mutate(gender = factor(gender, levels = 1:2, labels = c("Female", "Male")))
# Build model with multiple predictors
full_model <- lm(
salarygrade ~ gender + tenure +
evaluation + age + job_satisfaction,
data = hr_data
)
# Display coefficient summary
summary(full_model)$coefficients |>
as.data.frame() |>
rownames_to_column(var = "Predictor") |>
select(Predictor, Estimate, `Pr(>|t|)`) |>
knitr::kable(
digits = 3,
col.names = c("Predictor", "Effect on Salary", "p-value")
)
summary(full_model)
hr_data
