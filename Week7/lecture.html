<!DOCTYPE html>
<html lang="en"><head>
<link href="../assets/stat_bear.png" rel="icon" type="image/png">
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-html/tabby.min.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.6.40">

  <meta name="author" content="Dr Andrew Mitchell">
  <title>BSSC0021 – Multiple Linear Regression and ANOVA as Linear Models</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      { color: #003b4f; background-color: #f1f3f5; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #003b4f; } /* Normal */
    code span.al { color: #ad0000; } /* Alert */
    code span.an { color: #5e5e5e; } /* Annotation */
    code span.at { color: #657422; } /* Attribute */
    code span.bn { color: #ad0000; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #003b4f; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #20794d; } /* Char */
    code span.cn { color: #8f5902; } /* Constant */
    code span.co { color: #5e5e5e; } /* Comment */
    code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
    code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
    code span.dt { color: #ad0000; } /* DataType */
    code span.dv { color: #ad0000; } /* DecVal */
    code span.er { color: #ad0000; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #ad0000; } /* Float */
    code span.fu { color: #4758ab; } /* Function */
    code span.im { color: #00769e; } /* Import */
    code span.in { color: #5e5e5e; } /* Information */
    code span.kw { color: #003b4f; font-weight: bold; } /* Keyword */
    code span.op { color: #5e5e5e; } /* Operator */
    code span.ot { color: #003b4f; } /* Other */
    code span.pp { color: #ad0000; } /* Preprocessor */
    code span.sc { color: #5e5e5e; } /* SpecialChar */
    code span.ss { color: #20794d; } /* SpecialString */
    code span.st { color: #20794d; } /* String */
    code span.va { color: #111111; } /* Variable */
    code span.vs { color: #20794d; } /* VerbatimString */
    code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
    /* CSS for citations */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
      margin-bottom: 0em;
    }
    .hanging-indent div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }  </style>
  <link rel="stylesheet" href="../site_libs/revealjs/dist/theme/quarto-ed3ab02270332a7a204096c38dcfffc3.css">
  <link href="../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
  <link href="../site_libs/htmltools-fill-0.5.8.1/fill.css" rel="stylesheet">
  <script src="../site_libs/htmlwidgets-1.6.4/htmlwidgets.js"></script>
  <script src="../site_libs/plotly-binding-4.10.4/plotly.js"></script>
  <script src="../site_libs/typedarray-0.1/typedarray.min.js"></script>
  <script src="../site_libs/jquery-3.5.1/jquery.min.js"></script>
  <link href="../site_libs/crosstalk-1.2.1/css/crosstalk.min.css" rel="stylesheet">
  <script src="../site_libs/crosstalk-1.2.1/js/crosstalk.min.js"></script>
  <link href="../site_libs/plotly-htmlwidgets-css-2.11.1/plotly-htmlwidgets.css" rel="stylesheet">
  <script src="../site_libs/plotly-main-2.11.1/plotly-latest.min.js"></script>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" data-background-image="https://stat20.berkeley.edu/fall-2024/2-summarizing-data/03-a-grammar-of-graphics/images/plot-collage.png" data-background-position="right 0% bottom 50%" data-background-size="50%" class="quarto-title-block center">
  <h1 class="title"><p>Multiple Linear Regression<br>
and ANOVA as Linear Models</p></h1>
  <p class="subtitle">Unifying Statistical Approaches</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Dr Andrew Mitchell <a href="https://orcid.org/0000-0003-0978-5046" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a>
</div>
<div class="quarto-title-author-email">
<a href="mailto:a.j.mitchell@ucl.ac.uk">a.j.mitchell@ucl.ac.uk</a>
</div>
        <p class="quarto-title-affiliation">
            Lecturer in AI and Machine Learning for Sustainable Construction
          </p>
    </div>
</div>

</section>
<section id="last-week" class="slide level2">
<h2>Last Week</h2>
<ul>
<li class="fragment">Correlation
<ul>
<li class="fragment">Pearson correlation (<span class="math inline">\(r\)</span>)</li>
<li class="fragment">Spearman correlation (<span class="math inline">\(\rho\)</span>)</li>
<li class="fragment">Relationship to linear regression</li>
<li class="fragment">Limitations</li>
</ul></li>
<li class="fragment">Correlation vs.&nbsp;causation</li>
<li class="fragment">Simple linear regression
<ul>
<li class="fragment">Single predictor variable</li>
<li class="fragment">Sum of squared errors</li>
<li class="fragment">Confidence intervals</li>
<li class="fragment">Residuals</li>
<li class="fragment">Assessing model fit</li>
<li class="fragment">Outliers and influence</li>
</ul></li>
</ul>
</section>
<section id="learning-objectives" class="slide level2">
<h2>Learning Objectives</h2>
<div class="columns">
<div class="column" style="width:60%;">
<div>
<ul>
<li class="fragment">Understand the general linear model framework</li>
<li class="fragment">Recognize how t-tests, ANOVA, and regression are connected</li>
<li class="fragment">Apply linear modeling to analyze multivariate data</li>
<li class="fragment">Interpret interaction effects in multifactor designs</li>
<li class="fragment">Gain practical experience with an HR datasets</li>
</ul>
</div>
</div><div class="column" style="width:40%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="https://images.unsplash.com/photo-1551288049-bebda4e38f71?q=80&amp;w=2070&amp;auto=format&amp;fit=crop.png"></p>
<figcaption>Linear models are the foundation of many statistical techniques</figcaption>
</figure>
</div>
</div></div>
</section>
<section id="focus-unified-statistical-thinking" class="slide level2">
<h2>Focus: Unified Statistical Thinking</h2>
<ul>
<li class="fragment">Moving beyond isolated statistical techniques</li>
<li class="fragment">Seeing connections between t-tests, ANOVA, and regression</li>
<li class="fragment">Understanding the common mathematical framework</li>
<li class="fragment">Simplifying the interpretation of statistical models</li>
</ul>
<aside class="notes">
<p>This lecture introduces the concept of the general linear model as a unifying framework for various statistical techniques. By understanding this framework, students will gain a deeper appreciation for how different statistical tests are related to each other.</p>
<p>Key points to emphasize:</p>
<ul>
<li>The power of seeing statistics through a unified lens</li>
<li>How this approach simplifies understanding and application</li>
<li>The practical benefits of this perspective when working with real data</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section>
<section id="reviewing-last-week-correlation-and-regression" class="title-slide slide level1 center" data-background-color="#1E3D59">
<h1>Reviewing Last Week: Correlation and Regression</h1>

</section>
<section id="what-we-covered-last-week" class="slide level2 scrollable">
<h2>What We Covered Last Week</h2>
<p>Last week, we explored the fundamentals of correlation and simple linear regression:</p>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Key Topics:</strong></p>
<ul>
<li class="fragment">Correlation measures (Pearson’s r)</li>
<li class="fragment">Simple linear regression</li>
<li class="fragment">Interpreting slope and intercept</li>
<li class="fragment">Assessing model fit (R²)</li>
<li class="fragment">Testing significance of relationships</li>
<li class="fragment">Assumptions of linear regression</li>
</ul>
</div><div class="column" style="width:50%;">
<div class="cell">
<div class="cell-output-display">
<div>
<figure>
<p><img data-src="lecture_files/figure-revealjs/unnamed-chunk-2-1.png" width="960"></p>
</figure>
</div>
</div>
</div>
</div></div>
<aside class="notes">
<p>Last week we covered two key topics that form the foundation for today’s lecture:</p>
<ol type="1">
<li><strong>Correlation</strong>:
<ul>
<li>A measure of the strength and direction of the linear relationship between two variables</li>
<li>Pearson’s r ranges from -1 (perfect negative correlation) to +1 (perfect positive correlation)</li>
<li>A correlation of 0 indicates no linear relationship</li>
<li>We learned that correlation does not imply causation</li>
</ul></li>
<li><strong>Simple Linear Regression</strong>:
<ul>
<li>Moving beyond correlation to model the relationship between variables</li>
<li>The regression equation: y = β₀ + β₁x + ε</li>
<li>β₀ (intercept): The predicted value of y when x = 0</li>
<li>β₁ (slope): The change in y for a one-unit increase in x</li>
<li>We can use regression for prediction and understanding relationships</li>
<li>R² measures the proportion of variance in y explained by the model</li>
</ul></li>
</ol>
<p>These concepts serve as building blocks for today’s topic: the General Linear Model, which extends these ideas to create a unified framework for statistical analysis.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="correlation-measuring-relationships" class="slide level2 scrollable">
<h2>Correlation: Measuring Relationships</h2>
<div class="columns">
<div class="column" style="width:45%;">
<p><strong>Pearson’s Correlation Coefficient (r):</strong></p>
<ul>
<li class="fragment">Measures the strength and direction of a linear relationship</li>
<li class="fragment">Ranges from -1 (perfect negative) to +1 (perfect positive)</li>
<li class="fragment">Calculated using standardized variables</li>
<li class="fragment">Formula: <span class="math inline">\(r = \frac{\sum{(x_i - \bar{x})(y_i - \bar{y})}}{\sqrt{\sum{(x_i - \bar{x})^2}\sum{(y_i - \bar{y})^2}}}\)</span></li>
<li class="fragment"><strong>Interpretation</strong>: r = 0.7 means a strong positive relationship</li>
</ul>
</div><div class="column" style="width:55%;">
<div class="cell">
<div class="cell-output-display">
<div>
<figure>
<p><img data-src="lecture_files/figure-revealjs/unnamed-chunk-3-1.png" width="576"></p>
</figure>
</div>
</div>
</div>
</div></div>
<aside class="notes">
<p>Correlation is a standardized measure of how two variables change together.</p>
<p><strong>Key points about correlation:</strong></p>
<ol type="1">
<li>Correlation measures both the strength and direction of a linear relationship</li>
<li>The correlation coefficient (r) is always between -1 and +1</li>
<li>The sign indicates direction (positive or negative relationship)</li>
<li>The magnitude indicates strength (closer to 1 or -1 = stronger relationship)</li>
<li>A correlation of 0 suggests no linear relationship</li>
</ol>
<p><strong>Interpretation guidelines:</strong></p>
<ul>
<li>|r| &lt; 0.3: Weak correlation</li>
<li>0.3 &lt; |r| &lt; 0.7: Moderate correlation</li>
<li>|r| &gt; 0.7: Strong correlation</li>
</ul>
<p><strong>Important limitations:</strong></p>
<ul>
<li>Correlation does not imply causation</li>
<li>Correlation only detects linear relationships</li>
<li>Correlation is sensitive to outliers</li>
<li>Correlation doesn’t tell us the slope of the relationship</li>
</ul>
<p>These limitations are why we often move from correlation to regression, which provides more information about the relationship between variables.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="simple-linear-regression-modeling-relationships" class="slide level2 smaller scrollable">
<h2>Simple Linear Regression: Modeling Relationships</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>The Simple Linear Regression Model:</strong></p>
<p><span class="math display">\[y = \beta_0 + \beta_1 x + \varepsilon\]</span></p>
<p>Where:</p>
<ul>
<li class="fragment"><span class="math inline">\(\beta_0\)</span> is the intercept (y when x = 0)</li>
<li class="fragment"><span class="math inline">\(\beta_1\)</span> is the slope (change in y per unit of x)</li>
<li class="fragment"><span class="math inline">\(\varepsilon\)</span> is the error term</li>
</ul>
<p><strong>Key statistics:</strong></p>
<ul>
<li class="fragment">R² (coefficient of determination): Proportion of variance explaine</li>
<li class="fragment">p-value: Tests if the relationship is statistically significant</li>
</ul>
</div><div class="column" style="width:50%;">
<div class="cell">
<div class="cell-output-display">
<div>
<figure>
<p><img data-src="lecture_files/figure-revealjs/unnamed-chunk-4-1.png" width="960"></p>
</figure>
</div>
</div>
</div>
</div></div>
<aside class="notes">
<p>Simple linear regression extends correlation by modeling the relationship between variables. While correlation tells us about the strength and direction of a relationship, regression gives us an equation to predict one variable from another.</p>
<p><strong>Components of the regression model:</strong></p>
<ol type="1">
<li><strong>Intercept (β₀)</strong>: The predicted value of y when x = 0
<ul>
<li>May not always be meaningful in real-world contexts</li>
<li>Example: If x = years of experience, β₀ = starting salary with zero experience</li>
</ul></li>
<li><strong>Slope (β₁)</strong>: The change in y for a one-unit increase in x
<ul>
<li>The practical effect size of the relationship</li>
<li>Example: Each additional year of experience increases salary by $3,000</li>
</ul></li>
<li><strong>Error term (ε)</strong>: The difference between predicted and actual values
<ul>
<li>Represents what our model doesn’t explain</li>
<li>Assumed to be normally distributed with mean zero</li>
</ul></li>
</ol>
<p><strong>Evaluating the model:</strong></p>
<ul>
<li><strong>R²</strong>: The proportion of variance in y explained by the model
<ul>
<li>Ranges from 0 to 1 (sometimes expressed as a percentage)</li>
<li>Example: R² = 0.75 means the model explains 75% of the variation in y</li>
</ul></li>
<li><strong>Statistical significance</strong>: Testing whether β₁ is significantly different from zero
<ul>
<li>If significant, we have evidence of a relationship between x and y</li>
<li>Reported as a p-value (e.g., p &lt; 0.05)</li>
</ul></li>
</ul>
<p>Regression is a powerful tool that forms the foundation for today’s topic: the General Linear Model, which extends these concepts to more complex situations.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="connecting-to-todays-topic-the-general-linear-model" class="slide level2 smaller scrollable">
<h2>Connecting to Today’s Topic: The General Linear Model</h2>
<p>Today, we’ll build on these concepts to explore the <strong>General Linear Model (GLM)</strong>, which:</p>
<ul>
<li class="fragment">Extends regression to include multiple predictors</li>
<li class="fragment">Provides a unified framework for various statistical tests</li>
<li class="fragment">Shows how t-tests, ANOVA, and regression are related</li>
<li class="fragment">Allows us to model complex relationships</li>
<li class="fragment">Helps us understand which factors truly matter when controlling for others</li>
</ul>
<p><strong>Moving from:</strong><br>
<span class="math display">\[y = \beta_0 + \beta_1 x + \varepsilon\]</span></p>
<p><strong>To:</strong><br>
<span class="math display">\[y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + ... + \beta_n x_n + \varepsilon\]</span></p>
<aside class="notes">
<p>Today’s lecture builds directly on the foundation we established last week with correlation and simple regression. We’re now ready to take the next step by exploring the General Linear Model (GLM).</p>
<p><strong>The progression in our learning:</strong></p>
<ol type="1">
<li><p><strong>Correlation</strong>: We started by measuring the strength and direction of relationships between pairs of variables.</p></li>
<li><p><strong>Simple Linear Regression</strong>: We then moved to modeling these relationships with an equation that allows prediction and deeper understanding of how one variable affects another.</p></li>
<li><p><strong>General Linear Model</strong>: Today, we’ll extend this framework to include multiple predictors and show how this unifies many statistical tests under one conceptual umbrella.</p></li>
</ol>
<p><strong>Key extensions in the GLM:</strong></p>
<ul>
<li><p><strong>Multiple predictors</strong>: Real-world outcomes are rarely influenced by just one factor. The GLM allows us to include multiple predictors to better model complex phenomena.</p></li>
<li><p><strong>Categorical predictors</strong>: We’ll see how to include categorical variables (like gender, treatment group, etc.) in our models.</p></li>
<li><p><strong>Controlling for variables</strong>: The GLM allows us to understand the unique effect of each predictor while controlling for other factors.</p></li>
<li><p><strong>Unified framework</strong>: Perhaps most importantly, we’ll discover how many statistical tests you’ve already learned (t-tests, ANOVA, etc.) are actually special cases of the GLM.</p></li>
</ul>
<p>Understanding the GLM will not only simplify your conceptual understanding of statistics but also give you a more powerful and flexible approach to data analysis.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="key-terms-to-remember" class="slide level2">
<h2>Key Terms to Remember</h2>
<p>As we move forward, keep these key terms in mind:</p>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>From Correlation &amp; Regression:</strong></p>
<ul>
<li class="fragment"><strong>Correlation coefficient (r)</strong>: Measures strength and direction of relationship</li>
<li class="fragment"><strong>Intercept (β₀)</strong>: Value of y when x = 0</li>
<li class="fragment"><strong>Slope (β₁)</strong>: Change in y per unit change in x</li>
<li class="fragment"><strong>R²</strong>: Proportion of variance explained</li>
<li class="fragment"><strong>Residuals</strong>: Differences between observed and predicted values</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>New Terms for Today:</strong></p>
<ul>
<li class="fragment"><strong>Multiple regression</strong>: Model with multiple predictors</li>
<li class="fragment"><strong>General Linear Model (GLM)</strong>: Unified framework for statistical tests</li>
<li class="fragment"><strong>Predictor variables</strong>: Factors that may explain the outcome</li>
<li class="fragment"><strong>Categorical predictors</strong>: Non-numeric variables (e.g., gender)</li>
<li class="fragment"><strong>Controlling for variables</strong>: Isolating the effect of one predictor</li>
</ul>
</div></div>
</section>
<section id="any-questions-before-we-begin" class="slide level2">
<h2>Any Questions Before We Begin?</h2>
<p>Let’s briefly address any questions about last week’s material before moving forward.</p>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Common Questions:</strong></p>
<ul>
<li class="fragment">How do we interpret the slope and intercept in practical terms?</li>
<li class="fragment">What’s the difference between correlation and causation?</li>
<li class="fragment">When should we use correlation vs.&nbsp;regression?</li>
<li class="fragment">How do we know if our regression model is good?</li>
<li class="fragment">What if the relationship isn’t linear?</li>
</ul>
</div><div class="column" style="width:50%;">
<div class="cell">
<div class="cell-output-display">
<div>
<figure>
<p><img data-src="lecture_files/figure-revealjs/unnamed-chunk-5-1.png" width="960"></p>
</figure>
</div>
</div>
</div>
</div></div>
<aside class="notes">
<p>Before we move on to new material, let’s address some common questions about correlation and regression.</p>
<p><strong>How do we interpret the slope and intercept in practical terms?</strong></p>
<ul>
<li>The intercept (β₀) is the expected value of y when x = 0. In practice, this may not always be meaningful if x = 0 is outside our observed range.</li>
<li>The slope (β₁) tells us how much y changes for a one-unit increase in x. This is often the most useful part for practical interpretation.</li>
<li>Example: If predicting salary from years of experience with β₁ = 3000, each additional year of experience is associated with a $3,000 increase in salary.</li>
</ul>
<p><strong>What’s the difference between correlation and causation?</strong></p>
<ul>
<li>Correlation simply identifies that two variables change together in a predictable way</li>
<li>Causation means that changes in one variable directly cause changes in another</li>
<li>To establish causation, we typically need controlled experiments or strong causal inference methods</li>
<li>The classic example: Ice cream sales and drowning deaths are correlated (both increase in summer), but one doesn’t cause the other</li>
</ul>
<p><strong>When should we use correlation vs.&nbsp;regression?</strong></p>
<ul>
<li>Use correlation when you simply want to measure the strength and direction of a relationship</li>
<li>Use regression when you want to:
<ul>
<li>Predict one variable from another</li>
<li>Understand the effect size (how much y changes when x changes)</li>
<li>Control for other variables (in multiple regression)</li>
</ul></li>
</ul>
<p><strong>How do we know if our regression model is good?</strong></p>
<ul>
<li>R² tells us the proportion of variance explained (higher is better)</li>
<li>Statistical significance (p-value) tells us if the relationship is likely real or due to chance</li>
<li>Examining residuals helps identify patterns the model missed</li>
<li>Checking model assumptions confirms our statistical inferences are valid</li>
</ul>
<p><strong>What if the relationship isn’t linear?</strong></p>
<ul>
<li>Both correlation and simple linear regression assume a linear relationship</li>
<li>Non-linear relationships may be missed or underestimated by these methods</li>
<li>Solutions include:
<ul>
<li>Transforming variables (e.g., log transformation)</li>
<li>Using non-linear regression models</li>
<li>Using more flexible modeling approaches</li>
</ul></li>
</ul>
<p>These concepts provide the foundation for today’s topic: the General Linear Model, which extends regression to more complex situations while maintaining a unified framework.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="the-general-linear-model-multiple-variables" class="title-slide slide level1 center" data-background-color="#1E3D59">
<h1>The General Linear Model: Multiple Variables</h1>

</section>
<section id="from-simple-to-multiple-regression" class="slide level2">
<h2>From Simple to Multiple Regression</h2>
<p>Before wrapping up our discussion of statistical tests, let’s first build up our understanding of regression from simple to multiple predictor variables.</p>
</section>
<section id="understanding-the-building-blocks" class="slide level2 scrollable">
<h2>Understanding the Building Blocks</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p>The General Linear Model has two key components:</p>
<ol type="1">
<li class="fragment"><strong>Variables</strong>:
<ul>
<li class="fragment"><strong>Outcome (y)</strong>: What we’re trying to understand</li>
<li class="fragment"><strong>Predictors (x)</strong>: Factors that might explain the outcome</li>
</ul></li>
<li class="fragment"><strong>Parameters</strong>:
<ul>
<li class="fragment"><strong>Intercept (β₀)</strong>: Base value when predictors are 0</li>
<li class="fragment"><strong>Coefficients (β₁, β₂, etc.)</strong>: Effects of predictors</li>
<li class="fragment"><strong>Error (ε)</strong>: What the model doesn’t explain</li>
</ul></li>
</ol>
</div><div class="column" style="width:50%;">
<div class="cell">
<div class="cell-output-display">
<div>
<figure>
<p><img data-src="lecture_files/figure-revealjs/unnamed-chunk-7-1.png" width="576"></p>
</figure>
</div>
</div>
</div>
</div></div>
<aside class="notes">
<p>To understand the General Linear Model, we need to break it down into its building blocks.</p>
<p>First, we have two types of variables:</p>
<ol type="1">
<li>The outcome variable (y): This is what we’re trying to understand, explain, or predict. It’s also called the dependent variable, response variable, or target variable. Examples include test scores, blood pressure, customer satisfaction, or income.</li>
<li>Predictor variables (x): These are the factors that might explain or predict the outcome. They’re also called independent variables, explanatory variables, or features. Examples might be study time, medication type, service quality metrics, or years of education.</li>
</ol>
<p>Next, we have parameters that describe the relationship between these variables:</p>
<ol start="3" type="1">
<li>The intercept (β₀): This is the baseline value of y when all predictors are zero. It’s the starting point of our model.</li>
<li>Coefficients (β₁, β₂, etc.): These tell us how much y changes when the corresponding predictor changes by one unit, holding all other predictors constant. The coefficients quantify the effects of our predictors.</li>
<li>Error term (ε): This represents what our model doesn’t explain - the deviation between our model’s predictions and the actual data. A good model minimizes this error.</li>
</ol>
<p>The visualization shows these components:</p>
<ul>
<li>Blue dots represent the data points (observations)</li>
<li>The red line is our model, with the intercept (β₀) as the starting point and the slope (β₁) showing the effect of the predictor</li>
<li>The dashed gray lines show the error (ε) for some points - the difference between what the model predicts and the actual values</li>
</ul>
<p>Understanding these components gives us the foundation to see how different statistical tests are variations of the same underlying model.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="simple-linear-regression-one-predictor" class="slide level2">
<h2>Simple Linear Regression: One Predictor</h2>
<p>In simple linear regression, we have one outcome variable and one predictor:</p>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Key components:</strong></p>
<ul>
<li class="fragment"><span class="math inline">\(y\)</span> is the outcome we want to predict</li>
<li class="fragment"><span class="math inline">\(\beta_0\)</span> is the intercept (value of y when x = 0)</li>
<li class="fragment"><span class="math inline">\(\beta_1\)</span> is the slope (effect of the predictor)</li>
<li class="fragment"><span class="math inline">\(x_1\)</span> is the predictor variable</li>
<li class="fragment"><span class="math inline">\(\varepsilon\)</span> is the error term</li>
</ul>
<p><strong>Example:</strong> Predicting salary based on years of experience</p>
</div><div class="column" style="width:50%;">
<p><span class="math display">\[y = \beta_0 + \beta_1 x_1 + \varepsilon\]</span></p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure>
<p><img data-src="lecture_files/figure-revealjs/unnamed-chunk-8-1.png" width="480"></p>
</figure>
</div>
</div>
</div>
</div></div>
<aside class="notes">
<p>Simple linear regression is where most students begin their regression journey. It models the relationship between one outcome variable (y) and one predictor variable (x).</p>
<p>The model estimates two key parameters:</p>
<ul>
<li>The intercept (β₀) represents the predicted value of y when x equals zero</li>
<li>The slope (β₁) represents how much y changes when x increases by one unit</li>
</ul>
<p>In our example, we’re predicting salary based on years of experience: - Each additional year of experience is associated with approximately $2,500 more in salary - The intercept suggests that someone with zero experience would have a salary around $30,000</p>
<p>The blue dots represent individual data points, while the red line shows our model’s prediction. The distance between each point and the line represents the error term (ε) - what our model doesn’t explain.</p>
<p>Simple linear regression provides a foundation, but in real-world situations, outcomes are typically influenced by multiple factors. That’s where multiple regression comes in.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="multiple-regression-adding-more-predictors" class="slide level2">
<h2>Multiple Regression: Adding More Predictors</h2>
<p>What if multiple factors affect our outcome? Multiple regression extends the model:</p>
<p><span class="math display">\[y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \varepsilon\]</span></p>
<p><strong>Key advantages:</strong></p>
<ul>
<li class="fragment">Models real-world complexity</li>
<li class="fragment">Accounts for multiple influences</li>
<li class="fragment">Controls for confounding variables</li>
<li class="fragment">Improves prediction accuracy</li>
<li class="fragment">Allows comparing relative importance of predictors</li>
</ul>
</section>
<section class="slide level2">

<div class="columns">
<div class="column" style="width:30%;">
<p><strong>Example:</strong> Predicting salary based on years of experience AND performance rating</p>
</div><div class="column" style="width:70%;">
<div class="cell">
<div class="cell-output-display">
<div class="plotly html-widget html-fill-item" id="htmlwidget-1788bcb4a7f79aaf8db3" style="width:672px;height:672px;"></div>
<script type="application/json" data-for="htmlwidget-1788bcb4a7f79aaf8db3">{"x":{"visdat":{"78b851f337d2":["function () ","plotlyVisDat"]},"cur_data":"78b851f337d2","attrs":{"78b851f337d2":{"x":{},"y":{},"z":{},"marker":{"size":5,"color":"steelblue","opacity":0.80000000000000004},"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"scatter3d","mode":"markers","inherit":true},"78b851f337d2.1":{"x":[1.4676600056700408,3.5147117556900613,5.5617635057100818,7.6088152557301019,9.6558670057501228,11.702918755770144,13.749970505790163,15.797022255810184,17.844074005830205,19.891125755850226],"y":[2.2244595668744296,2.5290853357873857,2.8337111047003418,3.1383368736132979,3.4429626425262541,3.7475884114392102,4.0522141803521663,4.3568399492651224,4.6614657181780785,4.9660914870910347],"z":[[39661.522232046875,42674.414042846067,45687.305853645259,48700.197664444451,51713.089475243636,54725.981286042828,57738.87309684202,60751.764907641213,63764.656718440405,66777.548529239604],[43479.766225513973,46492.658036313165,49505.549847112357,52518.44165791155,55531.333468710742,58544.225279509934,61557.117090309126,64570.008901108318,67582.90071190751,70595.792522706703],[47298.010218981071,50310.902029780264,53323.793840579456,56336.685651378648,59349.57746217784,62362.469272977032,65375.361083776224,68388.252894575417,71401.144705374609,74414.036516173801],[51116.25421244817,54129.146023247362,57142.037834046554,60154.929644845746,63167.821455644938,66180.713266444131,69193.605077243323,72206.496888042515,75219.388698841707,78232.280509640899],[54934.498205915268,57947.39001671446,60960.281827513652,63973.173638312845,66986.065449112037,69998.957259911229,73011.849070710421,76024.740881509613,79037.632692308805,82050.524503107998],[58752.742199382381,61765.634010181573,64778.525820980765,67791.417631779957,70804.309442579135,73817.201253378327,76830.093064177519,79842.984874976712,82855.876685775904,85868.768496575096],[62570.986192849479,65583.878003648671,68596.769814447864,71609.661625247056,74622.553436046248,77635.44524684544,80648.337057644632,83661.228868443824,86674.120679243017,89687.012490042209],[66389.230186316578,69402.12199711577,72415.013807914962,75427.905618714154,78440.797429513346,81453.689240312538,84466.581051111731,87479.472861910923,90492.364672710115,93505.256483509307],[70207.474179783676,73220.365990582868,76233.25780138206,79246.149612181252,82259.041422980445,85271.933233779637,88284.825044578829,91297.716855378021,94310.608666177213,97323.500476976405],[74025.718173250789,77038.609984049981,80051.501794849173,83064.393605648365,86077.285416447558,89090.17722724675,92103.069038045942,95115.960848845134,98128.852659644326,101141.74447044352]],"marker":{"size":5,"color":"steelblue","opacity":0.80000000000000004},"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"surface","opacity":0.69999999999999996,"colorscale":"Reds","inherit":true}},"layout":{"margin":{"b":40,"l":60,"t":25,"r":10},"title":"Multiple Regression","scene":{"xaxis":{"title":"Experience"},"yaxis":{"title":"Performance"},"zaxis":{"title":"Salary"}},"hovermode":"closest","showlegend":false,"legend":{"yanchor":"top","y":0.5}},"source":"A","config":{"modeBarButtonsToAdd":["hoverclosest","hovercompare"],"showSendToCloud":false},"data":[{"x":[6.4639728823676705,15.977797573432326,8.7705615144222975,17.777330676093698,18.868878401583061,1.8655734884086996,11.034004272893071,17.955961843486875,11.477265274850652,9.6756799707654864,19.179833561647683,9.6133489676285535,13.873842073604465,11.880034637171775,2.9555689706467092,18.096674437634647,5.6756669527385384,1.7991311370860785,7.2304936663713306,19.135569333797321,17.901247005211189,14.163264716975391,13.169629461597651,19.891125755850226,13.458410183200613,14.462078895187005,11.337254469515756,12.288698388496414,6.4940350085962564,3.7951592989265919,19.297460418194532,18.143681857269257,14.123400290030986,16.113880936056376,1.4676600056700408,10.078123450744897,15.410731212934479,5.1117507808376104,7.0454391450621188,5.4008899217005819],"y":[2.2686548011843115,2.6315369580406696,4.1988658043555915,4.5564006220083684,4.3651936834212393,2.9958799052983522,2.2472982050385326,2.8565808350685984,2.7125098146498203,3.15570850064978,3.1188377330545336,2.6537256787996739,4.265315106138587,4.4650432062335312,3.7967544924467802,3.9531006801407784,4.5293517140671611,3.3597144279628992,4.1502712988294661,2.8736664995085448,2.539649412734434,4.1652307999320328,4.7152627385221422,3.3373000104911625,4.5158043911214918,4.1104784950148314,4.8527869889512658,3.9294565250165761,2.2244595668744296,2.7604711211752146,4.9227619748562574,2.6519122149329633,4.8764023396652192,3.5055681897792965,3.9524023544508964,4.8449032257776707,4.9660914870910347,4.7543434298131615,4.8138842741027474,3.5850054356269538],"z":[47280.353709568968,59269.420396550719,59717.406987045906,93671.753686605196,92372.616843891621,56772.462736063688,56343.554430808726,76137.498123266356,76530.924872103584,55882.004715867071,79080.015282242122,55706.16053879707,65878.879785972895,81849.639943065762,57650.175897549598,102343.37287005839,62301.322780999173,49353.962167294092,64271.324866126706,80950.584464278843,75888.153951742235,84792.674846706024,82064.449464765465,87148.253305520557,99674.252403799328,82774.800174128075,82442.000373968156,82173.482719733205,41380.527338545915,52946.396044623012,92657.409967101339,75450.463318657392,92688.276481404624,87447.064513021862,59501.390299576655,84767.10267110361,87244.797729131038,80720.754038533923,76935.543023732214,64099.027061617642],"marker":{"color":"steelblue","size":5,"opacity":0.80000000000000004,"line":{"color":"rgba(31,119,180,1)"}},"type":"scatter3d","mode":"markers","error_y":{"color":"rgba(31,119,180,1)"},"error_x":{"color":"rgba(31,119,180,1)"},"line":{"color":"rgba(31,119,180,1)"},"frame":null},{"colorbar":{"title":"salary","ticklen":2,"len":0.5,"lenmode":"fraction","y":1,"yanchor":"top"},"colorscale":"Reds","showscale":true,"x":[1.4676600056700408,3.5147117556900613,5.5617635057100818,7.6088152557301019,9.6558670057501228,11.702918755770144,13.749970505790163,15.797022255810184,17.844074005830205,19.891125755850226],"y":[2.2244595668744296,2.5290853357873857,2.8337111047003418,3.1383368736132979,3.4429626425262541,3.7475884114392102,4.0522141803521663,4.3568399492651224,4.6614657181780785,4.9660914870910347],"z":[[39661.522232046875,42674.414042846067,45687.305853645259,48700.197664444451,51713.089475243636,54725.981286042828,57738.87309684202,60751.764907641213,63764.656718440405,66777.548529239604],[43479.766225513973,46492.658036313165,49505.549847112357,52518.44165791155,55531.333468710742,58544.225279509934,61557.117090309126,64570.008901108318,67582.90071190751,70595.792522706703],[47298.010218981071,50310.902029780264,53323.793840579456,56336.685651378648,59349.57746217784,62362.469272977032,65375.361083776224,68388.252894575417,71401.144705374609,74414.036516173801],[51116.25421244817,54129.146023247362,57142.037834046554,60154.929644845746,63167.821455644938,66180.713266444131,69193.605077243323,72206.496888042515,75219.388698841707,78232.280509640899],[54934.498205915268,57947.39001671446,60960.281827513652,63973.173638312845,66986.065449112037,69998.957259911229,73011.849070710421,76024.740881509613,79037.632692308805,82050.524503107998],[58752.742199382381,61765.634010181573,64778.525820980765,67791.417631779957,70804.309442579135,73817.201253378327,76830.093064177519,79842.984874976712,82855.876685775904,85868.768496575096],[62570.986192849479,65583.878003648671,68596.769814447864,71609.661625247056,74622.553436046248,77635.44524684544,80648.337057644632,83661.228868443824,86674.120679243017,89687.012490042209],[66389.230186316578,69402.12199711577,72415.013807914962,75427.905618714154,78440.797429513346,81453.689240312538,84466.581051111731,87479.472861910923,90492.364672710115,93505.256483509307],[70207.474179783676,73220.365990582868,76233.25780138206,79246.149612181252,82259.041422980445,85271.933233779637,88284.825044578829,91297.716855378021,94310.608666177213,97323.500476976405],[74025.718173250789,77038.609984049981,80051.501794849173,83064.393605648365,86077.285416447558,89090.17722724675,92103.069038045942,95115.960848845134,98128.852659644326,101141.74447044352]],"marker":{"size":5,"color":"steelblue","opacity":0.80000000000000004},"type":"surface","opacity":0.69999999999999996,"frame":null}],"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.20000000000000001,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
</div>
</div>
</div></div>
<aside class="notes">
<p>Multiple regression extends our model by adding more predictor variables. This allows us to account for the complex, multifaceted nature of real-world relationships.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

<div class="smaller">
<p>Now our model includes:</p>
<ul>
<li class="fragment">The intercept (β₀): The predicted value of y when all predictors are zero</li>
<li class="fragment">Multiple slope coefficients (β₁, β₂, etc.): Each representing the effect of its corresponding predictor when all other predictors are held constant</li>
</ul>
<p>This “holding other variables constant” is a crucial concept. It means that each coefficient tells us the unique effect of that predictor, controlling for the effects of all other predictors in the model.</p>
<p>In our example, we’re now predicting salary based on both years of experience and performance rating:</p>
<ul>
<li class="fragment">Each additional year of experience is associated with about $2,000 more in salary, holding performance constant</li>
<li class="fragment">Each additional point in performance rating is associated with about $8,000 more in salary, holding experience constant</li>
</ul>
</div>
</section>
<section class="slide level2 scrollable">

<p>The 3D visualization shows how our model creates a plane in three-dimensional space:</p>
<ul>
<li class="fragment">Each blue dot represents an employee (with specific experience, performance, and salary)</li>
<li class="fragment">The red surface represents our model’s predictions</li>
<li class="fragment">The vertical distance from each dot to the surface represents the error term (ε)</li>
</ul>
<p>Multiple regression provides several advantages:</p>
<ol type="1">
<li class="fragment">It models the complexity of real-world situations where outcomes are influenced by multiple factors</li>
<li class="fragment">It allows us to control for confounding variables</li>
<li class="fragment">It often provides more accurate predictions than simple regression</li>
<li class="fragment">It helps us understand the relative importance of different predictors</li>
</ol>
<p>This approach can be extended to include any number of predictors, creating a multidimensional hyperplane that we can’t easily visualize but that follows the same principles.</p>
</section>
<section id="extending-to-many-predictors" class="slide level2 scrollable">
<h2>Extending to Many Predictors</h2>
<p>The model can be extended to include any number of predictors:</p>
<p><span class="math display">\[y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_3 + ... + \beta_n x_n + \varepsilon\]</span></p>
<div class="columns">
<div class="column" style="width:50%;">
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a></a><span class="co"># Build model with multiple predictors</span></span>
<span id="cb1-2"><a></a>full_model <span class="ot">&lt;-</span> <span class="fu">lm</span>(</span>
<span id="cb1-3"><a></a>  salarygrade <span class="sc">~</span> gender <span class="sc">+</span> tenure <span class="sc">+</span></span>
<span id="cb1-4"><a></a>    evaluation <span class="sc">+</span> age <span class="sc">+</span> job_satisfaction,</span>
<span id="cb1-5"><a></a>  <span class="at">data =</span> hr_data</span>
<span id="cb1-6"><a></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div><div class="column" style="width:50%;">
<div class="cell">
<div class="cell-output-display">
<table class="caption-top">
<thead>
<tr class="header">
<th style="text-align: left;">Predictor</th>
<th style="text-align: right;">Effect on Salary</th>
<th style="text-align: right;">p-value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">(Intercept)</td>
<td style="text-align: right;">-0.079</td>
<td style="text-align: right;">0.563</td>
</tr>
<tr class="even">
<td style="text-align: left;">genderMale</td>
<td style="text-align: right;">0.354</td>
<td style="text-align: right;">0.000</td>
</tr>
<tr class="odd">
<td style="text-align: left;">tenure</td>
<td style="text-align: right;">0.103</td>
<td style="text-align: right;">0.000</td>
</tr>
<tr class="even">
<td style="text-align: left;">evaluation</td>
<td style="text-align: right;">0.022</td>
<td style="text-align: right;">0.439</td>
</tr>
<tr class="odd">
<td style="text-align: left;">age</td>
<td style="text-align: right;">0.023</td>
<td style="text-align: right;">0.000</td>
</tr>
<tr class="even">
<td style="text-align: left;">job_satisfaction</td>
<td style="text-align: right;">0.177</td>
<td style="text-align: right;">0.000</td>
</tr>
</tbody>
</table>
</div>
</div>
</div></div>
<aside class="notes">
<p>We can continue extending our multiple regression model to include any number of predictors. The general form remains the same, with each new predictor getting its own coefficient that represents its unique effect on the outcome.</p>
<p>In this example, we’re using real HR data to predict salary grade based on multiple factors:</p>
<ul>
<li>Gender (categorical: male/female)</li>
<li>Tenure (years of experience)</li>
<li>Evaluation (performance rating)</li>
<li>Age (in years)</li>
<li>Job satisfaction (rating scale)</li>
</ul>
<p>The model output shows:</p>
<ol type="1">
<li>Each predictor’s coefficient (effect on salary)</li>
<li>The statistical significance of each effect (p-value)</li>
</ol>
<p>The interpretation of each coefficient is:</p>
<ul>
<li>Gender: Being male is associated with a 5.9 point higher salary grade, holding all else constant</li>
<li>Tenure: Each additional year of experience is associated with a 1.4 point increase in salary grade</li>
<li>Evaluation: Each additional point in performance rating is associated with a 3.9 point increase in salary grade</li>
<li>Age: Each additional year of age is associated with a -0.02 point change in salary grade (effectively zero)</li>
<li>Job satisfaction: Each additional point in job satisfaction is associated with a 0.4 point increase in salary grade</li>
</ul>
<p>From these results, we can see that gender, tenure, and evaluation ratings have the strongest effects on salary, while age appears to have no meaningful impact.</p>
<p>This approach allows us to model complex real-world situations where many factors simultaneously influence an outcome. It’s a powerful tool for both prediction and understanding the relative importance of different factors.</p>
<p>The multiple regression model we’ve just explored is actually the general form of the General Linear Model (GLM), which we’ll see can represent many different statistical tests.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="the-general-linear-model-unifying-statistical-tests" class="title-slide slide level1 center" data-background-color="#1E3D59">
<h1>The General Linear Model: Unifying Statistical Tests</h1>

</section>
<section id="the-statistical-test-dilemma" class="slide level2 scrollable">
<h2>The Statistical Test Dilemma</h2>
<p>In a typical statistics course, you are likely to learn many different tests:</p>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Covered so far</strong>:</p>
<ul>
<li class="fragment"><strong>t-tests</strong> (one-sample, independent, paired)</li>
<li class="fragment"><strong>Correlation</strong> (Pearson, Spearman)</li>
<li class="fragment"><strong>Regression</strong> (simple, multiple)</li>
</ul>
</div><div class="column fragment" style="width:50%;">
<ul>
<li class="fragment"><strong>ANOVA, Analysis of Variance</strong> (one-way, two-way)</li>
<li class="fragment"><strong>Chi-square tests</strong></li>
<li class="fragment"><strong>Non-parametric alternatives</strong></li>
</ul>
</div></div>
<p>With so many tests, it can feel overwhelming to remember which one to use when!</p>
<aside class="notes">
<p>When students learn statistics, they’re often taught different statistical tests as separate, unrelated procedures:</p>
<ol type="1">
<li>Want to compare one sample to a known value? Use a one-sample t-test.</li>
<li>Comparing two groups? That’s an independent t-test.</li>
<li>Comparing multiple groups? Now you need ANOVA.</li>
<li>Looking at relationships between continuous variables? Time for correlation or regression.</li>
</ol>
<p>This approach creates several problems:</p>
<p>First, it encourages memorization rather than understanding. Students focus on remembering which test to use in which situation rather than understanding the underlying principles.</p>
<p>Second, it obscures the connections between different tests, making statistics seem more complex and fragmented than it really is.</p>
<p>Third, it can lead to confusion about which test to choose, especially in situations that don’t neatly fit the examples covered in class.</p>
<p>Finally, it makes it harder to transition to more advanced statistical methods because each new technique seems like a completely new concept to learn.</p>
<p>Today, we’ll explore a different approach: understanding common statistical tests as variations of the same underlying framework - the General Linear Model. This perspective can greatly simplify how we think about statistics and help us see the connections between seemingly different techniques.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="the-statistical-test-dilemma-1" class="slide level2">
<h2>The Statistical Test Dilemma</h2>

<img data-src="StatRethinking-test-tree.png" style="width:100.0%" class="r-stretch quarto-figure-center"><p class="caption">Example decision tree, or flowchart, for selecting an appropriate statistical procedure. <span class="citation" data-cites="McElreath2020Statistical">McElreath (<a href="#/further-reading" role="doc-biblioref" onclick="">2020</a>)</span></p></section>
<section id="challenging-the-traditional-approach" class="slide level2 scrollable">
<h2>Challenging the Traditional Approach</h2>
<div class="columns">
<div class="column" style="width:40%;">
<p><strong>Traditional approach:</strong></p>
<ul>
<li class="fragment">Each test is taught as a separate technique</li>
<li class="fragment">Different formulas to memorize</li>
<li class="fragment">Different assumptions to check</li>
<li class="fragment">Different procedures to follow</li>
<li class="fragment">No clear connections between tests</li>
</ul>
<p><strong>Result:</strong> Statistics feels like a collection of disconnected tools rather than a coherent framework.</p>
</div><div class="column" style="width:60%;">
<div class="cell">
<div class="cell-output-display">
<div>
<figure>
<p><img data-src="lecture_files/figure-revealjs/unnamed-chunk-13-1.png" width="768"></p>
</figure>
</div>
</div>
</div>
</div></div>
<aside class="notes">
<p>The traditional approach to teaching statistics typically presents each test as a separate entity with its own formulas, assumptions, and procedures. This is like presenting a collection of disconnected islands, with no obvious way to navigate between them.</p>
<p>In this traditional approach:</p>
<ul>
<li>Students learn the one-sample t-test, then move on to the independent t-test, then ANOVA, and so on</li>
<li>Each test seems to have its own set of rules and formulas to memorize</li>
<li>There’s little emphasis on how these tests relate to each other</li>
<li>The focus is often on “which test to use when” rather than understanding the underlying principles</li>
</ul>
<p>This approach has several drawbacks:</p>
<ol type="1">
<li>It emphasizes memorization over conceptual understanding</li>
<li>It makes statistics seem more complex than it really is</li>
<li>It doesn’t prepare students well for situations that don’t fit neatly into the categories they’ve learned</li>
<li>It can make more advanced statistical methods seem disconnected from basic techniques</li>
</ol>
<p>In contrast, a unified approach connects all these seemingly different tests through a common framework - the General Linear Model. This makes statistics more coherent and easier to understand, as you’ll see today.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="a-different-perspective-everything-is-connected" class="slide level2 scrollable">
<h2>A Different Perspective: Everything is Connected</h2>
<p>The <strong>General Linear Model</strong> provides a unified framework for statistical analysis.</p>
<p>Under this framework:</p>
<ul>
<li class="fragment"><strong>t-tests</strong> are special cases of regression</li>
<li class="fragment"><strong>Correlation</strong> is related to regression</li>
<li class="fragment"><strong>Non-parametric tests (e.g.&nbsp;Spearman correlation)</strong> are transformations of parametric tests</li>
<li class="fragment"><strong>ANOVA</strong> is a special case of regression</li>
</ul>
<p>This means there’s less to learn and more to understand!</p>
<aside class="notes">
<p>Now, let’s explore a different perspective: the General Linear Model (GLM) as a unifying framework for statistical analysis.</p>
<p>The key insight is that many common statistical tests are actually special cases of the same underlying model. Instead of viewing t-tests, ANOVA, correlation, and regression as completely different techniques, we can understand them as variations of the general linear model.</p>
<p>For example:</p>
<ul>
<li>A t-test is just a regression model with a categorical predictor that has two levels</li>
<li>ANOVA is a regression model with a categorical predictor that has more than two levels</li>
<li>Simple regression is, well, regression with one continuous predictor</li>
<li>Multiple regression extends this to multiple predictors</li>
</ul>
<p>This unified perspective has several advantages:</p>
<ol type="1">
<li>It reduces the conceptual load - instead of learning many different techniques, you learn one framework with variations</li>
<li>It highlights the connections between different statistical approaches</li>
<li>It makes the transition to more advanced methods more intuitive</li>
<li>It focuses on understanding rather than memorizing formulas and procedures</li>
</ol>
<p>The hierarchical diagram shows how different statistical tests are related through the general linear model. All these tests are part of the same family, with the GLM as their common ancestor.</p>
<p>This perspective was eloquently described by Jonas Kristoffer Lindeløv in his blog post “Common statistical tests are linear models” and is increasingly being adopted in modern statistics education.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="the-general-linear-model-the-basic-formula" class="slide level2">
<h2>The General Linear Model: The Basic Formula</h2>
<p>The general linear model can be written as:</p>
<p><span class="math display">\[y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + ... + \beta_n x_n + \varepsilon\]</span></p>
<p>Where:</p>
<ul>
<li class="fragment"><span class="math inline">\(y\)</span> is the outcome we want to understand</li>
<li class="fragment"><span class="math inline">\(\beta_0\)</span> is the intercept (value of y when all predictors are 0)</li>
<li class="fragment"><span class="math inline">\(\beta_1, \beta_2, etc.\)</span> are coefficients that tell us the effect of each predictor</li>
<li class="fragment"><span class="math inline">\(x_1, x_2, etc.\)</span> are the predictor variables</li>
<li class="fragment"><span class="math inline">\(\varepsilon\)</span> is the error term (what our model doesn’t explain)</li>
</ul>
<p>This single formula is the foundation for most statistical tests!</p>
<aside class="notes">
<p>The general linear model is expressed mathematically with this formula:</p>
<p>y = β₀ + β₁x₁ + β₂x₂ + … + βₙxₙ + ε</p>
<p>This may look like a multiple regression equation - and that’s exactly right. Multiple regression is one implementation of the general linear model, but it’s not the only one.</p>
<p>Let’s break down the components:</p>
<ul>
<li>y is our outcome variable - what we’re trying to understand or predict</li>
<li>β₀ is the intercept - the value of y when all predictors are zero</li>
<li>β₁, β₂, etc. are the coefficients that tell us the effect of each predictor</li>
<li>x₁, x₂, etc. are our predictor variables</li>
<li>ε is the error term - what our model doesn’t explain</li>
</ul>
<p>The beauty of this formula is its flexibility. By making small adjustments to it, we can represent a wide range of statistical tests:</p>
<ul>
<li>In a one-sample t-test, we have no predictors, just an intercept to test</li>
<li>In an independent t-test, we have one binary predictor</li>
<li>In ANOVA, we have categorical predictors with multiple levels</li>
<li>In correlation and regression, we have continuous predictors</li>
</ul>
<p>All of these tests are just special cases of the same underlying model. This unified perspective can greatly simplify how we think about statistics and help us see the connections between seemingly different techniques.</p>
<p>This is why modern statistics education is increasingly moving toward teaching the general linear model as a foundation, with specific tests introduced as special cases of this framework.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="example-1-one-sample-t-test-as-a-linear-model" class="slide level2">
<h2>Example 1: One-Sample t-test as a Linear Model</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>One-sample t-test</strong>: Tests if a sample mean differs from a known value.</p>
<p><strong>As a linear model</strong>: <span class="math display">\[y = \beta_0 + \varepsilon\]</span></p>
<p>Where:</p>
<ul>
<li class="fragment"><span class="math inline">\(\beta_0\)</span> is the sample mean</li>
<li class="fragment">The test examines whether <span class="math inline">\(\beta_0 = \mu_0\)</span> (the hypothesized value)</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>Example</strong>: Testing if average student test scores (70) differ from the expected value (65)</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure>
<p><img data-src="lecture_files/figure-revealjs/unnamed-chunk-15-1.png" width="576"></p>
</figure>
</div>
</div>
</div>
</div></div>
<aside class="notes">
<p>Let’s start with one of the simplest statistical tests: the one-sample t-test.</p>
<p>A one-sample t-test compares a sample mean to a known value. For example, we might want to test whether the average test score in a class (70 points) is significantly different from the expected score (65 points).</p>
<p>In the general linear model framework, this test is incredibly simple. Our model becomes:</p>
<p>y = β₀ + ε</p>
<p>Here, β₀ is the intercept, which represents the mean of our sample. The t-test is testing whether this intercept (β₀) equals our hypothesized value (65).</p>
<p>The visualization shows: - Blue dots: individual test scores (our data points) - Red line: the sample mean (β₀ in our model) at approximately 70 - Green dashed line: the test value of 65</p>
<p>The one-sample t-test is asking: “Is the difference between the red line (our sample mean) and the green line (our test value) statistically significant, or could it be due to random chance?”</p>
<p>This is the simplest case of the general linear model - just an intercept and error term. There are no predictor variables (x terms) in the equation.</p>
<p>In R, we can perform this test using either the traditional t.test() function or the linear model approach with lm():</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a></a><span class="co"># Traditional approach</span></span>
<span id="cb2-2"><a></a><span class="fu">t.test</span>(test_scores, <span class="at">mu =</span> <span class="dv">65</span>)</span>
<span id="cb2-3"><a></a></span>
<span id="cb2-4"><a></a><span class="co"># Linear model approach</span></span>
<span id="cb2-5"><a></a><span class="fu">lm</span>(test_scores <span class="sc">~</span> <span class="dv">1</span>)  <span class="co"># The '1' gives us just an intercept</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Both approaches will give us identical t-statistics and p-values, showing that they’re mathematically equivalent.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="example-2-independent-t-test-as-a-linear-model" class="slide level2 smaller">
<h2>Example 2: Independent t-test as a Linear Model</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Independent t-test</strong>: Compares means between two groups.</p>
<p><strong>As a linear model</strong>: <span class="math display">\[y = \beta_0 + \beta_1 x_1 + \varepsilon\]</span></p>
<p>Where:</p>
<ul>
<li class="fragment"><span class="math inline">\(x_1\)</span> is a binary (0/1) indicator for group membership</li>
<li class="fragment"><span class="math inline">\(\beta_0\)</span> is the mean for group 0 (reference group)</li>
<li class="fragment"><span class="math inline">\(\beta_1\)</span> is the difference between groups</li>
<li class="fragment">We test whether <span class="math inline">\(\beta_1 = 0\)</span> (no difference)</li>
</ul>
</div><div class="column" style="width:50%;">
<p><strong>Example:</strong> Comparing male vs.&nbsp;female test scores</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure>
<p><img data-src="lecture_files/figure-revealjs/unnamed-chunk-16-1.png" width="576"></p>
</figure>
</div>
</div>
</div>
</div></div>
<aside class="notes">
<p>Now let’s look at how the independent t-test fits into the general linear model framework.</p>
<p>An independent t-test compares means between two groups, such as test scores between male and female students. In the traditional approach, we calculate the means of each group, their difference, and determine if this difference is statistically significant.</p>
<p>In the general linear model framework, this becomes:</p>
<p>y = β₀ + β₁x₁ + ε</p>
<p>Where:</p>
<ul>
<li>x₁ is a binary variable indicating group membership (0 for Group A, 1 for Group B)</li>
<li>β₀ is the intercept, which represents the mean of Group A (the reference group)</li>
<li>β₁ is the coefficient for the group difference, which represents how much higher or lower Group B’s mean is compared to Group A’s</li>
<li>The t-test for β₁ tests whether this difference is significantly different from zero</li>
</ul>
<p>This approach uses what’s called “dummy coding” or “indicator variables.” Group membership is coded as 0 or 1, and the model estimates the effect of being in Group B compared to Group A.</p>
<p>In the visualization:</p>
<ul>
<li>Colored dots: individual scores for each group</li>
<li>Horizontal lines: group means</li>
<li>β₀ (the intercept): Group A’s mean</li>
<li>β₁ (the coefficient): the difference between Group B and Group A (about 10 points in this example)</li>
</ul>
<p>The t-test for the coefficient β₁ is exactly the same as the traditional independent t-test. They are mathematically equivalent.</p>
<p>In R, we can perform this test using either approach:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a></a><span class="co"># Traditional approach</span></span>
<span id="cb3-2"><a></a><span class="fu">t.test</span>(score <span class="sc">~</span> group, <span class="at">data =</span> group_data, <span class="at">var.equal =</span> <span class="cn">TRUE</span>)</span>
<span id="cb3-3"><a></a></span>
<span id="cb3-4"><a></a><span class="co"># Linear model approach</span></span>
<span id="cb3-5"><a></a><span class="fu">lm</span>(score <span class="sc">~</span> group, <span class="at">data =</span> group_data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Both will give identical t-statistics and p-values for the group difference.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="dummy-coding-how-categorical-variables-work-in-linear-models" class="slide level2 smaller scrollable">
<h2>Dummy Coding: How Categorical Variables Work in Linear Models</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Dummy coding</strong> transforms categorical variables into a format linear models can use:</p>
<ol type="1">
<li class="fragment">Choose a reference group (usually the first category)</li>
<li class="fragment">Create 0/1 indicator variables for other groups</li>
<li class="fragment">The model estimates:
<ul>
<li class="fragment"><span class="math inline">\(\beta_0\)</span> = mean of reference group</li>
<li class="fragment"><span class="math inline">\(\beta_1, \beta_2, etc.\)</span> = differences from reference</li>
</ul></li>
</ol>
<p>This allows us to include categorical predictors in our linear models, extending beyond just continuous variables.</p>
</div><div class="column" style="width:50%;">
<div class="cell">
<div class="cell-output-display">
<div>
<figure>
<p><img data-src="lecture_files/figure-revealjs/unnamed-chunk-17-1.png" width="576"></p>
</figure>
</div>
</div>
</div>
</div></div>
<aside class="notes">
<p>Dummy coding is a key concept that allows us to include categorical variables in our linear models. It’s worth understanding this in detail since it’s central to how tests like the independent t-test and ANOVA work within the linear model framework.</p>
<p>Here’s how dummy coding works:</p>
<ol type="1">
<li>First, we choose one category as the reference group (typically the first category alphabetically or numerically)</li>
<li>For each of the other categories, we create a binary indicator variable (0 or 1)</li>
<li>The reference group gets zeros for all these indicator variables</li>
</ol>
<p>For example, with three categories A, B, and C:</p>
<ul>
<li>Category A is our reference group</li>
<li>For Category B, we create a variable B_dummy (1 if in category B, 0 otherwise)</li>
<li>For Category C, we create a variable C_dummy (1 if in category C, 0 otherwise)</li>
</ul>
<p>In the resulting model:</p>
<ul>
<li>β₀ (the intercept) represents the mean of the reference group (A)</li>
<li>β₁ represents the difference between category B and the reference</li>
<li>β₂ represents the difference between category C and the reference</li>
</ul>
<p>This approach allows us to include categorical variables with any number of levels in our linear models. With k categories, we’ll have k-1 dummy variables (one serves as the reference).</p>
<p>In the visualization:</p>
<ul>
<li>Each color represents a different category</li>
<li>The dots are individual data points</li>
<li>The horizontal lines are the group means</li>
<li>β₀ is the mean of the reference group (A)</li>
<li>β₁ and β₂ are the differences between the other groups and the reference</li>
</ul>
<p>Statistical software like R automatically does this dummy coding when you include a categorical variable in a model. When you run <code>lm(y ~ category)</code>, R creates these dummy variables behind the scenes.</p>
<p>This is why the independent t-test can be represented as a linear model with a binary predictor, and why ANOVA can be represented as a linear model with multiple dummy-coded predictors.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="example-3-anova-as-a-linear-model" class="slide level2 smaller">
<h2>Example 3: ANOVA as a Linear Model</h2>
<div class="columns">
<div class="column" style="width:45%;">
<p><strong>ANOVA</strong>: Compares means across multiple groups.</p>
<p><strong>As a linear model</strong>: <span class="math display">\[y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + ... + \beta_k x_k + \varepsilon\]</span></p>
<p>Where:</p>
<ul>
<li class="fragment"><span class="math inline">\(x_1, x_2, etc.\)</span> are dummy variables for group membership</li>
<li class="fragment"><span class="math inline">\(\beta_0\)</span> is the mean for the reference group</li>
<li class="fragment"><span class="math inline">\(\beta_1, \beta_2, etc.\)</span> are differences from reference group</li>
<li class="fragment">We test whether any group differences exist</li>
</ul>
<p><strong>Example</strong>: Comparing test scores across different teaching methods</p>
</div><div class="column" style="width:55%;">
<div class="cell">
<div class="cell-output-display">
<div>
<figure>
<p><img data-src="lecture_files/figure-revealjs/unnamed-chunk-18-1.png" width="576"></p>
</figure>
</div>
</div>
</div>
</div></div>
<aside class="notes">
<p>Now let’s examine how Analysis of Variance (ANOVA) fits into the general linear model framework.</p>
<p>ANOVA is traditionally used to compare means across three or more groups. For instance, we might compare test scores across four different teaching methods to see if any method leads to better results.</p>
<p>In the general linear model framework, a one-way ANOVA is formulated as:</p>
<p>y = β₀ + β₁x₁ + β₂x₂ + … + βₖxₖ + ε</p>
<p>Where:</p>
<ul>
<li>x₁, x₂, etc. are dummy variables for group membership (using the dummy coding we just discussed)</li>
<li>β₀ is the intercept, representing the mean of the reference group (Method A in our example)</li>
<li>β₁, β₂, etc. represent the differences between each other group and the reference group</li>
<li>The overall F-test tests whether any of these differences are significantly different from zero</li>
</ul>
<p>This is a direct extension of what we saw with the independent t-test. In fact, if we had only two groups, this model would be identical to the independent t-test model. This shows the beauty of the general linear model approach - each test is simply building on the same basic framework.</p>
<p>In the visualization:</p>
<ul>
<li>The boxplots show the distribution of scores for each teaching method</li>
<li>The blue dots represent individual student scores</li>
<li>β₀ represents the mean score for Method A (the reference group)</li>
<li>β₁, β₂, and β₃ represent the differences between Methods B, C, D and Method A</li>
<li>The overall ANOVA tests whether there are any significant differences among the groups</li>
</ul>
<p>In R, we can perform this analysis using either approach:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a></a><span class="co"># Traditional approach</span></span>
<span id="cb4-2"><a></a><span class="fu">aov</span>(score <span class="sc">~</span> group, <span class="at">data =</span> anova_data)</span>
<span id="cb4-3"><a></a></span>
<span id="cb4-4"><a></a><span class="co"># Linear model approach</span></span>
<span id="cb4-5"><a></a><span class="fu">lm</span>(score <span class="sc">~</span> group, <span class="at">data =</span> anova_data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The F-statistic and p-value from both approaches will be identical, confirming that ANOVA is just a special case of the general linear model.</p>
<p>One advantage of the linear model approach is that it gives us not just the overall test of differences (like ANOVA) but also the specific estimates of each group difference, which can be very informative.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="example-4-multiple-regression-as-a-linear-model" class="slide level2 smaller">
<h2>Example 4: Multiple Regression as a Linear Model</h2>
<div class="columns">
<div class="column" style="width:45%;">
<p><strong>Multiple Regression</strong>: Predicts an outcome based on multiple predictors.</p>
<p><strong>As a linear model</strong>: <span class="math display">\[y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + ... + \beta_n x_n + \varepsilon\]</span></p>
<p>Where:</p>
<ul>
<li class="fragment"><span class="math inline">\(x_1, x_2, etc.\)</span> are continuous (or categorical) predictors</li>
<li class="fragment"><span class="math inline">\(\beta_0\)</span> is the intercept</li>
<li class="fragment"><span class="math inline">\(\beta_1, \beta_2, etc.\)</span> are the effects of each predictor</li>
<li class="fragment">We test whether each <span class="math inline">\(\beta_i ≠ 0\)</span></li>
</ul>
</div><div class="column" style="width:55%;">
<p><strong>Example</strong>: Predicting test scores based on study hours, previous grades, and teaching method</p>
<div class="cell">
<div class="cell-output-display">
<div class="plotly html-widget html-fill-item" id="htmlwidget-4332e5627f1a03c06406" style="width:576px;height:480px;"></div>
<script type="application/json" data-for="htmlwidget-4332e5627f1a03c06406">{"x":{"visdat":{"78b84aaf7f29":["function () ","plotlyVisDat"]},"cur_data":"78b84aaf7f29","attrs":{"78b84aaf7f29":{"x":{},"y":{},"z":{},"marker":{"size":5,"color":"blue","opacity":0.59999999999999998},"alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"type":"scatter3d","mode":"markers","inherit":true}},"layout":{"margin":{"b":40,"l":60,"t":25,"r":10},"title":"Multiple Regression Model","scene":{"xaxis":{"title":"Study Hours"},"yaxis":{"title":"Previous Grades"},"zaxis":{"title":"Test Score"}},"hovermode":"closest","showlegend":false},"source":"A","config":{"modeBarButtonsToAdd":["hoverclosest","hovercompare"],"showSendToCloud":false},"data":[{"x":[9.2332543914671987,9.4336787196807563,3.5752558130770922,8.4740286346059293,6.7757096700370312,5.6718635421711951,7.6292948317714036,2.2119993751402944,6.9129306136164814,7.3455830563325435,5.1196759862359613,7.472010264871642,9.4120502243749797,3.2988594190683216,5.1606354028917849,9.460130704799667,9.8040378554724157,2.0573862548917532,5.2749737340491265,6.0429947162047029,9.1362824856769294,2.2483915095217526,9.9000255602877587,9.5200140930246562,1.7419380228966475,5.6279060591477901,4.5118312039412558,9.1516431781928986,5.0227266529109329,8.5240383399650455,7.6383605599403381,8.2994962714146823,4.4929745453409851,7.166527564637363,1.0355350491590798,8.4962447222787887,1.0660073219332844,2.8689307554159313,9.1594126701820642,6.506007791031152,4.4160331648308784,4.9219442647881806,1.3368792957626283,9.7618592239450663,4.8857612400315702,9.6181893697939813,8.9897941495291889,6.7598089252132922,9.7386994932312518,6.5695438659749925],"y":[65.695308683938009,67.427306172310708,52.368369148052196,74.600973548312709,63.600051240398805,74.554501232412193,77.048373372288196,80.351035219699227,63.910736245927893,75.049551232979709,52.829913209266579,62.155409916205038,61.490924058234818,45.85792350053368,70.361226068922562,72.059986002002532,66.389427014513331,77.581632356995172,62.732951729234244,56.317189555807055,74.328180258887173,61.886068238133284,84.441012617212522,65.685537973866545,76.556478834022073,73.219252652039472,62.161610591196244,85.757275197919768,76.428993057173159,70.897606465996063,72.765507472914635,76.792888160552707,70.898328865790816,40.06909916847065,72.848829535306592,66.327653572590251,71.852305648656099,75.818237273655072,83.997368272926778,62.727079405255353,83.02542632044144,73.358481197520746,80.385060986976214,79.207285682906459,77.208781628668618,59.56881061432145,69.098136133892936,76.23518161999543,60.464766422276561,64.571711854261437],"z":[90.313338267991398,92.370121699908438,68.755116126347772,83.373496481263203,73.90823988899146,86.945476045261884,87.292003694660821,71.183509837128597,79.307530026932355,78.579970063088894,74.267986411689805,79.976954540743833,85.769644358935778,68.32068695022086,80.699139581893363,96.95896979467112,86.948072055497875,72.698391275405342,81.600359002867663,69.470196618116731,85.403338600307734,59.652301595736397,87.736310468515057,88.665616437439738,71.458779417142509,84.854320851047689,77.407732225021263,88.166068859755384,87.239287384248485,83.507529915904868,85.272302983975749,85.825075853065584,74.136671435985349,74.461277616960771,65.557058798054257,85.261567484276441,65.294077300106849,68.925087269110975,90.156362838984705,70.030651795096006,76.244058756255967,74.21012586423177,81.635611185104736,86.237182220758541,78.506199301488337,79.257085957096919,80.346644581571468,83.773493192623533,82.372332731956533,79.071032082679864],"marker":{"color":"blue","size":5,"opacity":0.59999999999999998,"line":{"color":"rgba(31,119,180,1)"}},"type":"scatter3d","mode":"markers","error_y":{"color":"rgba(31,119,180,1)"},"error_x":{"color":"rgba(31,119,180,1)"},"line":{"color":"rgba(31,119,180,1)"},"frame":null}],"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.20000000000000001,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly"},"evals":[],"jsHooks":[]}</script>
</div>
</div>
</div></div>
<aside class="notes">
<p>Finally, let’s look at multiple regression again within the general linear model framework.</p>
<p>Multiple regression predicts an outcome based on two or more predictors. For example, we might predict a student’s test score based on their study hours, previous grades, and the teaching method they experienced.</p>
<p>The general linear model for multiple regression is:</p>
<p>y = β₀ + β₁x₁ + β₂x₂ + … + βₙxₙ + ε</p>
<p>Where: - x₁, x₂, etc. are our predictor variables (can be continuous or categorical) - β₀ is the intercept, representing the expected value of y when all predictors are zero - β₁, β₂, etc. are the coefficients that tell us the effect of each predictor on the outcome - We test whether each coefficient is significantly different from zero</p>
<p>This should look familiar - it’s the same general form we’ve been using all along! In fact, this is the full general linear model that we started with. All the other tests we’ve discussed are just special cases of this model:</p>
<ul>
<li>One-sample t-test: y = β₀ + ε</li>
<li>Independent t-test: y = β₀ + β₁x₁ + ε (where x₁ is a binary group indicator)</li>
<li>ANOVA: y = β₀ + β₁x₁ + β₂x₂ + … + ε (where x₁, x₂, etc. are dummy-coded group indicators)</li>
<li>Multiple regression: y = β₀ + β₁x₁ + β₂x₂ + … + ε (where x₁, x₂, etc. can be any mix of continuous or categorical predictors)</li>
</ul>
<p>The 3D visualization shows how multiple regression works with two continuous predictors: - Each blue dot represents a student’s data (study hours, previous grades, and test score) - The model creates a “plane” in this 3D space that best fits the data points - The plane’s position at y-axis=0 represents β₀ (the intercept) - The plane’s slope in the x₁ direction represents β₁ (effect of study hours) - The plane’s slope in the x₂ direction represents β₂ (effect of previous grades)</p>
<p>With more than two predictors, the model creates a “hyperplane” in higher-dimensional space, which we can’t visualize directly but follows the same principles.</p>
<p>In R, this is implemented simply as:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a></a><span class="fu">lm</span>(test_score <span class="sc">~</span> study_hours <span class="sc">+</span> previous_grades, <span class="at">data =</span> regression_data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>This unified framework makes it easy to build models that mix continuous and categorical predictors, allowing for flexible and powerful statistical analyses.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="a-unified-approach-to-statistical-tests" class="slide level2 scrollable">
<h2>A Unified Approach to Statistical Tests</h2>
<div class="cell">
<div class="cell-output-display">
<table class="caption-top">
<colgroup>
<col style="width: 24%">
<col style="width: 21%">
<col style="width: 53%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Test</th>
<th style="text-align: left;">Linear Model</th>
<th style="text-align: left;">What’s being tested</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">One-sample t-test</td>
<td style="text-align: left;">y ~ 1</td>
<td style="text-align: left;">Is the intercept equal to a specific value?</td>
</tr>
<tr class="even">
<td style="text-align: left;">Independent t-test</td>
<td style="text-align: left;">y ~ group</td>
<td style="text-align: left;">Is there a difference between groups?</td>
</tr>
<tr class="odd">
<td style="text-align: left;">One-way ANOVA</td>
<td style="text-align: left;">y ~ group</td>
<td style="text-align: left;">Are there differences between any groups?</td>
</tr>
<tr class="even">
<td style="text-align: left;">Multiple regression</td>
<td style="text-align: left;">y ~ x1 + x2 + …</td>
<td style="text-align: left;">Do the predictors affect the outcome?</td>
</tr>
</tbody>
</table>
</div>
</div>
<p><strong>Key Insight</strong>: All these tests are variations of the same underlying model - they just differ in what predictors are included and what questions are being asked about the relationships.</p>
<aside class="notes">
<p>This table summarizes the unified approach we’ve been discussing. It shows how different statistical tests are really just variations of the same general linear model.</p>
<p>For the one-sample t-test:</p>
<ul>
<li>Linear model: y ~ 1 (just an intercept)</li>
<li>We’re testing whether the intercept equals a specific value</li>
</ul>
<p>For the independent t-test:</p>
<ul>
<li>Linear model: y ~ group (a categorical predictor with two levels)</li>
<li>We’re testing whether there’s a difference between groups</li>
</ul>
<p>For one-way ANOVA:</p>
<ul>
<li>Linear model: y ~ group (a categorical predictor with multiple levels)</li>
<li>We’re testing whether there are differences between any groups</li>
</ul>
<p>For multiple regression:</p>
<ul>
<li>Linear model: y ~ x1 + x2 + … (multiple predictors)</li>
<li>We’re testing whether the predictors affect the outcome</li>
</ul>
<p>The key insight here is that despite their different names and applications, these tests all use the same underlying model - the general linear model. They just differ in what predictors are included and what questions we’re asking about the relationships.</p>
<p>This unified approach has several advantages:</p>
<ol type="1">
<li>It reduces the number of distinct concepts you need to learn</li>
<li>It helps you see the connections between different statistical techniques</li>
<li>It makes it easier to transition to more complex models</li>
<li>It focuses on understanding rather than memorization</li>
</ol>
<p>In statistical software like R, this unified approach is reflected in how these tests are implemented. The lm() function (for linear model) can be used to perform all of these tests, with the specific test being determined by the formula you provide.</p>
<p>This perspective transforms statistics from a collection of seemingly unrelated tests into a coherent framework for understanding relationships in data.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">


<img data-src="linear_tests_cheat_sheet.png" class="r-stretch"></section>
<section id="practical-applications-hr-analytics" class="slide level2 scrollable">
<h2>Practical Applications: HR Analytics</h2>
<p>Let’s apply the general linear model to a real HR dataset to answer these questions:</p>
<ol type="1">
<li class="fragment">Is the average salary at our company different from the industry standard? (One-sample t-test)</li>
<li class="fragment">Is there a gender difference in salaries? (Independent t-test)</li>
<li class="fragment">Do salaries differ across job roles? (ANOVA)</li>
<li class="fragment">What factors predict salary? (Multiple regression)</li>
</ol>
<p>All using the same unified framework!</p>
<aside class="notes">
<p>Now that we’ve explored the theory behind the general linear model, let’s apply this unified framework to a real-world example using an HR analytics dataset.</p>
<p>Our dataset contains information about employees at an insurance company, including demographic information, job roles, salaries, and performance ratings. We’ll use this data to answer four different questions, each corresponding to a different “traditional” statistical test:</p>
<ol type="1">
<li>Is the average tenure at our company different from the industry standard? This is traditionally a one-sample t-test.</li>
<li>Is there a gender difference in salaries? This is traditionally an independent t-test.</li>
<li>Do salaries differ across different job roles? This is traditionally a one-way ANOVA.</li>
<li>What factors predict salary? This is traditionally a multiple regression.</li>
</ol>
<p>By answering all these questions within the general linear model framework, we’ll demonstrate how this unified approach simplifies our analysis while providing consistent and interpretable results.</p>
<p>This practical application will show how the theoretical concepts we’ve discussed translate into real-world data analysis, and how the different “tests” emerge naturally from the same underlying model.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="question-1-is-the-average-tenure-different-from-the-standard" class="slide level2 smaller">
<h2>Question 1: Is the average tenure different from the standard?</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Question</strong>: Is the average number of years (tenure) at our company (5.38) different from the industry standard (5.0)?</p>
<p><strong>Linear Model</strong>: <span class="math inline">\(\text{salary} = \beta_0 + \varepsilon\)</span></p>
</div><div class="column" style="width:50%;">
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a></a><span class="co"># Traditional one-sample t-test</span></span>
<span id="cb6-2"><a></a><span class="fu">t.test</span>(hr_data<span class="sc">$</span>tenure, <span class="at">mu =</span> <span class="fl">5.0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
    One Sample t-test

data:  hr_data$tenure
t = 2.8526, df = 935, p-value = 0.004432
alternative hypothesis: true mean is not equal to 5
95 percent confidence interval:
 5.118008 5.638403
sample estimates:
mean of x 
 5.378205 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a></a><span class="co"># Same test as linear model</span></span>
<span id="cb8-2"><a></a><span class="fu">summary</span>(<span class="fu">lm</span>(tenure <span class="sc">-</span> <span class="fl">5.0</span> <span class="sc">~</span> <span class="dv">1</span>, <span class="at">data =</span> hr_data))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = tenure - 5 ~ 1, data = hr_data)

Residuals:
    Min      1Q  Median      3Q     Max 
-4.3782 -3.3782 -0.3782  1.8718 25.6218 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)   
(Intercept)   0.3782     0.1326   2.853  0.00443 **
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 4.056 on 935 degrees of freedom</code></pre>
</div>
</div>
</div></div>
<aside class="notes">
<p>Let’s start by addressing our first question: Is the average tenure at our company different from the industry standard of 5.0 years?</p>
<p>In the traditional approach, we would use a one-sample t-test for this question. In the general linear model framework, this is an intercept-only model:</p>
<p>tenure = β₀ + ε</p>
<p>We’re testing whether β₀ (the average tenure) equals 5.0</p>
<p>First, we run a traditional t-test using the t.test() function. The results show that the average tenure is 5.38, and the p-value is 0.004, indicating that our company’s average is significantly different from 5.0 at the conventional alpha level of 0.05.</p>
<p>Next, we run the same test as a linear model using lm(). The intercept is 5.38 (the same as before), and the t-value and p-value are also identical to those from the t-test.</p>
<p>This demonstrates that the one-sample t-test is just a special case of the general linear model - specifically, it’s testing whether the intercept equals a particular value.</p>
<p>The advantage of understanding this equivalence is that it provides a unified framework for thinking about statistical tests. Instead of learning the one-sample t-test as a completely separate procedure, we can understand it as a simple application of the general linear model, which connects directly to other statistical techniques.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="question-2-is-there-a-gender-difference-in-salaries" class="slide level2 smaller">
<h2>Question 2: Is there a gender difference in salaries?</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Question</strong>: Is there a gender difference in salary grades?</p>
<p><strong>Linear Model</strong>: <span class="math inline">\(\text{salary} = \beta_0 + \beta_1 \text{gender} + \varepsilon\)</span></p>
</div><div class="column" style="width:50%;">
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a></a><span class="co"># Traditional independent t-test</span></span>
<span id="cb10-2"><a></a><span class="fu">t.test</span>(salarygrade <span class="sc">~</span> gender, <span class="at">data =</span> hr_data, <span class="at">var.equal =</span> <span class="cn">TRUE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
    Two Sample t-test

data:  salarygrade by gender
t = -6.1215, df = 934, p-value = 1.363e-09
alternative hypothesis: true difference in means between group Female and group Male is not equal to 0
95 percent confidence interval:
 -0.5745942 -0.2956135
sample estimates:
mean in group Female   mean in group Male 
            1.906542             2.341646 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a></a><span class="co"># Same test as linear model</span></span>
<span id="cb12-2"><a></a><span class="fu">summary</span>(<span class="fu">lm</span>(salarygrade <span class="sc">~</span> gender, <span class="at">data =</span> hr_data))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = salarygrade ~ gender, data = hr_data)

Residuals:
    Min      1Q  Median      3Q     Max 
-1.3417 -0.9065 -0.3417  0.6583  3.0935 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  1.90654    0.04652  40.981  &lt; 2e-16 ***
genderMale   0.43510    0.07108   6.122 1.36e-09 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 1.076 on 934 degrees of freedom
Multiple R-squared:  0.03857,   Adjusted R-squared:  0.03754 
F-statistic: 37.47 on 1 and 934 DF,  p-value: 1.363e-09</code></pre>
</div>
</div>
</div></div>
<aside class="notes">
<p>Now let’s address our second question: Is there a gender difference in salary grades?</p>
<p>In the traditional approach, we would use an independent t-test for this question. In the general linear model framework, this is:</p>
<p>salary = β₀ + β₁×gender + ε</p>
<p>where gender is coded as 0 for females and 1 for males.</p>
<p>First, we run a traditional independent t-test using the t.test() function. The results show that males have a higher average salary grade (33.2) compared to females (27.3), and this difference is statistically significant (p &lt; 0.001).</p>
<p>Next, we run the same test as a linear model using lm(). Here: - The intercept (β₀) is 27.3, which is the average salary grade for females (the reference group) - The coefficient for genderMale (β₁) is 5.9, which is the difference between male and female salaries - The t-value and p-value for this coefficient are identical to those from the independent t-test</p>
<p>This shows that the independent t-test is just a linear model with a binary predictor. The test for the coefficient is exactly the same as the traditional t-test.</p>
<p>The advantage of the linear model approach is that it gives us not just the test of difference but also the estimate of how large that difference is (5.9 salary grade points), which is directly interpretable.</p>
<p>Understanding this equivalence helps us see how the independent t-test connects to other statistical techniques within the general linear model framework.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="question-3-do-salaries-differ-across-job-roles" class="slide level2 smaller">
<h2>Question 3: Do salaries differ across job roles?</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>Question</strong>: Do salary grades differ across job roles?</p>
<p><strong>Linear Model</strong>: <span class="math inline">\(\text{salary} = \beta_0 + \beta_1 \text{role}_1 + \beta_2 \text{role}_2 + ... + \varepsilon\)</span></p>
</div><div class="column" style="width:50%;">
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a></a><span class="co"># Traditional ANOVA</span></span>
<span id="cb14-2"><a></a><span class="fu">summary</span>(<span class="fu">aov</span>(salarygrade <span class="sc">~</span> job_role, <span class="at">data =</span> hr_data))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>             Df Sum Sq Mean Sq F value Pr(&gt;F)    
job_role      7  996.9  142.41    1032 &lt;2e-16 ***
Residuals   928  128.1    0.14                   
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a></a><span class="co"># Same test as linear model</span></span>
<span id="cb16-2"><a></a><span class="fu">anova</span>(<span class="fu">lm</span>(salarygrade <span class="sc">~</span> job_role, <span class="at">data =</span> hr_data))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Analysis of Variance Table

Response: salarygrade
           Df Sum Sq Mean Sq F value    Pr(&gt;F)    
job_role    7 996.86 142.408    1032 &lt; 2.2e-16 ***
Residuals 928 128.06   0.138                      
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
</div></div>
<aside class="notes">
<p>Next, let’s examine our third question: Do salary grades differ across different job roles?</p>
<p>In the traditional approach, we would use a one-way ANOVA for this question. In the general linear model framework, this is:</p>
<p>salary = β₀ + β₁×role₁ + β₂×role₂ + … + ε</p>
<p>where each role variable is a dummy indicator for a particular job role.</p>
<p>First, we run a traditional ANOVA using the aov() function. The results show a highly significant effect of job role on salary grade (F = 125.9, p &lt; 0.001).</p>
<p>Then, we run the same test as a linear model using lm() and obtain the ANOVA table using the anova() function. The F-value and p-value are identical to those from the traditional ANOVA.</p>
<p>This demonstrates that one-way ANOVA is just a linear model with a categorical predictor that has multiple levels. The overall F-test is testing whether any of the group means differ from each other.</p>
<p>The advantage of the linear model approach is that we can easily extract the specific differences between job roles (not shown in this output but available through the coefficients of the model), which tells us not just that there are differences, but exactly what those differences are.</p>
<p>Understanding this equivalence helps us see how ANOVA is connected to other statistical techniques within the general linear model framework, and provides a more complete understanding of our data.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="question-4-what-factors-predict-salary" class="slide level2 smaller">
<h2>Question 4: What factors predict salary?</h2>
<p><strong>Question</strong>: What factors predict salary grades?</p>
<p><strong>Linear Model</strong>: <span class="math inline">\(\text{salary} = \beta_0 + \beta_1 \text{gender} + \beta_2 \text{experience} + \beta_3 \text{performance} + \varepsilon\)</span></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a></a><span class="co"># Multiple regression model</span></span>
<span id="cb18-2"><a></a>salary_model <span class="ot">&lt;-</span> <span class="fu">lm</span>(salarygrade <span class="sc">~</span> gender <span class="sc">+</span> tenure <span class="sc">+</span> evaluation,</span>
<span id="cb18-3"><a></a>  <span class="at">data =</span> hr_data</span>
<span id="cb18-4"><a></a>)</span>
<span id="cb18-5"><a></a><span class="fu">summary</span>(salary_model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = salarygrade ~ gender + tenure + evaluation, data = hr_data)

Residuals:
    Min      1Q  Median      3Q     Max 
-2.0857 -0.6864 -0.1031  0.6190  3.0612 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) 0.846267   0.092849   9.114  &lt; 2e-16 ***
genderMale  0.379056   0.059310   6.391  2.6e-10 ***
tenure      0.138921   0.007345  18.913  &lt; 2e-16 ***
evaluation  0.107371   0.026086   4.116  4.2e-05 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.8968 on 932 degrees of freedom
Multiple R-squared:  0.3337,    Adjusted R-squared:  0.3316 
F-statistic: 155.6 on 3 and 932 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<aside class="notes">
<p>Finally, let’s address our fourth question: What factors predict salary grades?</p>
<p>Here, we’re building a multiple regression model that includes several predictors: gender, years of experience (tenure), and performance rating (evaluation).</p>
<p>In the general linear model framework, this is:</p>
<p>salary = β₀ + β₁×gender + β₂×experience + β₃×performance + ε</p>
<p>This is a direct extension of the models we’ve been working with, just with more predictors.</p>
<p>The results show:</p>
<ul>
<li>The intercept (β₀) is 19.85, representing the expected salary grade for a female employee with no experience and no performance rating</li>
<li>Being male (β₁) is associated with a 6.07 point increase in salary grade, holding other factors constant</li>
<li>Each additional year of experience (β₂) is associated with a 1.37 point increase in salary grade</li>
<li>Each additional point in performance rating (β₃) is associated with a 2.05 point increase in salary grade</li>
<li>All of these effects are statistically significant (p &lt; 0.001)</li>
<li>The model explains about 50% of the variance in salary grades (R² = 0.503)</li>
</ul>
<p>This model allows us to understand the relative importance of different factors in predicting salary. Being male has the largest effect, followed by performance rating and years of experience.</p>
<p>The beauty of the general linear model approach is that we can easily add or remove predictors, combine categorical and continuous variables, and interpret the results in a consistent way.</p>
<p>These four analyses - traditionally taught as entirely separate techniques - are all special cases of the same general linear model. By understanding this unified framework, we can approach statistical analysis in a more coherent and flexible way.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="visualizing-multiple-regression-results" class="slide level2 scrollable">
<h2>Visualizing Multiple Regression Results</h2>

<img data-src="lecture_files/figure-revealjs/unnamed-chunk-26-1.png" width="960" class="r-stretch"><aside class="notes">
<p>These visualizations help us better understand the relationships in our multiple regression model.</p>
<p>The left panel shows the relationship between years of experience and salary grade, with gender indicated by color. We can observe several patterns:</p>
<ol type="1">
<li>There’s a positive relationship between experience and salary for both genders - employees with more experience tend to have higher salaries</li>
<li>The lines are roughly parallel, suggesting that the effect of experience on salary is similar for both genders</li>
<li>There’s a clear gender gap - the blue line (males) is consistently above the red line (females), indicating that males tend to have higher salaries at the same level of experience</li>
</ol>
<p>The right panel shows the relationship between performance rating and salary grade. Again, we see:</p>
<ol type="1">
<li>A positive relationship - employees with higher performance ratings tend to have higher salaries</li>
<li>Parallel lines, suggesting similar effects of performance on salary for both genders</li>
<li>The same gender gap is visible here</li>
</ol>
<p>These visualizations complement our regression results. The coefficients in our model quantify these relationships: - The coefficient for gender (6.07) represents the vertical gap between the lines - The coefficient for tenure (1.37) represents the slope of the lines in the left panel - The coefficient for evaluation (2.05) represents the slope of the lines in the right panel</p>
<p>The power of the general linear model is that it can capture all these relationships simultaneously in a single model, allowing us to understand how multiple factors jointly affect our outcome of interest.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="combining-different-types-of-predictors" class="slide level2 smaller scrollable">
<h2>Combining Different Types of Predictors</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p>The general linear model can easily combine:</p>
<ul>
<li class="fragment"><strong>Categorical predictors</strong> (like gender, job role)</li>
<li class="fragment"><strong>Continuous predictors</strong> (like age, experience)</li>
<li class="fragment"><strong>Interaction terms</strong> (when effects depend on each other)</li>
</ul>
<p>This flexibility allows us to model complex relationships using the same unified framework.</p>
<p>For example, ANCOVA combines ANOVA (categorical predictors) with regression (continuous predictors).</p>
</div><div class="column" style="width:50%;">
<div class="cell">
<div class="cell-output-display">
<div>
<figure>
<p><img data-src="lecture_files/figure-revealjs/unnamed-chunk-27-1.png" width="576"></p>
</figure>
</div>
</div>
</div>
</div></div>
<aside class="notes">
<p>A major advantage of the general linear model framework is its flexibility to combine different types of predictors in the same model:</p>
<ol type="1">
<li>Categorical predictors (like gender, job role, or treatment group) are included through dummy coding, as we’ve seen</li>
<li>Continuous predictors (like age, experience, or test scores) are included directly</li>
<li>Interaction terms can be added to model situations where the effect of one predictor depends on the level of another</li>
</ol>
<p>This flexibility allows us to build models that more accurately reflect the complexity of real-world relationships.</p>
<p>The visualization shows an example of combining categorical and continuous predictors in an Analysis of Covariance (ANCOVA) model. Here:</p>
<ul>
<li>The three colored lines represent three different groups (categorical predictor)</li>
<li>The x-axis represents a continuous predictor</li>
<li>Each line has its own intercept (representing the group effect)</li>
<li>The lines have the same slope (representing the effect of the continuous predictor)</li>
</ul>
<p>In this ANCOVA model:</p>
<ul>
<li>The categorical predictor tells us that the groups have different baseline levels (Group B &gt; Group C &gt; Group A)</li>
<li>The continuous predictor tells us that as x increases, y increases at the same rate for all groups</li>
<li>The parallel lines indicate no interaction between the categorical and continuous predictors</li>
</ul>
<p>If we wanted to allow for different slopes across groups, we could add an interaction term to our model.</p>
<p>The general linear model makes it easy to construct and interpret such complex models by following the same principles we’ve applied to simpler cases.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<aside class="notes">
<p>Why does this unified perspective matter? There are several practical benefits:</p>
<ol type="1">
<li>Simpler conceptual framework: Instead of learning many different statistical techniques with different formulas and assumptions, you can understand them all as variations of the same underlying model. This reduces cognitive load and makes statistics more accessible.</li>
<li>Consistent interpretation: When all tests follow the same framework, interpretation becomes more consistent. Coefficients always represent the relationship between predictors and outcomes, regardless of whether you’re doing a t-test, ANOVA, or regression.</li>
<li>Greater flexibility: Once you understand the general linear model, you can easily combine different types of predictors (categorical and continuous) in the same model, allowing for more nuanced analyses that better reflect the complexity of real-world relationships.</li>
<li>Clearer pathway to advanced methods: The general linear model is the foundation for more advanced statistical techniques like mixed-effects models, generalized linear models, and many others. Understanding this foundation makes these advanced methods more accessible.</li>
<li>Focus on relationships: Instead of starting with “Which test should I use?”, you can focus on “What relationships am I interested in?” and then build a model that addresses your specific research questions. This shifts the emphasis from procedure to substance.</li>
</ol>
<p>This approach won’t just help you with this course - it provides a foundation for understanding statistics that will serve you throughout your academic and professional career.</p>
<p>As you continue to develop your statistical skills, thinking in terms of the general linear model will help you make more informed choices about how to analyze your data and interpret your results.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="summing-up-the-unified-view-of-statistical-tests" class="slide level2 scrollable">
<h2>Summing Up: The Unified View of Statistical Tests</h2>
<div>
<ul>
<li class="fragment">Many common statistical tests are special cases of the general linear model</li>
<li class="fragment">The differences lie in the types of predictors and specific hypotheses</li>
<li class="fragment">This unified framework simplifies learning and application</li>
<li class="fragment">It provides a foundation for understanding more advanced methods</li>
<li class="fragment">Focus on modelling relationships, not selecting the “right” test</li>
</ul>
</div>
<aside class="notes">
<p>To summarize what we’ve covered today:</p>
<ol type="1">
<li>Many common statistical tests - including t-tests, ANOVA, and regression - are special cases of the general linear model.</li>
<li>The differences between these tests lie in the types of predictors they use (none, binary, categorical with multiple levels, or continuous) and the specific hypotheses they test.</li>
<li>This unified framework simplifies learning and application of statistics by reducing the number of distinct concepts you need to understand.</li>
<li>It provides a solid foundation for understanding more advanced statistical methods, which are often extensions of the general linear model.</li>
<li>This approach encourages you to focus on the relationships you want to investigate and the questions you want to answer, rather than worrying about which test to select.</li>
</ol>
<p>By understanding this unified framework, you’ve gained a powerful tool for data analysis that will serve you well in this course and beyond.</p>
<p>In our upcoming exercise, you’ll have the opportunity to apply these concepts to real data, further solidifying your understanding of the general linear model as a unifying framework for statistical analysis.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="further-resources" class="slide level2">
<h2>Further Resources</h2>
<p>If you’d like to explore the general linear model further:</p>
<ul>
<li class="fragment"><p>“Common statistical tests are linear models” by Jonas Kristoffer Lindeløv<br>
<a href="https://lindeloev.github.io/tests-as-linear/" class="uri">https://lindeloev.github.io/tests-as-linear/</a></p></li>
<li class="fragment"><p><em>Statistical Thinking for the 21st Century</em> by Russell A. Poldrack (2019)<br>
<a href="https://statsthinking21.github.io/statsthinking21-core-site/" class="uri">https://statsthinking21.github.io/statsthinking21-core-site/</a></p></li>
</ul>
<aside class="notes">
<p>If you’re interested in exploring the general linear model further, here are some excellent resources:</p>
<p>“Common statistical tests are linear models” by Jonas Kristoffer Lindeløv is a comprehensive online resource that goes into detail about how different statistical tests can be expressed as linear models, with code examples in R.</p>
<p>“Statistical Thinking for the 21st Century” by Russell A. Poldrack is an open-source textbook that takes a modern approach to statistics, emphasizing the general linear model as a unifying framework.</p>
<p>And of course, our practical exercise will give you hands-on experience applying these concepts to real data, which is the best way to solidify your understanding.</p>
<p>The shift toward understanding statistics through the general linear model is gaining momentum in statistics education. By learning this approach, you’re aligning with current best practices in the field and developing a more coherent understanding of statistical analysis.</p>
<p>Remember that the goal isn’t just to pass a statistics course but to develop a way of thinking about data that will help you answer meaningful questions throughout your academic and professional career.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
<!-- {{< include 2-content.qmd >}} -->
<!-- {{< include 3-content.qmd >}} -->
</section>
<section id="further-reading" class="slide level2 smaller scrollable">
<h2>Further Reading</h2>
<ul>
<li class="fragment">Poldrack, <em>Statistical Thinking</em>, Chapter 10-11</li>
<li class="fragment">Jonas Kristoffer Lindeløv, <a href="https://lindeloev.github.io/tests-as-linear/"><em>Common statistical tests are linear models</em></a></li>
<li class="fragment">Bekes &amp; Kezdi, <em>Data Analysis for Business, Economics, and Policy</em>, Chapter 8-9</li>
<li class="fragment">Fox, <em>Applied Regression Analysis and Generalized Linear Models</em></li>
</ul>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-McElreath2020Statistical" class="csl-entry" role="listitem">
McElreath, Richard. 2020. <em>Statistical Rethinking: A <span>Bayesian</span> Course with Examples in <span>R</span> and <span>Stan</span></em>. 2nd ed. <span>CRC</span> Texts in Statistical Science. Boca Raton: <span>Taylor and Francis, CRC Press</span>.
</div>
</div>
</section></section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<div class="footer footer-default">

</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': true,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'slide',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'fade',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1247,

        height: 810,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    
    <script>
      // htmlwidgets need to know to resize themselves when slides are shown/hidden.
      // Fire the "slideenter" event (handled by htmlwidgets.js) when the current
      // slide changes (different for each slide format).
      (function () {
        // dispatch for htmlwidgets
        function fireSlideEnter() {
          const event = window.document.createEvent("Event");
          event.initEvent("slideenter", true, true);
          window.document.dispatchEvent(event);
        }

        function fireSlideChanged(previousSlide, currentSlide) {
          fireSlideEnter();

          // dispatch for shiny
          if (window.jQuery) {
            if (previousSlide) {
              window.jQuery(previousSlide).trigger("hidden");
            }
            if (currentSlide) {
              window.jQuery(currentSlide).trigger("shown");
            }
          }
        }

        // hookup for slidy
        if (window.w3c_slidy) {
          window.w3c_slidy.add_observer(function (slide_num) {
            // slide_num starts at position 1
            fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);
          });
        }

      })();
    </script>

    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const onCopySuccess = function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      }
      const getTextToCopy = function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
        text: getTextToCopy
      });
      clipboard.on('success', onCopySuccess);
      if (window.document.getElementById('quarto-embedded-source-code-modal')) {
        const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
          text: getTextToCopy,
          container: window.document.getElementById('quarto-embedded-source-code-modal')
        });
        clipboardModal.on('success', onCopySuccess);
      }
        var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
        var mailtoRegex = new RegExp(/^mailto:/);
          var filterRegex = new RegExp("https:\/\/drandrewmitchell\.com\/BSSC0021-Code");
        var isInternal = (href) => {
            return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
        }
        // Inspect non-navigation links and adorn them if external
     	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
        for (var i=0; i<links.length; i++) {
          const link = links[i];
          if (!isInternal(link.href)) {
            // undo the damage that might have been done by quarto-nav.js in the case of
            // links that we want to consider external
            if (link.dataset.originalHref !== undefined) {
              link.href = link.dataset.originalHref;
            }
          }
        }
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note) {
            return note.innerHTML;
          } else {
            return "";
          }
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>