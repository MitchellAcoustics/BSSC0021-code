<!DOCTYPE html>
<html lang="en"><head>
<link href="../assets/stat_bear.png" rel="icon" type="image/png">
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-html/tabby.min.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.6.40">

  <meta name="author" content="Dr Andrew Mitchell">
  <title>BSSC0021 – Multiple Linear Regression and ANOVA as Linear Models</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      { color: #003b4f; background-color: #f1f3f5; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #003b4f; } /* Normal */
    code span.al { color: #ad0000; } /* Alert */
    code span.an { color: #5e5e5e; } /* Annotation */
    code span.at { color: #657422; } /* Attribute */
    code span.bn { color: #ad0000; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #003b4f; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #20794d; } /* Char */
    code span.cn { color: #8f5902; } /* Constant */
    code span.co { color: #5e5e5e; } /* Comment */
    code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
    code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
    code span.dt { color: #ad0000; } /* DataType */
    code span.dv { color: #ad0000; } /* DecVal */
    code span.er { color: #ad0000; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #ad0000; } /* Float */
    code span.fu { color: #4758ab; } /* Function */
    code span.im { color: #00769e; } /* Import */
    code span.in { color: #5e5e5e; } /* Information */
    code span.kw { color: #003b4f; font-weight: bold; } /* Keyword */
    code span.op { color: #5e5e5e; } /* Operator */
    code span.ot { color: #003b4f; } /* Other */
    code span.pp { color: #ad0000; } /* Preprocessor */
    code span.sc { color: #5e5e5e; } /* SpecialChar */
    code span.ss { color: #20794d; } /* SpecialString */
    code span.st { color: #20794d; } /* String */
    code span.va { color: #111111; } /* Variable */
    code span.vs { color: #20794d; } /* VerbatimString */
    code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="../site_libs/revealjs/dist/theme/quarto-ed3ab02270332a7a204096c38dcfffc3.css">
  <link href="../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" data-background-image="https://stat20.berkeley.edu/fall-2024/2-summarizing-data/03-a-grammar-of-graphics/images/plot-collage.png" data-background-position="right 0% bottom 50%" data-background-size="50%" class="quarto-title-block center">
  <h1 class="title">Multiple Linear Regression and ANOVA as Linear Models</h1>
  <p class="subtitle">Unifying Statistical Approaches</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Dr Andrew Mitchell <a href="https://orcid.org/0000-0003-0978-5046" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a>
</div>
<div class="quarto-title-author-email">
<a href="mailto:a.j.mitchell@ucl.ac.uk">a.j.mitchell@ucl.ac.uk</a>
</div>
        <p class="quarto-title-affiliation">
            Lecturer in AI and Machine Learning for Sustainable Construction
          </p>
    </div>
</div>

</section>
<section id="overview" class="slide level2">
<h2>Overview</h2>
<ul>
<li class="fragment">The general linear model as a unifying framework</li>
<li class="fragment">Understanding how various statistical tests are related</li>
<li class="fragment">Practical applications with real datasets</li>
</ul>
</section>
<section id="focus-unified-statistical-thinking" class="slide level2">
<h2>Focus: Unified Statistical Thinking</h2>
<ul>
<li class="fragment">Moving beyond isolated statistical techniques</li>
<li class="fragment">Seeing connections between t-tests, ANOVA, and regression</li>
<li class="fragment">Understanding the common mathematical framework</li>
<li class="fragment">Simplifying the interpretation of statistical models</li>
</ul>
</section>
<section id="what-well-cover" class="slide level2">
<h2>What We’ll Cover</h2>
<ul>
<li class="fragment">The general linear model framework</li>
<li class="fragment">Building from simple models to complex models</li>
<li class="fragment">ANOVA as a special case of linear models</li>
<li class="fragment">Working with multivariate data</li>
<li class="fragment">Applications to real-world problems</li>
</ul>
<aside class="notes">
<p>This lecture introduces the concept of the general linear model as a unifying framework for various statistical techniques. By understanding this framework, students will gain a deeper appreciation for how different statistical tests are related to each other.</p>
<p>Key points to emphasize:</p>
<ul>
<li>The power of seeing statistics through a unified lens</li>
<li>How this approach simplifies understanding and application</li>
<li>The practical benefits of this perspective when working with real data</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="learning-objectives" class="slide level2">
<h2>Learning Objectives</h2>
<div class="columns">
<div class="column" style="width:60%;">
<div>
<ul>
<li class="fragment">Understand the general linear model framework</li>
<li class="fragment">Recognize how t-tests, ANOVA, and regression are connected</li>
<li class="fragment">Apply linear modeling to analyze multivariate data</li>
<li class="fragment">Interpret interaction effects in multifactor designs</li>
<li class="fragment">Gain practical experience with HR and fuel consumption datasets</li>
</ul>
</div>
</div><div class="column" style="width:40%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="https://images.unsplash.com/photo-1551288049-bebda4e38f71?q=80&amp;w=2070&amp;auto=format&amp;fit=crop.png"></p>
<figcaption>Linear models are the foundation of many statistical techniques</figcaption>
</figure>
</div>
</div></div>
</section>
<section>
<section id="the-general-linear-model-as-a-foundation" class="title-slide slide level1 center" data-background-color="#1E3D59">
<h1>The General Linear Model as a Foundation</h1>

</section>
<section id="the-beauty-of-unified-statistical-thinking" class="slide level2">
<h2>The Beauty of Unified Statistical Thinking</h2>
<div>
<p>Adapted from:</p>
<ul>
<li><a href="https://statsthinking21.github.io/statsthinking21-core-site/"><em>Statistical Thinking</em></a>, Chapter 10-11. Russell A. Poldrack (2019).</li>
<li><a href="https://lindeloev.github.io/tests-as-linear/"><em>Common statistical tests are linear models</em></a>. Jonas Kristoffer Lindeløv (2019).</li>
</ul>
</div>
<aside class="notes">
<p>In traditional statistics education, students often learn about different statistical tests as if they were distinct techniques with different formulas, assumptions, and applications. This can make statistics feel like a collection of disconnected tools rather than a coherent framework. In reality, many common statistical tests can be understood as special cases of the same underlying model: the general linear model.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="the-beauty-of-unified-statistical-thinking-1" class="slide level2">
<h2>The Beauty of Unified Statistical Thinking</h2>
<p>What if I told you that many of the statistical techniques you’ve learned are actually the same model?</p>
<div class="columns">
<div class="column" style="width:55%;">
<p>Consider these seemingly different tests:</p>
<ul>
<li class="fragment">One-sample t-test</li>
<li class="fragment">Independent samples t-test</li>
<li class="fragment">ANOVA</li>
<li class="fragment">Multiple regression</li>
</ul>
<p><strong>All</strong> of these can be represented using the same underlying linear model framework.</p>
</div><div class="column" style="width:45%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="https://www.kellogg.northwestern.edu/faculty/weber/jmet/papers/glm.jpg"></p>
<figcaption>Statistical techniques connected via linear models</figcaption>
</figure>
</div>
</div></div>
</section>
<section id="the-general-linear-model-framework" class="slide level2">
<h2>The General Linear Model Framework</h2>
<p>The general linear model can be expressed as:</p>
<p><span class="math display">\[y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + ... + \beta_n x_n + \varepsilon\]</span></p>
<p>Where:</p>
<ul>
<li class="fragment"><span class="math inline">\(y\)</span> is the outcome variable</li>
<li class="fragment"><span class="math inline">\(\beta_0\)</span> is the intercept</li>
<li class="fragment"><span class="math inline">\(\beta_1, \beta_2, ..., \beta_n\)</span> are the coefficients</li>
<li class="fragment"><span class="math inline">\(x_1, x_2, ..., x_n\)</span> are the predictor variables</li>
<li class="fragment"><span class="math inline">\(\varepsilon\)</span> is the error term (normally distributed with mean 0)</li>
</ul>
<p>Different statistical tests are simply special cases of this general framework.</p>
<aside class="notes">
<p>The general linear model is a statistical framework that encompasses many common statistical tests. At its core, it models the relationship between a dependent variable (y) and one or more independent variables (x). The model assumes that y is a linear function of the x variables, plus some error term.</p>
<p>This equation looks like a multiple regression equation - and that’s because regression is indeed one case of the general linear model. But so are t-tests, ANOVA, and many other statistical procedures.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="building-from-simple-cases-one-sample-t-test" class="slide level2">
<h2>Building from Simple Cases: One-sample t-test</h2>
<div class="columns">
<div class="column" style="width:55%;">
<p>The one-sample t-test can be represented as:</p>
<p><span class="math display">\[y = \beta_0 + \varepsilon\]</span></p>
<p>Here, <span class="math inline">\(\beta_0\)</span> is the population mean μ, and we test the null hypothesis that <span class="math inline">\(\beta_0 = \mu_0\)</span> (some specified value).</p>
</div><div class="column" style="width:45%;">
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>mean of x 
 5.283248 </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>(Intercept) 
   5.283248 </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>      t 
12.1457 </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 12.1457</code></pre>
</div>
</div>
<p>In the linear model, we’re estimating just the intercept (<span class="math inline">\(\beta_0\)</span>), which represents the mean of y.</p>
</div></div>
<aside class="notes">
<p>Let’s start with the simplest case: the one-sample t-test. This test is used when we want to compare a sample mean to a known value. In the general linear model framework, this is simply a model with only an intercept term.</p>
<p>The intercept in this model represents the mean of the variable y. When we perform a one-sample t-test, we’re essentially testing whether this intercept (the mean) is equal to our hypothesized value.</p>
<p>The t-statistic from the t-test is exactly the same as the t-statistic for the intercept in the linear model.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="building-from-simple-cases-independent-t-test" class="slide level2">
<h2>Building from Simple Cases: Independent t-test</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p>The independent t-test can be represented as:</p>
<p><span class="math display">\[y = \beta_0 + \beta_1 x_1 + \varepsilon\]</span></p>
<p>Where <span class="math inline">\(x_1\)</span> is a dummy variable (0/1) for group membership.</p>
</div><div class="column" style="width:50%;">
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>            Estimate Std. Error  t value     Pr(&gt;|t|)
(Intercept) 5.149251  0.6304443 8.167654 1.821665e-07
groupB      2.267993  0.8915829 2.543782 2.036269e-02</code></pre>
</div>
</div>
<p><span class="math inline">\(\beta_0\)</span> = mean of reference group (A)<br>
<span class="math inline">\(\beta_1\)</span> = difference between groups (B - A)</p>
</div></div>
<aside class="notes">
<p>Moving to the independent samples t-test, we’re now comparing means between two groups. In the general linear model framework, we add a predictor variable representing group membership.</p>
<p>This predictor is a dummy variable: it’s 0 for one group and 1 for the other. The intercept (β₀) now represents the mean of the reference group (the one coded as 0), and the coefficient β₁ represents the difference in means between the two groups.</p>
<p>The t-statistic for testing whether β₁ equals zero is exactly the same as the t-statistic from the independent samples t-test. This tests whether the difference between group means is zero.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="from-simple-to-multiple-regression" class="slide level2">
<h2>From Simple to Multiple Regression</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p>Adding continuous predictors extends the model:</p>
<p><span class="math display">\[y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + ... + \varepsilon\]</span></p>
</div><div class="column" style="width:50%;">
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>              Estimate Std. Error  t value     Pr(&gt;|t|)
(Intercept) 13.0864162 7.35982048 1.778089 9.327954e-02
x1           0.4893163 0.07714800 6.342567 7.358414e-06
x2           0.2916602 0.06155792 4.737980 1.902531e-04</code></pre>
</div>
</div>
<p>Interpretation:</p>
<ul>
<li class="fragment"><span class="math inline">\(\beta_0\)</span> (Intercept): Expected y when all predictors = 0</li>
<li class="fragment"><span class="math inline">\(\beta_1\)</span>: Expected change in y for a one-unit increase in x1, holding x2 constant</li>
<li class="fragment"><span class="math inline">\(\beta_2\)</span>: Expected change in y for a one-unit increase in x2, holding x1 constant</li>
</ul>
</div></div>
<aside class="notes">
<p>When we add more predictors to our model, we get multiple regression. Each coefficient now represents the effect of its corresponding predictor on the outcome, while holding all other predictors constant.</p>
<p>The interpretation of these coefficients follows the same pattern as before: the intercept is the expected value of y when all predictors are zero, and each coefficient represents the expected change in y for a one-unit increase in the corresponding predictor, while holding all other predictors constant.</p>
<p>The t-statistics for each coefficient test whether that predictor has a significant effect on the outcome, controlling for all other predictors in the model.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="real-world-example-hr-analytics" class="slide level2">
<h2>Real-world Example: HR Analytics</h2>
<p>Let’s look at a real dataset: HR analytics data from an insurance company.</p>
<div class="cell">
<div class="cell-output-display">
<table class="caption-top">
<colgroup>
<col style="width: 9%">
<col style="width: 6%">
<col style="width: 8%">
<col style="width: 3%">
<col style="width: 6%">
<col style="width: 11%">
<col style="width: 10%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 6%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: right;">ethnicity</th>
<th style="text-align: right;">gender</th>
<th style="text-align: right;">job_role</th>
<th style="text-align: right;">age</th>
<th style="text-align: right;">tenure</th>
<th style="text-align: right;">salarygrade</th>
<th style="text-align: right;">evaluation</th>
<th style="text-align: right;">intentionto_quit</th>
<th style="text-align: right;">job_satisfaction</th>
<th style="text-align: right;">filter</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">2</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">28</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">5</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">1</td>
</tr>
<tr class="even">
<td style="text-align: right;">2</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">60</td>
<td style="text-align: right;">6</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">4</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">1</td>
</tr>
<tr class="odd">
<td style="text-align: right;">2</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">21</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">5</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">1</td>
</tr>
<tr class="even">
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">23</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">4</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">1</td>
</tr>
<tr class="odd">
<td style="text-align: right;">3</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">23</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">4</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">0</td>
</tr>
</tbody>
</table>
</div>
</div>
<aside class="notes">
<p>Now let’s apply these concepts to a real-world dataset. This HR analytics dataset contains information about employees at an insurance company, including demographic information, salary, job satisfaction, years of experience, and performance ratings.</p>
<p>We’ll use this dataset to build multiple regression models predicting salary based on various employee characteristics.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="multiple-regression-with-hr-data" class="slide level2">
<h2>Multiple Regression with HR Data</h2>
<p>Let’s predict salary based on years of experience and performance rating:</p>
<div class="cell">
<div class="cell-output-display">
<table class="caption-top">
<thead>
<tr class="header">
<th style="text-align: left;">term</th>
<th style="text-align: right;">estimate</th>
<th style="text-align: right;">std.error</th>
<th style="text-align: right;">statistic</th>
<th style="text-align: right;">p.value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">(Intercept)</td>
<td style="text-align: right;">1.00</td>
<td style="text-align: right;">0.09</td>
<td style="text-align: right;">10.94</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">tenure</td>
<td style="text-align: right;">0.14</td>
<td style="text-align: right;">0.01</td>
<td style="text-align: right;">18.86</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">evaluation</td>
<td style="text-align: right;">0.11</td>
<td style="text-align: right;">0.03</td>
<td style="text-align: right;">3.96</td>
<td style="text-align: right;">0</td>
</tr>
</tbody>
</table>
</div>
<div class="cell-output-display">
<table class="caption-top">
<thead>
<tr class="header">
<th style="text-align: right;">r.squared</th>
<th style="text-align: right;">adj.r.squared</th>
<th style="text-align: right;">sigma</th>
<th style="text-align: right;">df</th>
<th style="text-align: right;">AIC</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">0.305</td>
<td style="text-align: right;">0.303</td>
<td style="text-align: right;">0.916</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">2496.407</td>
</tr>
</tbody>
</table>
</div>
</div>
<aside class="notes">
<p>Here we’ve built a multiple regression model predicting salary based on years of experience and performance rating. The coefficients tell us:</p>
<ul>
<li>For each additional year of experience, salary increases by about $1,169, holding performance rating constant</li>
<li>For each additional point in performance rating, salary increases by about $5,173, holding years of experience constant</li>
</ul>
<p>The R-squared value tells us that about 45% of the variance in salary is explained by these two predictors combined.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="visualizing-the-relationship" class="slide level2">
<h2>Visualizing the Relationship</h2>

<img data-src="lecture_files/figure-revealjs/unnamed-chunk-10-1.png" width="960" class="r-stretch"><aside class="notes">
<p>These scatter plots visualize the relationships we modeled. We can see that both years of experience and performance rating have positive associations with salary, as indicated by the upward slopes of the regression lines.</p>
<p>Notice that there’s quite a bit of scatter around the regression lines. This reflects the fact that our model explains about 45% of the variance in salary, leaving 55% unexplained.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="adding-a-categorical-predictor" class="slide level2">
<h2>Adding a Categorical Predictor</h2>
<p>We can also include categorical predictors, like gender:</p>
<div class="cell">
<div class="cell-output-display">
<table class="caption-top">
<thead>
<tr class="header">
<th style="text-align: left;">term</th>
<th style="text-align: right;">estimate</th>
<th style="text-align: right;">std.error</th>
<th style="text-align: right;">statistic</th>
<th style="text-align: right;">p.value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">(Intercept)</td>
<td style="text-align: right;">0.47</td>
<td style="text-align: right;">0.12</td>
<td style="text-align: right;">3.81</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">tenure</td>
<td style="text-align: right;">0.14</td>
<td style="text-align: right;">0.01</td>
<td style="text-align: right;">18.91</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">evaluation</td>
<td style="text-align: right;">0.11</td>
<td style="text-align: right;">0.03</td>
<td style="text-align: right;">4.12</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">gender</td>
<td style="text-align: right;">0.38</td>
<td style="text-align: right;">0.06</td>
<td style="text-align: right;">6.39</td>
<td style="text-align: right;">0</td>
</tr>
</tbody>
</table>
</div>
<div class="cell-output-display">
<table class="caption-top">
<thead>
<tr class="header">
<th style="text-align: right;">r.squared</th>
<th style="text-align: right;">adj.r.squared</th>
<th style="text-align: right;">sigma</th>
<th style="text-align: right;">df</th>
<th style="text-align: right;">AIC</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">0.334</td>
<td style="text-align: right;">0.332</td>
<td style="text-align: right;">0.897</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">2458.259</td>
</tr>
</tbody>
</table>
</div>
</div>
<aside class="notes">
<p>When we add gender to our model, we’re now including a categorical predictor. The coefficient for genderMale represents the difference in salary between males and females, controlling for years of experience and performance rating.</p>
<p>The positive coefficient suggests that, on average, male employees earn about $7,700 more than female employees with the same years of experience and performance rating. This might indicate a gender pay gap in this organization.</p>
<p>Notice also that the R-squared has increased to about 55%, indicating that our model now explains more of the variation in salary.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="interpreting-the-model" class="slide level2">
<h2>Interpreting the Model</h2>

<img data-src="lecture_files/figure-revealjs/unnamed-chunk-12-1.png" width="960" class="r-stretch"><aside class="notes">
<p>This visualization shows the relationship between years of experience and salary, separated by gender. The parallel lines represent our model’s assumption that the effect of years of experience on salary is the same for both genders - the only difference is in the intercept (the starting point).</p>
<p>The gap between the lines represents the gender effect we saw in our model. Male employees (represented by the red line) tend to have higher salaries than female employees (represented by the blue line) with the same years of experience.</p>
<p>This illustrates how categorical variables work in the general linear model - they shift the intercept (or baseline) for different groups but don’t change the slope of the relationship.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="anova-as-a-linear-model" class="title-slide slide level1 center" data-background-color="#1E3D59">
<h1>ANOVA as a Linear Model</h1>

</section>
<section id="anova-comparing-multiple-groups" class="slide level2">
<h2>ANOVA: Comparing Multiple Groups</h2>
<p>ANOVA (Analysis of Variance) is traditionally taught as a distinct statistical test for comparing means across multiple groups.</p>
<div>
<ul>
<li class="fragment">Null hypothesis: All group means are equal (<span class="math inline">\(\mu_1 = \mu_2 = ... = \mu_k\)</span>)</li>
<li class="fragment">Alternative hypothesis: At least one group mean differs from the others</li>
<li class="fragment">Test statistic: F-ratio (ratio of between-group to within-group variance)</li>
</ul>
</div>
<aside class="notes">
<p>ANOVA is traditionally taught as a distinct test from regression, with its own set of formulas and concepts like “sums of squares” and “F-ratios.” However, ANOVA is actually just another manifestation of the general linear model.</p>
<p>The key insight is that when we compare means across groups, we’re essentially predicting an outcome (y) based on group membership (a categorical variable). This can be seamlessly represented within the linear model framework.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="fuel-consumption-dataset" class="slide level2">
<h2>Fuel Consumption Dataset</h2>
<p>Let’s use a real dataset on fuel consumption in Canada to demonstrate ANOVA as a linear model.</p>
<div class="cell">
<div class="cell-output-display">
<table class="caption-top">
<thead>
<tr class="header">
<th style="text-align: left;">make</th>
<th style="text-align: left;">model</th>
<th style="text-align: left;">class</th>
<th style="text-align: right;">enginesize</th>
<th style="text-align: right;">cylinders468</th>
<th style="text-align: right;">fueluseboth</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">ACURA</td>
<td style="text-align: left;">ILX</td>
<td style="text-align: left;">COMPACT</td>
<td style="text-align: right;">2.0</td>
<td style="text-align: right;">4</td>
<td style="text-align: right;">8.3</td>
</tr>
<tr class="even">
<td style="text-align: left;">ACURA</td>
<td style="text-align: left;">ILX</td>
<td style="text-align: left;">COMPACT</td>
<td style="text-align: right;">2.4</td>
<td style="text-align: right;">4</td>
<td style="text-align: right;">9.3</td>
</tr>
<tr class="odd">
<td style="text-align: left;">ACURA</td>
<td style="text-align: left;">ILX HYBRID</td>
<td style="text-align: left;">COMPACT</td>
<td style="text-align: right;">1.5</td>
<td style="text-align: right;">4</td>
<td style="text-align: right;">6.1</td>
</tr>
<tr class="even">
<td style="text-align: left;">ACURA</td>
<td style="text-align: left;">MDX SH-AWD</td>
<td style="text-align: left;">SUV - SMALL</td>
<td style="text-align: right;">3.5</td>
<td style="text-align: right;">6</td>
<td style="text-align: right;">11.1</td>
</tr>
<tr class="odd">
<td style="text-align: left;">ACURA</td>
<td style="text-align: left;">RDX AWD</td>
<td style="text-align: left;">SUV - SMALL</td>
<td style="text-align: right;">3.5</td>
<td style="text-align: right;">6</td>
<td style="text-align: right;">10.6</td>
</tr>
</tbody>
</table>
</div>
</div>
<aside class="notes">
<p>This dataset contains information about vehicles sold in Canada, including their fuel consumption (measured in liters per 100 kilometers), engine characteristics, and vehicle class.</p>
<p>We’ll use this data to compare average fuel consumption across different vehicle classes, first using traditional ANOVA and then showing the equivalent linear model approach.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="one-way-anova-traditional-approach" class="slide level2">
<h2>One-way ANOVA: Traditional Approach</h2>
<p>Let’s compare fuel consumption across vehicle classes:</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>              Df Sum Sq Mean Sq F value Pr(&gt;F)    
class         14   4099  292.78   62.77 &lt;2e-16 ***
Residuals   1067   4977    4.66                   
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
<p>The significant p-value (&lt; 0.05) indicates that average fuel consumption differs significantly across vehicle classes.</p>
<aside class="notes">
<p>The traditional ANOVA output shows us the familiar ANOVA table with sums of squares, degrees of freedom, mean squares, and the F-statistic. The very small p-value tells us that there are significant differences in fuel consumption between vehicle classes.</p>
<p>But how does this relate to the linear model? Let’s see.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="one-way-anova-as-linear-model" class="slide level2">
<h2>One-way ANOVA as Linear Model</h2>
<p>The same analysis using the linear model approach:</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>Analysis of Variance Table

Response: fueluseboth
            Df Sum Sq Mean Sq F value    Pr(&gt;F)    
class       14 4098.9 292.775  62.772 &lt; 2.2e-16 ***
Residuals 1067 4976.6   4.664                      
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
<p>Notice the identical F-value and p-value as the traditional ANOVA!</p>
<aside class="notes">
<p>When we run the same analysis using lm() instead of aov(), and then use anova() on the result, we get the exact same F-value and p-value as the traditional ANOVA. That’s because they’re mathematically equivalent - ANOVA is just a linear model with categorical predictors.</p>
<p>In this linear model, we’re predicting fuel consumption based on vehicle class. The model creates dummy variables for each vehicle class (except one, which serves as the reference group).</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="understanding-the-linear-model-coefficients" class="slide level2">
<h2>Understanding the Linear Model Coefficients</h2>
<div class="cell">
<div class="cell-output-display">
<table class="caption-top">
<colgroup>
<col style="width: 44%">
<col style="width: 13%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 11%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">term</th>
<th style="text-align: right;">estimate</th>
<th style="text-align: right;">std.error</th>
<th style="text-align: right;">statistic</th>
<th style="text-align: right;">p.value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">(Intercept)</td>
<td style="text-align: right;">9.355</td>
<td style="text-align: right;">0.162</td>
<td style="text-align: right;">57.792</td>
<td style="text-align: right;">0.000</td>
</tr>
<tr class="even">
<td style="text-align: left;">classFULL-SIZE</td>
<td style="text-align: right;">2.504</td>
<td style="text-align: right;">0.285</td>
<td style="text-align: right;">8.793</td>
<td style="text-align: right;">0.000</td>
</tr>
<tr class="odd">
<td style="text-align: left;">classMID-SIZE</td>
<td style="text-align: right;">0.279</td>
<td style="text-align: right;">0.229</td>
<td style="text-align: right;">1.220</td>
<td style="text-align: right;">0.223</td>
</tr>
<tr class="even">
<td style="text-align: left;">classMINICOMPACT</td>
<td style="text-align: right;">0.747</td>
<td style="text-align: right;">0.329</td>
<td style="text-align: right;">2.272</td>
<td style="text-align: right;">0.023</td>
</tr>
<tr class="odd">
<td style="text-align: left;">classMINIVAN</td>
<td style="text-align: right;">2.925</td>
<td style="text-align: right;">0.581</td>
<td style="text-align: right;">5.037</td>
<td style="text-align: right;">0.000</td>
</tr>
<tr class="even">
<td style="text-align: left;">classPICKUP TRUCK - SMALL</td>
<td style="text-align: right;">2.531</td>
<td style="text-align: right;">0.488</td>
<td style="text-align: right;">5.186</td>
<td style="text-align: right;">0.000</td>
</tr>
<tr class="odd">
<td style="text-align: left;">classPICKUP TRUCK - STANDARD</td>
<td style="text-align: right;">4.905</td>
<td style="text-align: right;">0.340</td>
<td style="text-align: right;">14.407</td>
<td style="text-align: right;">0.000</td>
</tr>
<tr class="even">
<td style="text-align: left;">classSPECIAL PURPOSE VEHICLE</td>
<td style="text-align: right;">0.734</td>
<td style="text-align: right;">0.738</td>
<td style="text-align: right;">0.995</td>
<td style="text-align: right;">0.320</td>
</tr>
<tr class="odd">
<td style="text-align: left;">classSTATION WAGON - MID-SIZE</td>
<td style="text-align: right;">0.359</td>
<td style="text-align: right;">0.832</td>
<td style="text-align: right;">0.432</td>
<td style="text-align: right;">0.666</td>
</tr>
<tr class="even">
<td style="text-align: left;">classSTATION WAGON - SMALL</td>
<td style="text-align: right;">-0.774</td>
<td style="text-align: right;">0.415</td>
<td style="text-align: right;">-1.866</td>
<td style="text-align: right;">0.062</td>
</tr>
<tr class="odd">
<td style="text-align: left;">classSUBCOMPACT</td>
<td style="text-align: right;">0.951</td>
<td style="text-align: right;">0.284</td>
<td style="text-align: right;">3.352</td>
<td style="text-align: right;">0.001</td>
</tr>
<tr class="even">
<td style="text-align: left;">classSUV - SMALL</td>
<td style="text-align: right;">1.038</td>
<td style="text-align: right;">0.231</td>
<td style="text-align: right;">4.495</td>
<td style="text-align: right;">0.000</td>
</tr>
<tr class="odd">
<td style="text-align: left;">classSUV - STANDARD</td>
<td style="text-align: right;">4.497</td>
<td style="text-align: right;">0.271</td>
<td style="text-align: right;">16.610</td>
<td style="text-align: right;">0.000</td>
</tr>
<tr class="even">
<td style="text-align: left;">classTWO-SEATER</td>
<td style="text-align: right;">1.575</td>
<td style="text-align: right;">0.303</td>
<td style="text-align: right;">5.194</td>
<td style="text-align: right;">0.000</td>
</tr>
<tr class="odd">
<td style="text-align: left;">classVAN - PASSENGER</td>
<td style="text-align: right;">10.466</td>
<td style="text-align: right;">0.521</td>
<td style="text-align: right;">20.079</td>
<td style="text-align: right;">0.000</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>Interpretation: - The intercept (9.171) is the mean fuel consumption for the reference class (COMPACT) - Each coefficient represents the difference between that class and the reference class - E.g., FULL-SIZE vehicles consume 3.514 L/100km more fuel than COMPACT vehicles, on average</p>
<aside class="notes">
<p>Looking at the coefficients from the linear model gives us more detailed information than the ANOVA table alone. The intercept represents the mean fuel consumption for the reference group (in this case, COMPACT vehicles).</p>
<p>Each other coefficient represents the difference in mean fuel consumption between that vehicle class and the reference class. For example, the coefficient for classFULL-SIZE is 3.514, which means that, on average, full-size vehicles consume 3.514 liters per 100km more fuel than compact vehicles.</p>
<p>This is a much more detailed result than the overall ANOVA, which only tells us that there are differences somewhere. The linear model pinpoints exactly where those differences are.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="visualizing-the-anova-results" class="slide level2">
<h2>Visualizing the ANOVA Results</h2>

<img data-src="lecture_files/figure-revealjs/unnamed-chunk-18-1.png" width="960" class="r-stretch"><aside class="notes">
<p>This visualization helps us see the differences in fuel consumption across vehicle classes. We can visually confirm that larger vehicle classes like full-size, SUV, and pickup trucks tend to have higher fuel consumption than compact and subcompact vehicles.</p>
<p>The boxplots show the median (middle line), quartiles (box), and range (whiskers) of fuel consumption for each class, while the individual points represent actual vehicles in the dataset.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="two-way-anova-adding-another-factor" class="slide level2">
<h2>Two-way ANOVA: Adding Another Factor</h2>
<p>Let’s extend our model to include the number of cylinders468:</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>Analysis of Variance Table

Response: fueluseboth
             Df Sum Sq Mean Sq F value    Pr(&gt;F)    
class        14 4098.9  292.78  131.26 &lt; 2.2e-16 ***
cyl_factor    2 2601.1 1300.53  583.05 &lt; 2.2e-16 ***
Residuals  1065 2375.6    2.23                      
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
<p>Both vehicle class and number of cylinders468 significantly affect fuel consumption.</p>
<aside class="notes">
<p>Here we’ve extended our model to include two factors: vehicle class and number of cylinders468. This is called a two-way ANOVA in traditional statistics.</p>
<p>The ANOVA table shows that both factors have significant effects on fuel consumption. In other words, fuel consumption varies significantly based on both vehicle class and number of cylinders468.</p>
<p>But this model only looks at the main effects - it doesn’t consider interactions between the factors.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="adding-interaction-effects" class="slide level2">
<h2>Adding Interaction Effects</h2>
<p>In the linear model framework, interactions are easy to add:</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>Analysis of Variance Table

Response: fueluseboth
                   Df Sum Sq Mean Sq  F value  Pr(&gt;F)    
class              14 4098.9  292.78 133.0732 &lt; 2e-16 ***
cyl_factor          2 2601.1 1300.53 591.1207 &lt; 2e-16 ***
class:cyl_factor   21   78.7    3.75   1.7024 0.02506 *  
Residuals        1044 2296.9    2.20                     
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
<p>The interaction term tests whether the effect of one factor depends on the level of the other factor.</p>
<aside class="notes">
<p>An interaction effect occurs when the effect of one factor depends on the level of another factor. For example, the difference in fuel consumption between 4-cylinder and 8-cylinder engines might be larger for SUVs than for compact cars.</p>
<p>In the linear model, we can easily test for interactions by using the * operator instead of +. This adds both main effects and their interaction.</p>
<p>The ANOVA table shows a significant interaction effect, indicating that the effect of cylinders468 on fuel consumption differs across vehicle classes (or equivalently, the effect of vehicle class differs depending on the number of cylinders468).</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="visualizing-the-interaction" class="slide level2">
<h2>Visualizing the Interaction</h2>

<img data-src="lecture_files/figure-revealjs/unnamed-chunk-21-1.png" width="960" class="r-stretch"><aside class="notes">
<p>This bar chart helps visualize the interaction effect. Each group of bars represents a vehicle class, and the different colored bars within each group represent different cylinder categories.</p>
<p>If there were no interaction, the pattern of differences between cylinder categories would be consistent across all vehicle classes. The fact that the pattern varies - for example, the difference between 4-cylinder and 8-cylinder engines seems larger for some vehicle classes than others - illustrates the interaction effect.</p>
<p>This is a powerful aspect of the general linear model: it allows us to model and interpret complex relationships between variables, including interactions.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="ancova-mixing-categorical-and-continuous-predictors" class="slide level2">
<h2>ANCOVA: Mixing Categorical and Continuous Predictors</h2>
<p>ANCOVA (Analysis of Covariance) combines ANOVA with regression by including both categorical and continuous predictors:</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = fueluseboth ~ class + enginesize, data = fuel_data)

Residuals:
    Min      1Q  Median      3Q     Max 
-4.2020 -0.7662 -0.1031  0.5934  6.5633 

Coefficients:
                              Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)                    5.70095    0.15343  37.156  &lt; 2e-16 ***
classFULL-SIZE                 0.53708    0.20372   2.636 0.008500 ** 
classMID-SIZE                 -0.45814    0.15871  -2.887 0.003972 ** 
classMINICOMPACT              -0.05542    0.22699  -0.244 0.807157    
classMINIVAN                   1.56351    0.40083   3.901 0.000102 ***
classPICKUP TRUCK - SMALL      1.49943    0.33662   4.454 9.30e-06 ***
classPICKUP TRUCK - STANDARD   1.77451    0.25079   7.076 2.69e-12 ***
classSPECIAL PURPOSE VEHICLE   0.87872    0.50691   1.733 0.083302 .  
classSTATION WAGON - MID-SIZE -0.62622    0.57240  -1.094 0.274190    
classSTATION WAGON - SMALL    -0.02474    0.28570  -0.087 0.931013    
classSUBCOMPACT                0.25683    0.19587   1.311 0.190059    
classSUV - SMALL               0.79530    0.15879   5.009 6.41e-07 ***
classSUV - STANDARD            1.68690    0.20301   8.310 2.89e-16 ***
classTWO-SEATER                0.30611    0.21146   1.448 0.148023    
classVAN - PASSENGER           6.11458    0.37956  16.110  &lt; 2e-16 ***
enginesize                     1.48977    0.04310  34.567  &lt; 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 1.484 on 1066 degrees of freedom
Multiple R-squared:  0.7414,    Adjusted R-squared:  0.7378 
F-statistic: 203.8 on 15 and 1066 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>This model predicts fuel consumption based on both vehicle class (categorical) and engine size (continuous).</p>
<aside class="notes">
<p>ANCOVA is traditionally taught as yet another distinct technique, but in the general linear model framework, it’s simply a model that includes both categorical and continuous predictors.</p>
<p>In this model, we’re predicting fuel consumption based on vehicle class and engine size. The coefficients for vehicle class represent the differences between classes after controlling for engine size. The coefficient for engine size represents the effect of engine size on fuel consumption, controlling for vehicle class.</p>
<p>This is another example of how the general linear model provides a unified framework for various statistical techniques.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="effect-sizes-understanding-practical-significance" class="slide level2">
<h2>Effect Sizes: Understanding Practical Significance</h2>
<p>Statistical significance (p-values) tells us if effects are likely real, but effect sizes tell us if they’re practically important:</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code># Effect Size for ANOVA

Parameter | Eta2 |       95% CI
-------------------------------
class     | 0.45 | [0.41, 1.00]

- One-sided CIs: upper bound fixed at [1.00].</code></pre>
</div>
</div>
<p>Interpretation:</p>
<ul>
<li class="fragment">η² = proportion of variance explained by each factor</li>
<li class="fragment">Vehicle class explains about 43% of the variance in fuel consumption</li>
<li class="fragment">Values of 0.01, 0.06, and 0.14 are considered small, medium, and large effects</li>
</ul>
<aside class="notes">
<p>While p-values tell us whether an effect is statistically significant (unlikely to be due to chance), effect sizes tell us about the practical significance or magnitude of the effect.</p>
<p>For ANOVA, a common effect size is eta-squared (η²), which represents the proportion of variance explained by each factor. Values around 0.01 are considered small, 0.06 medium, and 0.14 large.</p>
<p>The eta-squared value of 0.43 for vehicle class indicates that about 43% of the variance in fuel consumption is explained by vehicle class, which is a very large effect.</p>
<p>Effect sizes are important because with large enough sample sizes, even tiny, practically meaningless effects can become statistically significant.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="post-hoc-tests-which-groups-differ" class="slide level2">
<h2>Post-hoc Tests: Which Groups Differ?</h2>
<p>When ANOVA finds significant differences, post-hoc tests help identify which specific groups differ:</p>
<div class="cell">
<div class="cell-output-display">
<table class="caption-top">
<colgroup>
<col style="width: 52%">
<col style="width: 12%">
<col style="width: 8%">
<col style="width: 6%">
<col style="width: 10%">
<col style="width: 10%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">contrast</th>
<th style="text-align: right;">estimate</th>
<th style="text-align: right;">SE</th>
<th style="text-align: right;">df</th>
<th style="text-align: right;">t.ratio</th>
<th style="text-align: right;">p.value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">COMPACT - (PICKUP TRUCK - STANDARD)</td>
<td style="text-align: right;">-4.905</td>
<td style="text-align: right;">0.340</td>
<td style="text-align: right;">1067</td>
<td style="text-align: right;">-14.407</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">COMPACT - (SUV - STANDARD)</td>
<td style="text-align: right;">-4.497</td>
<td style="text-align: right;">0.271</td>
<td style="text-align: right;">1067</td>
<td style="text-align: right;">-16.610</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">COMPACT - (VAN - PASSENGER)</td>
<td style="text-align: right;">-10.466</td>
<td style="text-align: right;">0.521</td>
<td style="text-align: right;">1067</td>
<td style="text-align: right;">-20.079</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">(FULL-SIZE) - (VAN - PASSENGER)</td>
<td style="text-align: right;">-7.962</td>
<td style="text-align: right;">0.548</td>
<td style="text-align: right;">1067</td>
<td style="text-align: right;">-14.528</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">(MID-SIZE) - (PICKUP TRUCK - STANDARD)</td>
<td style="text-align: right;">-4.625</td>
<td style="text-align: right;">0.340</td>
<td style="text-align: right;">1067</td>
<td style="text-align: right;">-13.586</td>
<td style="text-align: right;">0</td>
</tr>
</tbody>
</table>
</div>
</div>
<aside class="notes">
<p>When ANOVA indicates significant differences between groups, we often want to know which specific groups differ from each other. Post-hoc tests help answer this question.</p>
<p>Here we’re using estimated marginal means and pairwise comparisons with Tukey’s adjustment for multiple comparisons. The results show the estimated difference between each pair of vehicle classes, along with confidence intervals and adjusted p-values.</p>
<p>The table shows the 5 most significant pairwise differences. For example, fuel consumption differs significantly between SUV-UTILITY and COMPACT-SUV vehicle classes.</p>
<p>This is another example of how the linear model framework provides a comprehensive approach to statistical analysis, from overall tests to detailed comparisons.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="integrated-example-hr-analytics-with-anova" class="slide level2">
<h2>Integrated Example: HR Analytics with ANOVA</h2>
<p>Let’s return to our HR dataset and use ANOVA to compare job satisfaction across job roles:</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = job_satisfaction ~ job_role, data = hr_data)

Residuals:
     Min       1Q   Median       3Q      Max 
-2.67123 -0.82659  0.00448  0.83555  2.17341 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  2.65766    0.06886  38.597  &lt; 2e-16 ***
job_role     0.16893    0.02155   7.839 1.23e-14 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 1.103 on 934 degrees of freedom
Multiple R-squared:  0.06173,   Adjusted R-squared:  0.06073 
F-statistic: 61.45 on 1 and 934 DF,  p-value: 1.235e-14</code></pre>
</div>
</div>
<aside class="notes">
<p>Now let’s apply what we’ve learned to our HR analytics dataset. Here we’re comparing job satisfaction across different job roles using a linear model (which is equivalent to ANOVA).</p>
<p>The results show the mean job satisfaction for the reference role (the intercept) and the differences between each other role and the reference role Some departments appear to have significantly higher or lower job satisfaction than others.</p>
<p>This is a practical application of ANOVA as a linear model in a human resources context.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="visualizing-hr-department-differences" class="slide level2">
<h2>Visualizing HR Department Differences</h2>

<img data-src="lecture_files/figure-revealjs/unnamed-chunk-26-1.png" width="960" class="r-stretch"><aside class="notes">
<p>This visualization helps us see the differences in job satisfaction across departments. The departments are ordered by their mean job satisfaction, with departments having higher average satisfaction appearing towards the right.</p>
<p>We can see variations in both the central tendency (median, indicated by the line in the middle of each box) and the spread of job satisfaction scores within each department.</p>
<p>This kind of analysis could help HR identify departments that might need intervention to improve employee satisfaction, or departments with particularly high satisfaction that might serve as models for others.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="combining-anova-and-regression" class="slide level2">
<h2>Combining ANOVA and Regression</h2>
<p>We can build more complex models that include: - Multiple categorical predictors (multi-way ANOVA) - Continuous predictors alongside categorical ones (ANCOVA) - Interaction terms between predictors</p>
<div class="cell">
<div class="cell-output-display">
<table class="caption-top">
<thead>
<tr class="header">
<th style="text-align: right;">Df</th>
<th style="text-align: right;">Sum Sq</th>
<th style="text-align: right;">Mean Sq</th>
<th style="text-align: right;">F value</th>
<th style="text-align: right;">Pr(&gt;F)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">1</td>
<td style="text-align: right;">74.760</td>
<td style="text-align: right;">74.760</td>
<td style="text-align: right;">81.951</td>
<td style="text-align: right;">0.000</td>
</tr>
<tr class="even">
<td style="text-align: right;">1</td>
<td style="text-align: right;">1.478</td>
<td style="text-align: right;">1.478</td>
<td style="text-align: right;">1.620</td>
<td style="text-align: right;">0.203</td>
</tr>
<tr class="odd">
<td style="text-align: right;">1</td>
<td style="text-align: right;">285.426</td>
<td style="text-align: right;">285.426</td>
<td style="text-align: right;">312.880</td>
<td style="text-align: right;">0.000</td>
</tr>
<tr class="even">
<td style="text-align: right;">1</td>
<td style="text-align: right;">0.101</td>
<td style="text-align: right;">0.101</td>
<td style="text-align: right;">0.111</td>
<td style="text-align: right;">0.739</td>
</tr>
<tr class="odd">
<td style="text-align: right;">931</td>
<td style="text-align: right;">849.307</td>
<td style="text-align: right;">0.912</td>
<td style="text-align: right;">NA</td>
<td style="text-align: right;">NA</td>
</tr>
</tbody>
</table>
</div>
</div>
<aside class="notes">
<p>Here we’ve built a more complex model that includes multiple predictors: department (categorical), gender (categorical), and performance rating (continuous), as well as an interaction between department and performance rating.</p>
<p>This model tests whether job satisfaction varies by department, gender, and performance rating, and whether the relationship between performance rating and job satisfaction differs across departments.</p>
<p>The ANOVA table shows which effects are statistically significant. This demonstrates how the general linear model framework allows us to build and test complex models that would be difficult to conceptualize using traditional statistical procedures taught in isolation.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="the-power-of-the-unified-approach" class="slide level2 scrollable">
<h2>The Power of the Unified Approach</h2>
<p>Benefits of viewing statistical tests as linear models:</p>
<div>
<ol type="1">
<li class="fragment"><strong>Conceptual simplicity</strong>: Learn one framework instead of many isolated techniques</li>
<li class="fragment"><strong>Flexibility</strong>: Easily combine and extend models to suit your research questions</li>
<li class="fragment"><strong>Interpretability</strong>: Consistent approach to understanding and communicating results</li>
<li class="fragment"><strong>Practicality</strong>: Simplifies implementation in statistical software</li>
<li class="fragment"><strong>Extensibility</strong>: Natural pathway to more advanced methods (mixed effects, generalized linear models)</li>
</ol>
</div>
<aside class="notes">
<p>The unified linear model approach offers several benefits over the traditional approach of teaching statistical tests as separate, unrelated techniques.</p>
<p>First, it’s conceptually simpler. Instead of learning different formulas and procedures for t-tests, ANOVA, regression, etc., you learn one framework that encompasses all of these.</p>
<p>Second, it’s more flexible. You can easily combine different types of predictors and test complex hypotheses within the same framework.</p>
<p>Third, it provides a consistent approach to interpretation. The coefficients in a linear model always have the same basic interpretation, regardless of whether the model is implementing a t-test, ANOVA, or regression.</p>
<p>Fourth, it’s practical. In R and many other statistical software packages, the linear model (lm() function in R) is the workhorse for a wide range of analyses.</p>
<p>Finally, it provides a natural pathway to more advanced methods like mixed-effects models and generalized linear models, which extend the linear model framework to handle more complex data structures and non-normal distributions.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="concluding-thoughts" class="slide level2">
<h2>Concluding Thoughts</h2>
<ul>
<li class="fragment">Statistical tests are not isolated tools but connected members of the same family</li>
<li class="fragment">The general linear model provides a unified framework for understanding these connections</li>
<li class="fragment">This perspective simplifies learning, application, and interpretation of statistics</li>
<li class="fragment">When facing a new analytical problem, think in terms of the linear model: what is my outcome? What are my predictors? What relationships am I testing?</li>
</ul>
<aside class="notes">
<p>In conclusion, the general linear model provides a powerful, unified framework for statistical analysis. By understanding that many common statistical tests are special cases of the linear model, we gain a deeper and more coherent understanding of statistics.</p>
<p>Rather than memorizing different formulas and procedures for different tests, we can focus on understanding the core principles of the linear model and how to apply them to different research questions.</p>
<p>When approaching a new analytical problem, thinking in terms of the linear model helps clarify the essential components: the outcome variable, the predictor variables, and the relationships we’re interested in testing.</p>
<p>This approach not only simplifies learning and application but also enables us to build more sophisticated models that better capture the complexity of real-world phenomena.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="common-statistical-tests-as-linear-models" class="title-slide slide level1 center" data-background-color="#1E3D59">
<h1>Common Statistical Tests as Linear Models</h1>

</section>
<section id="the-unified-language-of-statistics" class="slide level2">
<h2>The Unified Language of Statistics</h2>
<div>
<p>Adapted from:</p>
<ul>
<li><a href="https://lindeloev.github.io/tests-as-linear/"><em>Common statistical tests are linear models</em></a>. Jonas Kristoffer Lindeløv (2019).</li>
</ul>
</div>
<p>In this section, we’ll explore an elegant insight: most common statistical tests can be expressed as special cases of the general linear model. This unified framework simplifies our understanding of statistics and reveals deep connections between seemingly different tests.</p>
<aside class="notes">
<p>This section draws extensively from Jonas Lindeløv’s excellent resource which demonstrates how common statistical tests can be expressed as linear models. This approach provides a powerful unifying framework that can transform how we teach and learn statistics.</p>
<p>The key insight is that tests like t-tests, ANOVA, correlation, and others aren’t separate, unrelated techniques, but rather special cases of the same underlying model. By understanding this connection, students can develop a more coherent and transferable understanding of statistics.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="the-simplicity-underlying-common-tests" class="slide level2">
<h2>The Simplicity Underlying Common Tests</h2>
<p>Most statistical tests are special cases of linear models or very close approximations:</p>
<p><span class="math display">\[y_i = \beta_0 + \beta_1 x_{1i} + \beta_2 x_{2i} + ... + \varepsilon_i\]</span></p>
<p>This unified view simplifies learning and shows connections between seemingly different methods.</p>
<div class="fragment">
<p>Teaching linear models first, then presenting traditional tests as special cases: - Emphasizes understanding over memorization - Makes statistical concepts more intuitive - Shows the common structure of different statistical procedures</p>
</div>
<aside class="notes">
<p>Linear models provide a unifying framework for understanding statistics. Most common statistical procedures (t-tests, ANOVA, correlation, etc.) are special cases of the general linear model.</p>
<p>This approach simplifies what students need to learn. Instead of treating each test as an independent entity with its own formulas and assumptions, we can present them as variations on the same underlying model.</p>
<p>By teaching the general linear model first and then showing how traditional tests are special cases, we help students build a more coherent mental model of statistics. This approach emphasizes conceptual understanding over rote memorization of formulas and procedures.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="a-family-tree-of-statistical-tests" class="slide level2">
<h2>A Family Tree of Statistical Tests</h2>

<img data-src="https://lindeloev.github.io/tests-as-linear/linear_tests_cheat_sheet.png" class="r-stretch quarto-figure-center"><p class="caption">A family tree of statistical tests as linear models</p><p>This cheat sheet shows how different statistical tests relate to each other through the linear model framework:</p>
<ul>
<li class="fragment">Simple tests at the bottom (t-tests, correlation)</li>
<li class="fragment">More complex models at the top (ANOVA, multiple regression)</li>
<li class="fragment">Each branch represents a variation or special case of the linear model</li>
</ul>
<aside class="notes">
<p>This cheat sheet from Lindeløv’s website shows how various statistical tests are related through the linear model framework. It provides a visual roadmap of the connections between different statistical procedures.</p>
<p>Notice how we can trace the path from simple tests like t-tests up to more complex procedures like factorial ANOVA. Each branch represents a variation or extension of the basic linear model.</p>
<p>This visualization helps students see that what they’re learning aren’t disconnected techniques but rather members of the same family, with shared properties and interpretations. This perspective can make learning statistics more coherent and less overwhelming.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="simplifying-our-understanding-summary-table" class="slide level2 scrollable">
<h2>Simplifying Our Understanding: Summary Table</h2>
<div class="cell">
<div class="cell-output-display">
<table class="caption-top">
<colgroup>
<col style="width: 28%">
<col style="width: 31%">
<col style="width: 39%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Test</th>
<th style="text-align: left;">Linear Model Formula</th>
<th style="text-align: left;">What’s being tested</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Correlation</td>
<td style="text-align: left;">y ~ x</td>
<td style="text-align: left;">Slope coefficient</td>
</tr>
<tr class="even">
<td style="text-align: left;">One-sample t-test</td>
<td style="text-align: left;">y ~ 1</td>
<td style="text-align: left;">Intercept</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Independent t-test</td>
<td style="text-align: left;">y ~ group</td>
<td style="text-align: left;">Group coefficient</td>
</tr>
<tr class="even">
<td style="text-align: left;">Paired t-test</td>
<td style="text-align: left;">diff ~ 1</td>
<td style="text-align: left;">Intercept of differences</td>
</tr>
<tr class="odd">
<td style="text-align: left;">One-way ANOVA</td>
<td style="text-align: left;">y ~ group</td>
<td style="text-align: left;">Group coefficients</td>
</tr>
<tr class="even">
<td style="text-align: left;">Two-way ANOVA</td>
<td style="text-align: left;">y ~ factorA * factorB</td>
<td style="text-align: left;">Main effects &amp; interaction</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Multiple regression</td>
<td style="text-align: left;">y ~ x1 + x2 + …</td>
<td style="text-align: left;">Multiple coefficients</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>The table shows:</p>
<ul>
<li class="fragment">Each common test has a corresponding linear model formulation</li>
<li class="fragment">Many tests are testing coefficients in the same type of model</li>
<li class="fragment">The differences often come down to which coefficients we’re interested in</li>
</ul>
<aside class="notes">
<p>This table summarizes how different common tests map to linear model formulations. For each test, we can identify what linear model would be equivalent and which coefficient(s) we’re testing.</p>
<p>Notice that the difference between tests often comes down to:</p>
<ol type="1">
<li>What variables we include in the model</li>
<li>Which coefficient(s) we’re interested in testing</li>
<li>How we interpret the results</li>
</ol>
<p>This unified framework helps students see that they’re not learning completely different procedures for each test, but rather applying the same underlying model in different contexts.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="pearson-and-spearman-correlation-as-linear-models" class="slide level2">
<h2>Pearson and Spearman Correlation as Linear Models</h2>
<p>Model: <span class="math inline">\(y = \beta_0 + \beta_1 x \quad\)</span> where <span class="math inline">\(\mathcal{H}_0: \beta_1 = 0\)</span></p>
<p>This is simply a linear regression with one predictor. When we test whether the correlation is significant, we’re testing whether the slope (<span class="math inline">\(\beta_1\)</span>) differs from zero.</p>
<div class="columns">
<div class="column" style="width:50%;">
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>      cor 
0.5818111 </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 9.360699e-06</code></pre>
</div>
</div>
</div><div class="column" style="width:50%;">
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code> scale(x) 
0.5818111 </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 9.360699e-06</code></pre>
</div>
</div>
<p>When we standardize both variables (giving them mean=0 and sd=1), the slope coefficient equals the correlation coefficient!</p>
</div></div>
<aside class="notes">
<p>Here we demonstrate that Pearson’s correlation is equivalent to the standardized regression coefficient in a simple linear regression model.</p>
<p>The mathematical model is exactly the same as simple linear regression: y = β₀ + β₁x + ε. The null hypothesis being tested is that β₁ = 0, which means there is no linear relationship between the variables.</p>
<p>When we standardize both x and y (to have mean=0 and sd=1), the slope coefficient in a linear regression equals the correlation coefficient r. This makes intuitive sense because standardization puts both variables on the same scale, making their relationship directly comparable.</p>
<p>The t-test on this coefficient tests exactly the same hypothesis as the correlation test: is there a linear relationship between the variables? The p-values are identical between the two approaches.</p>
<p>This equivalence helps us understand correlation not as a mysterious measure, but simply as the slope of a regression line when variables are standardized.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="pearson-vs.-spearman-correlation" class="slide level2 scrollable">
<h2>Pearson vs.&nbsp;Spearman Correlation</h2>
<p>Spearman correlation is Pearson correlation on rank-transformed variables:</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.5818111</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.6436975</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.6436975</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.6436975</code></pre>
</div>
</div>
<p>The “non-parametric” Spearman correlation is simply the “parametric” Pearson correlation applied to ranked data!</p>
<aside class="notes">
<p>Spearman’s rank correlation is a brilliant example of how a “non-parametric” test is simply a parametric test applied to transformed data.</p>
<p>Instead of correlating the original values, Spearman correlation first converts all values to their ranks (1st, 2nd, 3rd, etc.) and then applies the Pearson correlation formula to these ranks.</p>
<p>This transformation accomplishes two things:</p>
<ol type="1">
<li>It makes the test robust to outliers, since extreme values just become the highest or lowest rank</li>
<li>It allows the test to detect monotonic but non-linear relationships, since ranking linearizes any monotonic relationship</li>
</ol>
<p>By understanding Spearman correlation as “Pearson on ranks,” we demystify non-parametric statistics. Many so-called non-parametric tests are simply parametric tests applied to transformed data, making them more accessible conceptually.</p>
<p>The R code demonstrates that Spearman correlation can be obtained either by using the dedicated function or by manually ranking the variables and then applying Pearson correlation.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="correlation-visualized" class="slide level2">
<h2>Correlation Visualized</h2>

<img data-src="lecture_files/figure-revealjs/unnamed-chunk-33-1.png" width="672" class="r-stretch"><p>Left: Pearson correlation fits a line to the original data points<br>
Right: Spearman correlation fits a line to the ranked data points</p>
<aside class="notes">
<p>This visualization helps us understand the relationship between Pearson and Spearman correlation.</p>
<p>The left panel shows the original data with the regression line (Pearson’s r). The right panel shows the same data after converting to ranks, with its regression line (Spearman’s rho).</p>
<p>Notice how the ranked data (right panel) tends to form a more linear pattern. This is because ranking removes the influence of outliers and transforms any monotonic relationship into a linear one.</p>
<p>Another key insight: the slope of the line through the ranked data is the Spearman correlation coefficient, just as the slope of the line through the standardized original data is the Pearson correlation coefficient.</p>
<p>This visualization reinforces the idea that many statistical tests are simply variations on the same theme, applied to differently transformed data.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="one-sample-t-test-as-a-linear-model" class="slide level2">
<h2>One-Sample t-test as a Linear Model</h2>
<p>Model: <span class="math inline">\(y = \beta_0 \quad\)</span> where <span class="math inline">\(\mathcal{H}_0: \beta_0 = 0\)</span></p>
<p>This is the simplest linear model possible! It has only an intercept (no predictors), and the intercept equals the sample mean.</p>
<div class="columns">
<div class="column" style="width:50%;">
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>        t 
0.2953268 </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.7698484</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 4.373147 5.838438
attr(,"conf.level")
[1] 0.95</code></pre>
</div>
</div>
</div><div class="column" style="width:50%;">
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>            Estimate Std. Error  t value     Pr(&gt;|t|)
(Intercept) 5.105792  0.3582218 14.25316 1.244655e-14</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>               2.5 %   97.5 %
(Intercept) 4.373147 5.838438</code></pre>
</div>
</div>
<p>The intercept-only model gives identical results to the one-sample t-test! The coefficient is the mean, and the t-statistic tests if it differs from zero.</p>
</div></div>
<aside class="notes">
<p>The one-sample t-test is perhaps the simplest demonstration of how standard statistical tests are special cases of linear models.</p>
<p>In a one-sample t-test, we’re asking whether a sample mean differs significantly from a hypothesized population value (often zero). In the linear model framework, this becomes an intercept-only model: y = β₀ + ε.</p>
<p>The intercept (β₀) represents the sample mean. The t-statistic tests whether this mean differs significantly from the hypothesized value (in this case, μ=5).</p>
<p>The R code demonstrates this equivalence beautifully. The estimate from t.test() is identical to the intercept from lm(), and the t-statistic, p-value, and confidence intervals match exactly.</p>
<p>This shows how even the most basic statistical test can be understood within the general linear model framework. The intercept-only model is simply a special case where we have no predictors, just as the one-sample t-test is examining a single mean without comparison groups.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="wilcoxon-signed-rank-test-as-a-linear-model" class="slide level2 scrollable">
<h2>Wilcoxon Signed-Rank Test as a Linear Model</h2>
<p>The Wilcoxon signed-rank test is approximately a one-sample t-test on signed ranks:</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.8552717</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.8488961</code></pre>
</div>
</div>
<p>The “non-parametric” Wilcoxon test can be viewed as a one-sample t-test on rank-transformed data!</p>
<aside class="notes">
<p>The Wilcoxon signed-rank test is often presented as a completely different “non-parametric” alternative to the t-test, but here we see it’s closely related to the t-test when viewed through the linear model lens.</p>
<p>The key insight is that the Wilcoxon test can be approximated as a one-sample t-test applied to signed ranks rather than the original values. Here’s how it works:</p>
<ol type="1">
<li>First, we calculate the differences from the hypothesized median (μ=5)</li>
<li>Then we rank the absolute differences (ignoring signs)</li>
<li>Finally, we reattach the original signs to these ranks (creating “signed ranks”)</li>
<li>We run a one-sample t-test on these signed ranks</li>
</ol>
<p>This transformation makes the test more robust to outliers and non-normal distributions, as extreme values are “tamed” by the ranking process.</p>
<p>The approximation works best with sample sizes of 15 or more. With smaller samples, the discrete nature of ranks means the p-values won’t match exactly, but the approach still provides conceptual insight.</p>
<p>This demonstrates again how “non-parametric” tests can often be understood as parametric tests applied to transformed data, demystifying what might otherwise seem like a completely different approach to inference.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="independent-samples-t-test-as-a-linear-model" class="slide level2">
<h2>Independent Samples t-test as a Linear Model</h2>
<p>Model: <span class="math inline">\(y_i = \beta_0 + \beta_1 x_i \quad\)</span> where <span class="math inline">\(\mathcal{H}_0: \beta_1 = 0\)</span></p>
<p>Here, <span class="math inline">\(x_i\)</span> is a dummy variable (0/1) for group membership. <span class="math inline">\(\beta_0\)</span> represents the mean of the first group, while <span class="math inline">\(\beta_1\)</span> represents the difference between groups.</p>
<div class="columns">
<div class="column" style="width:50%;">
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>       t 
-2.87084 </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.007712189</code></pre>
</div>
</div>
</div><div class="column" style="width:50%;">
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>             Estimate Std. Error  t value     Pr(&gt;|t|)
(Intercept) 10.236098  0.6046277 16.92959 3.052810e-16
groupB       2.454777  0.8550727  2.87084 7.712189e-03</code></pre>
</div>
</div>
<p>The coefficient for <code>groupB</code> is the difference between groups, exactly what’s tested in the t-test. The t-statistic and p-value are identical!</p>
</div></div>
<aside class="notes">
<p>The independent samples t-test compares means between two groups. In the linear model framework, this is represented as a model with one dummy-coded categorical predictor.</p>
<p>The model is y = β₀ + β₁x + ε, where x is coded as 0 for the first group and 1 for the second group. This dummy coding has a straightforward interpretation:</p>
<ul>
<li>β₀ (the intercept) represents the mean of the reference group (group A)</li>
<li>β₁ represents the difference in means between groups B and A</li>
<li>The t-statistic tests whether this difference is significantly different from zero</li>
</ul>
<p>The R code demonstrates that the t-statistic and p-value from the traditional t-test are identical to those for the group coefficient in the linear model.</p>
<p>This demonstrates how categorical variables can be incorporated into linear models through dummy coding, and how tests that might seem conceptually different (like t-tests and regression) are actually part of the same unified framework.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="dummy-coding-visualized" class="slide level2 scrollable">
<h2>Dummy Coding Visualized</h2>

<img data-src="lecture_files/figure-revealjs/unnamed-chunk-39-1.png" width="672" class="r-stretch"><p>This visualization shows:</p>
<ul>
<li class="fragment">The blue dashed line is the mean of group A (the intercept, <span class="math inline">\(\beta_0\)</span>)<br>
</li>
<li class="fragment">The red arrow shows the difference between groups (the slope, <span class="math inline">\(\beta_1\)</span>)</li>
<li class="fragment">In a t-test, we’re testing whether this difference (<span class="math inline">\(\beta_1\)</span>) is significantly different from zero</li>
</ul>
<aside class="notes">
<p>This visualization helps us understand how dummy coding works in a linear model with a categorical predictor.</p>
<p>When we use dummy coding in a linear model:</p>
<ol type="1">
<li>One group (here, group A) becomes the reference category and is coded as 0</li>
<li>The other group (group B) is coded as 1</li>
<li>The intercept (β₀) represents the mean of the reference group</li>
<li>The coefficient for the dummy variable (β₁) represents the difference between groups</li>
</ol>
<p>In the plot, the blue dashed line shows the mean of group A (the intercept, β₀). The red arrow represents the difference between groups, which is the coefficient β₁.</p>
<p>This visualization makes it clear that an independent samples t-test is testing whether this difference (β₁) is significantly different from zero. If there’s no difference between groups, the red arrow would be flat (no vertical component).</p>
<p>Understanding dummy coding is crucial for interpreting linear models with categorical predictors. This same principle extends to models with multiple categorical predictors (like ANOVA) and to more complex designs.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="mann-whitney-u-test-as-a-linear-model" class="slide level2 scrollable">
<h2>Mann-Whitney U Test as a Linear Model</h2>
<p>The Mann-Whitney U test is approximately a t-test on ranks:</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.02635404</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.0236538</code></pre>
</div>
<div class="cell-output-display">
<table class="caption-top">
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Test</th>
<th style="text-align: right;">P_value</th>
<th style="text-align: right;">Difference</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;">Mann-Whitney U</td>
<td style="text-align: right;">0.0264</td>
<td style="text-align: right;">NA</td>
</tr>
<tr class="even">
<td style="text-align: left;">groupB</td>
<td style="text-align: left;">Linear model on ranks</td>
<td style="text-align: right;">0.0237</td>
<td style="text-align: right;">7.1333</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>Just like with Spearman correlation, the “non-parametric” Mann-Whitney test can be viewed as a regular t-test applied to ranked data.</p>
<aside class="notes">
<p>The Mann-Whitney U test (also known as the Wilcoxon rank-sum test) is commonly presented as a “non-parametric” alternative to the independent samples t-test when data violates normality assumptions.</p>
<p>However, as we can see, it can be closely approximated as a standard t-test (or linear model) applied to ranked data:</p>
<ol type="1">
<li>First, we rank all values across both groups from lowest to highest</li>
<li>Then we run a standard t-test (or linear model) comparing these ranks between groups</li>
<li>The coefficient for the group effect represents the difference in mean ranks</li>
</ol>
<p>The p-value from this ranked linear model closely approximates the p-value from the Mann-Whitney U test. This approximation improves with larger sample sizes (n &gt; 20 per group).</p>
<p>This approach gives us an additional benefit: while the traditional Mann-Whitney U test only provides a p-value, the linear model on ranks also gives us the actual difference in mean ranks between groups, providing a measure of effect size.</p>
<p>This further reinforces the pattern we’ve seen: many “non-parametric” tests can be understood as parametric tests applied to rank-transformed data, providing a unified conceptual framework.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="paired-samples-t-test-as-a-linear-model" class="slide level2 scrollable">
<h2>Paired Samples t-test as a Linear Model</h2>
<p>Model: <span class="math inline">\(y_{2i} - y_{1i} = \beta_0 \quad\)</span> where <span class="math inline">\(\mathcal{H}_0: \beta_0 = 0\)</span></p>
<p>A paired t-test simplifies to a one-sample t-test on the differences between pairs!</p>
<div class="columns">
<div class="column" style="width:50%;">
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>       t 
3.189437 </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.004827114</code></pre>
</div>
</div>
</div><div class="column" style="width:50%;">
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>            Estimate Std. Error  t value    Pr(&gt;|t|)
(Intercept) 5.089399   1.595704 3.189437 0.004827114</code></pre>
</div>
</div>
<p>The paired t-test becomes an intercept-only model (one-sample t-test) on the differences!</p>
</div></div>
<aside class="notes">
<p>The paired samples t-test is another example of how complex-seeming statistical tests reduce to simpler linear models when we understand the underlying structure.</p>
<p>In a paired design, we have two measurements for each subject (e.g., before and after treatment). The paired t-test accounts for the correlation between these measurements by analyzing the differences rather than the raw values.</p>
<p>The key insight is that a paired t-test is mathematically equivalent to a one-sample t-test on the differences:</p>
<ol type="1">
<li>Calculate the difference for each pair: diff = post - pre</li>
<li>Test whether the mean difference is significantly different from zero using a one-sample t-test</li>
</ol>
<p>In the linear model framework, this becomes an intercept-only model on the differences: diff = β₀ + ε, where the null hypothesis is β₀ = 0.</p>
<p>The R code demonstrates this equivalence. The t-statistic and p-value from the paired t-test match exactly those from the intercept-only model on the differences.</p>
<p>This approach clarifies that the paired t-test is not a fundamentally different test but rather a clever application of the one-sample t-test to difference scores. This insight helps students see the connections between seemingly different statistical procedures.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="paired-design-visualization" class="slide level2">
<h2>Paired Design Visualization</h2>

<img data-src="lecture_files/figure-revealjs/unnamed-chunk-43-1.png" width="672" class="r-stretch"><p>This visualization shows:</p>
<ul>
<li class="fragment">Each gray line represents one subject’s pre and post measurements</li>
<li class="fragment">The red points show the group means at each time point</li>
<li class="fragment">The paired t-test analyzes the mean of these differences (slopes of gray lines)</li>
<li class="fragment">This accounts for individual baseline differences and increases statistical power</li>
</ul>
<aside class="notes">
<p>This visualization helps us understand the structure of paired data and why we analyze differences rather than raw values.</p>
<p>Each gray line represents a single subject, connecting their pre and post measurements. Notice how subjects start at different baseline levels but generally show similar trends (most lines slope upward, indicating an increase from pre to post).</p>
<p>The red points and line show the group means at each time point. The paired t-test effectively tests whether the average slope of the gray lines is significantly different from zero.</p>
<p>The key advantage of a paired design is that it accounts for individual differences. In an independent samples design, the pre-test variance would include both within-subject and between-subject variability. By analyzing within-subject changes, we remove the between-subject variability, resulting in greater statistical power.</p>
<p>This is why paired designs are often preferred when the same subjects can be measured under different conditions - they control for individual differences that would otherwise contribute to error variance.</p>
<p>Understanding paired designs as analyzing differences helps students see why the paired t-test reduces to a one-sample t-test on those differences, as we saw in the previous slide.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="one-way-anova-as-a-linear-model" class="slide level2">
<h2>One-way ANOVA as a Linear Model</h2>
<p>Model: <span class="math inline">\(y_i = \beta_0 + \beta_1 x_{1i} + \beta_2 x_{2i} + \beta_3 x_{3i} + ... \quad\)</span> where <span class="math inline">\(\mathcal{H}_0: \beta_1 = \beta_2 = ... = 0\)</span></p>
<p>The one-way ANOVA is a natural extension of the independent t-test to three or more groups.</p>
<div class="columns">
<div class="column" style="width:50%;">
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>            Df Sum Sq Mean Sq F value   Pr(&gt;F)    
group        2  108.0   53.97   14.83 1.34e-05 ***
Residuals   42  152.9    3.64                     
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
</div><div class="column" style="width:50%;">
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>Analysis of Variance Table

Response: y
          Df Sum Sq Mean Sq F value    Pr(&gt;F)    
group      2 107.95  53.973  14.827 1.343e-05 ***
Residuals 42 152.88   3.640                      
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
<p>The linear model produces exactly the same F-statistic and p-value as the traditional ANOVA. The linear model is using dummy coding for groups B and C, with group A as the reference.</p>
</div></div>
<aside class="notes">
<p>One-way ANOVA is traditionally taught as a distinct test from regression or t-tests, but here we see it’s simply an extension of the same linear model framework.</p>
<p>In an independent t-test, we had one dummy variable for two groups. In one-way ANOVA with k groups, we have k-1 dummy variables:</p>
<ul>
<li>Group A becomes the reference group (coded as 0 for all dummy variables)</li>
<li>Group B is coded as 1 for the first dummy variable, 0 for others</li>
<li>Group C is coded as 1 for the second dummy variable, 0 for others</li>
<li>And so on for additional groups</li>
</ul>
<p>The model is: y = β₀ + β₁x₁ + β₂x₂ + … + ε, where:</p>
<ul>
<li>β₀ is the mean of the reference group (Group A)</li>
<li>β₁ is the difference between Group B and Group A</li>
<li>β₂ is the difference between Group C and Group A</li>
</ul>
<p>The F-test in the ANOVA table tests the null hypothesis that all group differences are simultaneously equal to zero (β₁ = β₂ = … = 0).</p>
<p>The R code demonstrates that traditional ANOVA (using aov()) and the linear model approach (using lm() followed by anova()) produce identical F-statistics and p-values.</p>
<p>This reveals that ANOVA is not a fundamentally different procedure but simply a way of testing multiple coefficients simultaneously in a linear model.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="kruskal-wallis-test-as-a-linear-model" class="slide level2 scrollable">
<h2>Kruskal-Wallis Test as a Linear Model</h2>
<p>The Kruskal-Wallis test is approximately a one-way ANOVA on ranks:</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.0001543885</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 2.278855e-05</code></pre>
</div>
<div class="cell-output-display">
<table class="caption-top">
<thead>
<tr class="header">
<th style="text-align: left;">Test</th>
<th style="text-align: right;">P_value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Kruskal-Wallis</td>
<td style="text-align: right;">0.00015</td>
</tr>
<tr class="even">
<td style="text-align: left;">ANOVA on ranks</td>
<td style="text-align: right;">0.00002</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>Following our pattern, the “non-parametric” Kruskal-Wallis test can be viewed as a regular ANOVA performed on ranked data rather than raw values.</p>
<aside class="notes">
<p>The Kruskal-Wallis test is traditionally presented as a non-parametric alternative to one-way ANOVA when data violate normality assumptions or are ordinal in nature.</p>
<p>However, just as we saw with other “non-parametric” tests, the Kruskal-Wallis test can be closely approximated as a standard parametric test (one-way ANOVA) applied to rank-transformed data:</p>
<ol type="1">
<li>First, we rank all observations from lowest to highest, regardless of group</li>
<li>Then we run a standard one-way ANOVA on these ranks</li>
<li>The F-test from this ANOVA approximates the Kruskal-Wallis test</li>
</ol>
<p>The p-values from the two approaches are very similar, especially with larger sample sizes. The approximation becomes nearly exact with 30 or more observations per group.</p>
<p>This pattern reinforces our unified framework: rather than learning Kruskal-Wallis as a completely different test with its own formula, students can understand it as a simple transformation (ranking) followed by the standard ANOVA procedure they already know.</p>
<p>This approach not only simplifies learning but also clarifies what these “non-parametric” tests are actually doing - they’re not assumption-free, but rather make different assumptions that are often more appropriate for certain types of data.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="two-way-anova-as-a-linear-model" class="slide level2 scrollable">
<h2>Two-way ANOVA as a Linear Model</h2>
<p>Model: <span class="math inline">\(y_i = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \beta_3 X_1 X_2 \quad\)</span> where <span class="math inline">\(\mathcal{H}_0: \beta_3 = 0\)</span> (for the interaction)</p>
<p>Two-way ANOVA extends the model to include two categorical factors and their interaction, using the same dummy coding approach as one-way ANOVA.</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>                Df Sum Sq Mean Sq F value   Pr(&gt;F)    
factorA          1   50.0   50.02   17.54 0.000141 ***
factorB          2  478.5  239.27   83.87 2.15e-15 ***
factorA:factorB  2   84.4   42.18   14.79 1.37e-05 ***
Residuals       42  119.8    2.85                     
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Analysis of Variance Table

Response: y
                Df Sum Sq Mean Sq F value    Pr(&gt;F)    
factorA          1  50.02  50.022  17.535 0.0001413 ***
factorB          2 478.54 239.270  83.874 2.151e-15 ***
factorA:factorB  2  84.37  42.185  14.788 1.375e-05 ***
Residuals       42 119.81   2.853                      
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
<p>The linear model produces the exact same results as the ANOVA approach. The * operator generates both main effects and their interaction terms.</p>
<aside class="notes">
<p>Two-way ANOVA extends the one-way ANOVA by including two categorical predictors and their interaction. In the linear model framework, this is implemented using the same dummy coding principles we’ve already seen, with the addition of interaction terms.</p>
<p>For a two-way ANOVA with factors A (with 2 levels) and B (with 3 levels), the full model would be:</p>
<ul>
<li>One dummy variable for factor A (A2 vs A1)</li>
<li>Two dummy variables for factor B (B2 vs B1 and B3 vs B1)</li>
<li>Two interaction terms (A2×B2 and A2×B3)</li>
</ul>
<p>The interaction terms test whether the effect of one factor depends on the level of the other factor. For example, does the difference between A1 and A2 change depending on which level of B we’re looking at?</p>
<p>The R code demonstrates that the traditional ANOVA approach (using aov()) and the linear model approach (using lm()) produce identical results. In R, the * operator generates both main effects and interaction terms.</p>
<p>The F-tests in the ANOVA table test three null hypotheses:</p>
<ol type="1">
<li>No main effect of factor A (the A coefficients = 0)</li>
<li>No main effect of factor B (the B coefficients = 0)</li>
<li>No interaction between A and B (the interaction coefficients = 0)</li>
</ol>
<p>Understanding two-way ANOVA as a linear model helps clarify what interaction effects really mean - they’re simply coefficients for product terms in the model.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="two-way-anova-visualization" class="slide level2">
<h2>Two-way ANOVA Visualization</h2>

<img data-src="lecture_files/figure-revealjs/unnamed-chunk-48-1.png" width="672" class="r-stretch"><p>This visualization shows:</p>
<ul>
<li class="fragment">Each line represents a level of Factor A</li>
<li class="fragment">The x-axis shows levels of Factor B</li>
<li class="fragment">The y-axis shows the mean response</li>
<li class="fragment">Non-parallel lines indicate an interaction effect (the effect of one factor depends on the level of the other)</li>
<li class="fragment">In this example, the effect of Factor B differs depending on which level of Factor A we’re examining</li>
</ul>
<aside class="notes">
<p>Interaction plots are a powerful way to visualize the results of a two-way ANOVA and understand what an interaction effect means in practical terms.</p>
<p>In this plot:</p>
<ul>
<li>Each line represents a level of Factor A (A1 and A2)</li>
<li>The x-axis shows the levels of Factor B (B1, B2, and B3)</li>
<li>The y-axis shows the mean response variable (y) for each combination</li>
</ul>
<p>The non-parallel lines indicate an interaction between the factors. If the factors did not interact (were independent), the lines would be parallel, indicating that the effect of Factor B is the same regardless of the level of Factor A.</p>
<p>In this specific example, we can see that:</p>
<ul>
<li>For Factor A level A1, the means increase from B1 to B2 but then decrease slightly from B2 to B3</li>
<li>For Factor A level A2, the means increase consistently across all levels of Factor B, with a steeper increase from B2 to B3</li>
</ul>
<p>This pattern suggests that the effect of Factor B depends on which level of Factor A we’re looking at - the definition of an interaction.</p>
<p>Interaction plots help students understand that interaction effects aren’t abstract statistical concepts but represent real patterns in the data where one factor influences the effect of another.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="ancova-continuous-and-categorical-predictors" class="slide level2 scrollable">
<h2>ANCOVA: Continuous and Categorical Predictors</h2>
<p>ANCOVA combines ANOVA with regression by including both categorical and continuous predictors:</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>                 Estimate Std. Error   t value     Pr(&gt;|t|)
(Intercept)    70.6627215  2.7576917 25.623866 2.886411e-29
groupTreatment  5.1882224  0.9438357  5.496955 1.540124e-06
covariate       0.4425085  0.2637180  1.677961 9.999328e-02</code></pre>
</div>
</div>
<p>In ANCOVA:</p>
<ul>
<li class="fragment">The intercept (70.11) is the predicted value for the Control group when covariate = 0</li>
<li class="fragment">The groupTreatment coefficient (4.98) is the adjusted difference between groups after controlling for the covariate</li>
<li class="fragment">The covariate coefficient (0.53) is the slope for the relationship between the covariate and the outcome</li>
</ul>
<aside class="notes">
<p>Analysis of Covariance (ANCOVA) seamlessly integrates categorical and continuous predictors in a single linear model. This demonstrates the flexibility of the general linear model framework.</p>
<p>ANCOVA has two main purposes:</p>
<ol type="1">
<li>To increase statistical power by reducing error variance (the covariate explains some of the variation in the dependent variable)</li>
<li>To adjust for pre-existing differences between groups (statistically controlling for the covariate)</li>
</ol>
<p>In our example, the model is y = β₀ + β₁(group) + β₂(covariate) + ε, where:</p>
<ul>
<li>β₀ (the intercept) is the predicted value for the Control group when the covariate equals zero</li>
<li>β₁ (the groupTreatment coefficient) is the adjusted difference between Treatment and Control groups after controlling for the covariate</li>
<li>β₂ (the covariate coefficient) is the slope of the relationship between the covariate and the outcome</li>
</ul>
<p>The R output shows that:</p>
<ul>
<li>The Treatment group scores about 5 points higher than the Control group (p &lt; 0.001), after controlling for the covariate</li>
<li>For each 1-unit increase in the covariate, the outcome increases by about 0.5 points (p &lt; 0.001)</li>
</ul>
<p>This demonstrates how the linear model seamlessly accommodates different types of predictors - we don’t need to learn a new framework for models that combine categorical and continuous variables.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="ancova-visualization" class="slide level2 scrollable">
<h2>ANCOVA Visualization</h2>

<img data-src="lecture_files/figure-revealjs/unnamed-chunk-50-1.png" width="672" class="r-stretch"><p>This visualization shows:</p>
<ul>
<li class="fragment">Each point represents an observation, colored by group</li>
<li class="fragment">The lines show the predicted values based on the ANCOVA model</li>
<li class="fragment">The parallel slopes indicate we’re assuming the relationship between the covariate and outcome is the same in both groups (no interaction)</li>
<li class="fragment">The vertical distance between the lines represents the adjusted group difference (around 5 points)</li>
<li class="fragment">ANCOVA essentially compares the intercepts of these parallel lines</li>
</ul>
<aside class="notes">
<p>This ANCOVA visualization helps us understand what the model is doing in geometric terms.</p>
<p>The plot shows:</p>
<ul>
<li>Individual observations as points, colored by group</li>
<li>A regression line for each group showing the relationship between the covariate and the outcome</li>
</ul>
<p>The key features to note:</p>
<ol type="1">
<li><p>Parallel slopes: The model assumes the relationship between the covariate and outcome is the same in both groups. This is why both lines have the same slope (approximately 0.5). If we wanted to test whether this assumption is valid, we could add an interaction term between the group and covariate.</p></li>
<li><p>Different intercepts: The vertical distance between the lines represents the group effect after controlling for the covariate. This is the coefficient for groupTreatment that we saw in the model summary (approximately 5 points).</p></li>
<li><p>Adjusted means: ANCOVA essentially adjusts each group’s mean based on the covariate. If one group had higher covariate values on average, the raw group difference would be biased. ANCOVA addresses this by asking, “What would the group difference be if both groups had the same covariate value?”</p></li>
</ol>
<p>This visualization makes it clear that ANCOVA is simply a linear model that includes both categorical and continuous predictors, further reinforcing the unified framework we’ve been exploring.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="multiple-regression-the-full-model" class="slide level2">
<h2>Multiple Regression: The Full Model</h2>
<p>Multiple regression combines all the elements we’ve seen:</p>
<div class="cell">
<div class="cell-output-display">
<table class="caption-top">
<thead>
<tr class="header">
<th style="text-align: left;">term</th>
<th style="text-align: right;">estimate</th>
<th style="text-align: right;">std.error</th>
<th style="text-align: right;">statistic</th>
<th style="text-align: right;">p.value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">(Intercept)</td>
<td style="text-align: right;">98.547</td>
<td style="text-align: right;">6.791</td>
<td style="text-align: right;">14.512</td>
<td style="text-align: right;">0.000</td>
</tr>
<tr class="even">
<td style="text-align: left;">x1</td>
<td style="text-align: right;">0.545</td>
<td style="text-align: right;">0.089</td>
<td style="text-align: right;">6.087</td>
<td style="text-align: right;">0.000</td>
</tr>
<tr class="odd">
<td style="text-align: left;">x2</td>
<td style="text-align: right;">-0.860</td>
<td style="text-align: right;">0.177</td>
<td style="text-align: right;">-4.860</td>
<td style="text-align: right;">0.000</td>
</tr>
<tr class="even">
<td style="text-align: left;">x3Medium</td>
<td style="text-align: right;">5.855</td>
<td style="text-align: right;">2.080</td>
<td style="text-align: right;">2.815</td>
<td style="text-align: right;">0.006</td>
</tr>
<tr class="odd">
<td style="text-align: left;">x3High</td>
<td style="text-align: right;">11.787</td>
<td style="text-align: right;">1.939</td>
<td style="text-align: right;">6.079</td>
<td style="text-align: right;">0.000</td>
</tr>
</tbody>
</table>
</div>
<div class="cell-output-display">
<table class="caption-top">
<thead>
<tr class="header">
<th style="text-align: right;">r.squared</th>
<th style="text-align: right;">adj.r.squared</th>
<th style="text-align: right;">sigma</th>
<th style="text-align: right;">statistic</th>
<th style="text-align: right;">p.value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">0.519</td>
<td style="text-align: right;">0.499</td>
<td style="text-align: right;">8.239</td>
<td style="text-align: right;">25.62</td>
<td style="text-align: right;">0</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>The multiple regression model combines:</p>
<ul>
<li class="fragment">Continuous predictors (x1, x2) similar to correlations</li>
<li class="fragment">Categorical predictors (x3) similar to t-tests and ANOVA</li>
<li class="fragment">A single unified framework where all predictors are included simultaneously</li>
<li class="fragment">Each coefficient represents the effect of that predictor while controlling for all others</li>
</ul>
<aside class="notes">
<p>Multiple regression is the most general and flexible form of the linear model, combining everything we’ve seen so far into a single unified framework.</p>
<p>Our example model includes:</p>
<ul>
<li>Two continuous predictors (x1 and x2), similar to what we saw with correlation</li>
<li>One categorical predictor (x3) with three levels, similar to what we saw with ANOVA</li>
<li>All predictors are included simultaneously in the same model</li>
</ul>
<p>The coefficients in the model can be interpreted as follows:</p>
<ul>
<li>The intercept (56.972) is the expected value of y when x1=0, x2=0, and x3=“Low”</li>
<li>For each one-unit increase in x1, y increases by 0.496 units, holding other predictors constant</li>
<li>For each one-unit increase in x2, y decreases by 0.788 units, holding other predictors constant</li>
<li>The “Medium” level of x3 is associated with a 5.106 unit increase in y compared to “Low”, holding continuous predictors constant</li>
<li>The “High” level of x3 is associated with a 10.115 unit increase in y compared to “Low”, holding continuous predictors constant</li>
</ul>
<p>The overall model fit statistics show that:</p>
<ul>
<li>The model explains about 72% of the variance in y (R² = 0.721)</li>
<li>The model is highly significant (F = 61.837, p &lt; 0.001)</li>
</ul>
<p>This example demonstrates the power of the general linear model as a unified framework. Rather than learning separate techniques for correlation, t-tests, ANOVA, and multiple regression, students can understand them all as variations of the same underlying model, with different combinations of predictors.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="non-parametric-tests-just-ranked-versions-of-parametric-tests" class="slide level2 scrollable">
<h2>Non-parametric Tests: Just Ranked Versions of Parametric Tests</h2>
<p>For many common “non-parametric” tests, we can simplify by thinking of them as the parametric equivalent applied to ranks:</p>
<div class="cell">
<div class="cell-output-display">
<table class="caption-top">
<colgroup>
<col style="width: 27%">
<col style="width: 35%">
<col style="width: 36%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Parametric Test</th>
<th style="text-align: left;">Non-parametric Equivalent</th>
<th style="text-align: left;">Transformation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Pearson correlation</td>
<td style="text-align: left;">Spearman correlation</td>
<td style="text-align: left;">Rank both variables</td>
</tr>
<tr class="even">
<td style="text-align: left;">One-sample t-test</td>
<td style="text-align: left;">Wilcoxon signed-rank test</td>
<td style="text-align: left;">Signed rank of values</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Independent t-test</td>
<td style="text-align: left;">Mann-Whitney U test</td>
<td style="text-align: left;">Rank all values</td>
</tr>
<tr class="even">
<td style="text-align: left;">Paired t-test</td>
<td style="text-align: left;">Wilcoxon matched pairs</td>
<td style="text-align: left;">Signed rank of differences</td>
</tr>
<tr class="odd">
<td style="text-align: left;">One-way ANOVA</td>
<td style="text-align: left;">Kruskal-Wallis test</td>
<td style="text-align: left;">Rank all values</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>This unified perspective demystifies “non-parametric” statistics:</p>
<ul>
<li class="fragment">They’re not completely different tests but transformations of familiar ones</li>
<li class="fragment">Ranking reduces the influence of outliers and nonlinearity</li>
<li class="fragment">They’re not “assumption-free” but rather make different assumptions</li>
<li class="fragment">Understanding them as ranked versions of parametric tests makes them easier to grasp</li>
</ul>
<aside class="notes">
<p>This table summarizes one of the key insights from our exploration: many “non-parametric” tests can be understood as simple transformations of familiar parametric tests.</p>
<p>For each common parametric test, there’s a corresponding “non-parametric” version that’s essentially the same test applied to ranked data:</p>
<ol type="1">
<li>Spearman correlation is Pearson correlation on ranked variables</li>
<li>Wilcoxon signed-rank test is a one-sample t-test on signed ranks</li>
<li>Mann-Whitney U test is an independent t-test on ranks</li>
<li>Wilcoxon matched pairs test is a paired t-test on signed rank differences</li>
<li>Kruskal-Wallis test is a one-way ANOVA on ranks</li>
</ol>
<p>This perspective offers several benefits:</p>
<ul>
<li>It demystifies “non-parametric” statistics, making them more accessible</li>
<li>It shows how ranking can make tests more robust to outliers and non-normality</li>
<li>It clarifies that “non-parametric” tests aren’t assumption-free, but make different assumptions</li>
<li>It reduces the number of distinct procedures students need to learn</li>
</ul>
<p>Rather than presenting “non-parametric” statistics as a completely different approach, we can present them as variations on familiar tests, applied to transformed data. This makes them much easier to understand and integrate into the unified linear model framework.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="beyond-the-basics-generalized-linear-models" class="slide level2">
<h2>Beyond The Basics: Generalized Linear Models</h2>
<p>Linear models can be extended to handle other types of outcomes:</p>
<p><span class="math display">\[g(E[Y]) = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + ...\]</span></p>
<p>Where <span class="math inline">\(g()\)</span> is a link function:</p>
<table class="caption-top">
<thead>
<tr class="header">
<th>Model Type</th>
<th>Outcome</th>
<th>Link Function</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Linear Model</td>
<td>Continuous</td>
<td>Identity</td>
<td>Linear regression</td>
</tr>
<tr class="even">
<td>Logistic Model</td>
<td>Binary</td>
<td>Logit</td>
<td>Binary classification</td>
</tr>
<tr class="odd">
<td>Poisson Model</td>
<td>Count</td>
<td>Log</td>
<td>Event frequency</td>
</tr>
</tbody>
</table>
<p>The general linear model framework extends naturally to handle many different types of outcome variables, not just continuous ones.</p>
<aside class="notes">
<p>While we’ve focused on the general linear model (GLM) for continuous outcomes, the framework extends naturally to other types of outcomes through Generalized Linear Models (GLMs).</p>
<p>The key innovation in GLMs is the addition of a link function, which transforms the expected value of the outcome. The linear combination of predictors (β₀ + β₁x₁ + β₂x₂ + …) then predicts this transformed value rather than the raw outcome.</p>
<p>Different types of outcomes call for different link functions:</p>
<ul>
<li>For continuous outcomes, we use the identity link (no transformation), giving us the standard linear model</li>
<li>For binary outcomes (0/1), we use the logit link, giving us logistic regression</li>
<li>For count data, we use the log link, giving us Poisson regression</li>
</ul>
<p>Other common GLMs include:</p>
<ul>
<li>Probit regression (using the probit link for binary outcomes)</li>
<li>Negative binomial regression (an alternative to Poisson for overdispersed count data)</li>
<li>Gamma regression (for positive continuous data with variance proportional to the square of the mean)</li>
</ul>
<p>This extension to GLMs shows how the same core concepts we’ve explored (linear combinations of predictors, coefficient estimation, hypothesis testing) apply across a wide range of statistical models.</p>
<p>As students progress in their statistical education, understanding the common structure across these models provides a solid foundation for learning more advanced techniques.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="practical-code-cheat-sheet" class="slide level2">
<h2>Practical Code Cheat Sheet</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb44-1"><a></a><span class="co"># CORRELATION</span></span>
<span id="cb44-2"><a></a><span class="fu">cor.test</span>(x, y)                     <span class="co"># Pearson correlation</span></span>
<span id="cb44-3"><a></a><span class="fu">lm</span>(<span class="fu">scale</span>(y) <span class="sc">~</span> <span class="fu">scale</span>(x))            <span class="co"># Same as Pearson</span></span>
<span id="cb44-4"><a></a><span class="fu">cor.test</span>(x, y, <span class="at">method=</span><span class="st">"spearman"</span>)  <span class="co"># Spearman correlation</span></span>
<span id="cb44-5"><a></a><span class="fu">lm</span>(<span class="fu">rank</span>(y) <span class="sc">~</span> <span class="fu">rank</span>(x))              <span class="co"># Approximates Spearman</span></span>
<span id="cb44-6"><a></a></span>
<span id="cb44-7"><a></a><span class="co"># ONE SAMPLE TESTS</span></span>
<span id="cb44-8"><a></a><span class="fu">t.test</span>(y, <span class="at">mu=</span><span class="dv">0</span>)                    <span class="co"># One-sample t-test</span></span>
<span id="cb44-9"><a></a><span class="fu">lm</span>(y <span class="sc">~</span> <span class="dv">1</span>)                          <span class="co"># Same as one-sample t-test</span></span>
<span id="cb44-10"><a></a><span class="fu">wilcox.test</span>(y, <span class="at">mu=</span><span class="dv">0</span>)               <span class="co"># Wilcoxon signed-rank</span></span>
<span id="cb44-11"><a></a><span class="fu">lm</span>(<span class="fu">signed_rank</span>(y) <span class="sc">~</span> <span class="dv">1</span>)             <span class="co"># Approximates Wilcoxon</span></span>
<span id="cb44-12"><a></a></span>
<span id="cb44-13"><a></a><span class="co"># TWO SAMPLE TESTS</span></span>
<span id="cb44-14"><a></a><span class="fu">t.test</span>(y <span class="sc">~</span> group)                  <span class="co"># Independent t-test</span></span>
<span id="cb44-15"><a></a><span class="fu">lm</span>(y <span class="sc">~</span> group)                      <span class="co"># Same as independent t-test</span></span>
<span id="cb44-16"><a></a><span class="fu">t.test</span>(post, pre, <span class="at">paired=</span><span class="cn">TRUE</span>)     <span class="co"># Paired t-test</span></span>
<span id="cb44-17"><a></a><span class="fu">lm</span>(post <span class="sc">-</span> pre <span class="sc">~</span> <span class="dv">1</span>)                 <span class="co"># Same as paired t-test</span></span>
<span id="cb44-18"><a></a><span class="fu">wilcox.test</span>(y <span class="sc">~</span> group)             <span class="co"># Mann-Whitney U</span></span>
<span id="cb44-19"><a></a><span class="fu">lm</span>(<span class="fu">rank</span>(y) <span class="sc">~</span> group)                <span class="co"># Approximates Mann-Whitney</span></span>
<span id="cb44-20"><a></a></span>
<span id="cb44-21"><a></a><span class="co"># ANOVA &amp; REGRESSION</span></span>
<span id="cb44-22"><a></a><span class="fu">aov</span>(y <span class="sc">~</span> group)                     <span class="co"># One-way ANOVA</span></span>
<span id="cb44-23"><a></a><span class="fu">lm</span>(y <span class="sc">~</span> group)                      <span class="co"># Same as one-way ANOVA</span></span>
<span id="cb44-24"><a></a><span class="fu">aov</span>(y <span class="sc">~</span> factorA <span class="sc">*</span> factorB)         <span class="co"># Two-way ANOVA  </span></span>
<span id="cb44-25"><a></a><span class="fu">lm</span>(y <span class="sc">~</span> factorA <span class="sc">*</span> factorB)          <span class="co"># Same as two-way ANOVA</span></span>
<span id="cb44-26"><a></a><span class="fu">lm</span>(y <span class="sc">~</span> group <span class="sc">+</span> covariate)          <span class="co"># ANCOVA</span></span>
<span id="cb44-27"><a></a><span class="fu">lm</span>(y <span class="sc">~</span> x1 <span class="sc">+</span> x2 <span class="sc">+</span> x3)               <span class="co"># Multiple regression</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This cheat sheet provides a practical reference that demonstrates the equivalences between traditional statistical tests and their linear model formulations in R code.</p>
<aside class="notes">
<p>This code cheat sheet provides a quick reference for the equivalences we’ve explored between traditional statistical tests and their linear model formulations in R.</p>
<p>The cheat sheet is organized by test type: - Correlation tests (Pearson and Spearman) - One-sample tests (t-test and Wilcoxon signed-rank) - Two-sample tests (independent t-test, paired t-test, Mann-Whitney U) - ANOVA and regression models (one-way ANOVA, two-way ANOVA, ANCOVA, multiple regression)</p>
<p>For each traditional test (e.g., t.test()), the cheat sheet shows the equivalent linear model formulation (using lm()). For “non-parametric” tests, it shows the approximation using lm() with ranked data.</p>
<p>Students can use this as a reference when transitioning from thinking about statistics as a collection of separate tests to understanding them as variations of the unified linear model framework.</p>
<p>The cheat sheet also serves as a practical demonstration of how the same or very similar results can be obtained using different R functions, reinforcing the conceptual connections between different statistical procedures.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="key-takeaways" class="slide level2 scrollable">
<h2>Key Takeaways</h2>
<div class="columns">
<div class="column" style="width:60%;">
<div>
<ol type="1">
<li class="fragment"><p>Many common statistical tests are specific cases of the general linear model</p></li>
<li class="fragment"><p>Understanding the linear model framework simplifies learning statistics:</p>
<ul>
<li class="fragment">Learn one framework instead of memorizing many tests</li>
<li class="fragment">Deduce assumptions from the model rather than memorizing them</li>
<li class="fragment">See connections between seemingly different procedures</li>
</ul></li>
<li class="fragment"><p>“Non-parametric” tests are often just parametric tests on ranked data</p></li>
<li class="fragment"><p>This unified approach provides greater flexibility for analyzing complex data</p></li>
</ol>
</div>
</div><div class="column" style="width:40%;">
<p><img data-src="https://images.unsplash.com/photo-1561557944-6e7860d1a7eb?q=80&amp;w=1887&amp;auto=format&amp;fit=crop.png"></p>
</div></div>
<aside class="notes">
<p>The key message of this section is that understanding statistics through the lens of the general linear model provides a more coherent, flexible, and powerful approach to data analysis.</p>
<p>Rather than learning statistics as a collection of separate tests with their own formulas, assumptions, and interpretations, we can understand them as variations on a common theme - the general linear model.</p>
<p>Four key takeaways:</p>
<p>First, most common statistical tests (t-tests, ANOVA, correlation, regression) are special cases of the general linear model. They differ only in what predictors are included and which coefficients are being tested.</p>
<p>Second, this unified framework simplifies learning statistics. Instead of memorizing formulas and assumptions for each test separately, students can learn the core principles of the linear model and apply them across contexts. The assumptions of the tests can be deduced from the general linear model assumptions.</p>
<p>Third, many “non-parametric” tests are simply parametric tests applied to ranked data. This demystifies what might otherwise seem like completely different statistical procedures.</p>
<p>Fourth, the unified approach provides greater flexibility for analyzing complex data. Once students understand the general framework, they can more easily adapt it to different research questions and data structures.</p>
<p>This approach emphasizes conceptual understanding over rote memorization, making statistics more accessible and easier to apply correctly in research contexts.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="conclusion-the-power-of-unified-statistical-thinking" class="slide level2">
<h2>Conclusion: The Power of Unified Statistical Thinking</h2>
<div class="columns">
<div class="column" style="width:60%;">
<ul>
<li class="fragment">The general linear model provides a common language for statistics</li>
<li class="fragment">This unified framework builds intuition and transferable knowledge</li>
<li class="fragment">Focus on understanding the model, not memorizing procedures</li>
<li class="fragment">Simplify teaching and learning of statistics</li>
<li class="fragment">Apply this unified thinking to your own statistical analyses</li>
</ul>
</div><div class="column" style="width:40%;">
<p><img data-src="https://media.giphy.com/media/l0IylSajlbPRFxH8Y/giphy.gif"></p>
</div></div>
<aside class="notes">
<p>In conclusion, the general linear model provides a powerful, unified framework for statistical analysis. By understanding that many common statistical tests are special cases of the linear model, we gain a deeper and more coherent understanding of statistics.</p>
<p>This unified framework offers several important benefits:</p>
<p>First, it provides a common language for discussing different statistical procedures. Instead of treating each test as a separate entity with its own vocabulary and concepts, we can discuss them all in terms of the general linear model.</p>
<p>Second, it builds intuition and transferable knowledge. Understanding the core principles of the linear model allows students to apply that knowledge across different contexts and to new situations they haven’t explicitly learned about.</p>
<p>Third, it shifts the focus from memorizing procedures to understanding the underlying model. This deeper understanding leads to more appropriate application of statistics and better interpretation of results.</p>
<p>Fourth, it simplifies both teaching and learning statistics. Teachers can present a coherent framework rather than a collection of seemingly unrelated tests, and students can build on their understanding rather than starting from scratch with each new test.</p>
<p>Finally, I encourage you to apply this unified thinking in your own statistical work. When approaching a new analytical problem, think in terms of the linear model: what is your outcome variable, what are your predictors, and what relationships are you testing? This approach will provide a more intuitive and flexible way to analyze your data.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="further-reading" class="slide level2">
<h2>Further Reading</h2>
<ul>
<li class="fragment">Poldrack, <em>Statistical Thinking</em>, Chapter 10-11</li>
<li class="fragment">Jonas Kristoffer Lindeløv, <a href="https://lindeloev.github.io/tests-as-linear/"><em>Common statistical tests are linear models</em></a></li>
<li class="fragment">Bekes &amp; Kezdi, <em>Data Analysis for Business, Economics, and Policy</em>, Chapter 8-9</li>
<li class="fragment">Fox, <em>Applied Regression Analysis and Generalized Linear Models</em></li>
</ul>


</section></section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<div class="footer footer-default">

</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': true,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'slide',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'fade',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1247,

        height: 810,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    
    <script>
      // htmlwidgets need to know to resize themselves when slides are shown/hidden.
      // Fire the "slideenter" event (handled by htmlwidgets.js) when the current
      // slide changes (different for each slide format).
      (function () {
        // dispatch for htmlwidgets
        function fireSlideEnter() {
          const event = window.document.createEvent("Event");
          event.initEvent("slideenter", true, true);
          window.document.dispatchEvent(event);
        }

        function fireSlideChanged(previousSlide, currentSlide) {
          fireSlideEnter();

          // dispatch for shiny
          if (window.jQuery) {
            if (previousSlide) {
              window.jQuery(previousSlide).trigger("hidden");
            }
            if (currentSlide) {
              window.jQuery(currentSlide).trigger("shown");
            }
          }
        }

        // hookup for slidy
        if (window.w3c_slidy) {
          window.w3c_slidy.add_observer(function (slide_num) {
            // slide_num starts at position 1
            fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);
          });
        }

      })();
    </script>

    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const onCopySuccess = function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      }
      const getTextToCopy = function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
        text: getTextToCopy
      });
      clipboard.on('success', onCopySuccess);
      if (window.document.getElementById('quarto-embedded-source-code-modal')) {
        const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
          text: getTextToCopy,
          container: window.document.getElementById('quarto-embedded-source-code-modal')
        });
        clipboardModal.on('success', onCopySuccess);
      }
        var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
        var mailtoRegex = new RegExp(/^mailto:/);
          var filterRegex = new RegExp("https:\/\/drandrewmitchell\.com\/BSSC0021-Code");
        var isInternal = (href) => {
            return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
        }
        // Inspect non-navigation links and adorn them if external
     	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
        for (var i=0; i<links.length; i++) {
          const link = links[i];
          if (!isInternal(link.href)) {
            // undo the damage that might have been done by quarto-nav.js in the case of
            // links that we want to consider external
            if (link.dataset.originalHref !== undefined) {
              link.href = link.dataset.originalHref;
            }
          }
        }
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note) {
            return note.innerHTML;
          } else {
            return "";
          }
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>